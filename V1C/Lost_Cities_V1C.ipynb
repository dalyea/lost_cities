{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4408281-2787-40fb-9f04-f78bc9f93220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lost Cities V1C\n",
    "# Starting with V1A, adding:\n",
    "# 1. the new legal block to draw an X card from center when exp started, and 6+ cards in deck\n",
    "# 2. new bonus for playing a next number card in an open exp\n",
    "# KEY:\n",
    "# Adding final score tracking into replay buffer via episode transitions\n",
    "# Tracking P1 and P2, with boosts for final reward (score) and for step rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2940239b-d2ba-48c6-b4c8-dcb01deec9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1f3e3-58ce-4d29-ab7e-dfaaa234d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAME SETUP\n",
    "COLORS = ['R', 'B', 'G']\n",
    "NUMBERS = ['X', '2', '3', '4', '5', '6']\n",
    "CARD_TO_IDX = {color + num: idx for idx, (color, num) in enumerate([(c, n) for c in COLORS for n in NUMBERS])}\n",
    "draw_to_index = {draw: i for i, draw in enumerate(['deck', 'R', 'B', 'G'])}\n",
    "tgt_pts = 7\n",
    "color_cnt=len(COLORS)\n",
    "per_color=len(NUMBERS)\n",
    "card_cnt=len(COLORS)*len(NUMBERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbb87e4-ff25-4c2d-a6b2-309128d93d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASICS & CLASSES\n",
    "\n",
    "# Deck creation\n",
    "def create_deck():\n",
    "    deck = [color + num for color in COLORS for num in NUMBERS]\n",
    "    random.shuffle(deck)\n",
    "    return deck\n",
    "\n",
    "# Environment Class (unchanged)\n",
    "class LostCitiesEnv:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        # self.last_discard = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.deck = create_deck()\n",
    "        self.hands = {f'P{i+1}': [self.deck.pop() for _ in range(3)] for i in range(2)}\n",
    "        self.expeditions = {player: defaultdict(list) for player in self.hands}\n",
    "        self.center_piles = {color: [] for color in COLORS}\n",
    "        self.players = list(self.hands.keys())\n",
    "        self.current_player_idx = 0\n",
    "        self.done = False\n",
    "        # self.last_discard = None\n",
    "        self.last_discards = {player: None for player in self.players}  # ✅ per-player discard tracking\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        state = {\n",
    "            'hands': {p: sorted(self.hands[p]) for p in self.hands},\n",
    "            'expeditions': {p: {color: list(cards) for color, cards in self.expeditions[p].items()} for p in self.expeditions},\n",
    "            'center': {color: list(self.center_piles[color]) for color in COLORS},\n",
    "            'deck_size': len(self.deck),\n",
    "            'current_player': self.players[self.current_player_idx]\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    def can_play_to_expedition(self, expedition, card):\n",
    "        if not expedition:\n",
    "            return True\n",
    "        if card[1] == 'X':\n",
    "            return False\n",
    "        existing_values = [int(c[1]) for c in expedition if c[1] != 'X']\n",
    "        last_number = max(existing_values) if existing_values else None\n",
    "        if last_number is None:\n",
    "            return True\n",
    "        return int(card[1]) >= last_number\n",
    "\n",
    "    def get_legal_actions(self, player):\n",
    "        hand = self.hands[player]\n",
    "        expeditions = self.expeditions[player]\n",
    "        deck_size = len(self.deck)\n",
    "    \n",
    "        playable_to_expedition = []\n",
    "        playable_to_center = []\n",
    "\n",
    "        for color in COLORS:\n",
    "            # Number cards (non-'X') in hand\n",
    "            color_number_cards = [card for card in hand if card[0] == color and card[1] != 'X']\n",
    "            expedition = expeditions[color]\n",
    "            existing_numbers = [int(c[1]) for c in expedition if c[1] != 'X']\n",
    "            highest_played = max(existing_numbers) if existing_numbers else 0\n",
    "            valid_cards = [card for card in color_number_cards if int(card[1]) >= highest_played]\n",
    "        \n",
    "            # Apply lowest-card rule if enough deck remains\n",
    "            if valid_cards:\n",
    "                deck_remaining = len(self.deck)\n",
    "                if deck_remaining >= 3:\n",
    "                    min_val = min(int(c[1]) for c in valid_cards)\n",
    "                    valid_cards = [c for c in valid_cards if int(c[1]) == min_val]\n",
    "        \n",
    "                playable_to_expedition.extend(valid_cards)\n",
    "        \n",
    "            # Multipliers (only if no numbers yet in expedition) - but maybe no other same color cards\n",
    "            # multiplier_cards = [card for card in hand if card[0] == color and card[1] == 'X']\n",
    "            # if multiplier_cards and not existing_numbers:\n",
    "            #     playable_to_expedition.extend(multiplier_cards)\n",
    "\n",
    "            # Multipliers (only if no numbers yet in expedition) - but must have at least one same color card\n",
    "            multiplier_cards = [card for card in hand if card[0] == color and card[1] == 'X']\n",
    "            if multiplier_cards and not existing_numbers:\n",
    "                # Check for sum of same color cards 4+\n",
    "                number_points = sum(int(c[1]) for c in hand if c[0] == color and c[1] != 'X')\n",
    "                if number_points >= 4:\n",
    "                    playable_to_expedition.extend(multiplier_cards)\n",
    "                # Check for presence of at least one number card 4+\n",
    "                # has_decent_number = any(int(c[1]) >= 4 for c in hand if c[0] == color and c[1] != 'X')\n",
    "                # if has_decent_number:\n",
    "                #     playable_to_expedition.extend(multiplier_cards)\n",
    "\n",
    "\n",
    "        if random.random() < 1e-8:\n",
    "            if not playable_to_expedition:\n",
    "                print(f\"\\n[DEBUG] No playable expedition cards for player {player}\")\n",
    "                print(f\"Hand: {sorted(hand)}\")\n",
    "                print(f\"Expeditions:\")\n",
    "                for c in COLORS:\n",
    "                    exp_cards = expeditions[c]\n",
    "                    print(f\"  {c}: {exp_cards}\")\n",
    "                print(f\"Deck remaining: {len(self.deck)}\\n\")\n",
    "                \n",
    "        # ✅ Multipliers: Only if expedition has no numbers yet\n",
    "        for card in hand:\n",
    "            if card[1] == 'X':\n",
    "                expedition = expeditions[card[0]]\n",
    "                existing_numbers = [c for c in expedition if c[1] != 'X']\n",
    "                if not existing_numbers:\n",
    "                    playable_to_expedition.append(card)\n",
    "                \n",
    "        # ✅ Discards: Always legal to discard any card\n",
    "        # for card in hand:\n",
    "        #     playable_to_center.append(card)\n",
    "\n",
    "        # Modification - do not play to center a card which could be put on an open exp\n",
    "        for card in hand:\n",
    "            expedition_pile = expeditions[card[0]]\n",
    "            existing_numbers = [int(c[1]) for c in expedition_pile if c[1] != 'X']\n",
    "            if existing_numbers:\n",
    "                top_val = max(existing_numbers)\n",
    "                card_val = int(card[1]) if card[1] != 'X' else None\n",
    "                if card_val is not None and card_val >= top_val:\n",
    "                    continue  # Don't allow discard—card is playable\n",
    "            playable_to_center.append(card)\n",
    "    \n",
    "        actions = [(\"expedition\", card) for card in playable_to_expedition] + [(\"center\", card) for card in playable_to_center]\n",
    "    \n",
    "        # ✅ Drawing logic with redraw rule\n",
    "        draws = ['deck'] + [c for c in COLORS if self.center_piles[c]]\n",
    "        player_last_discard = self.last_discards.get(player, None)\n",
    "        if player_last_discard is not None:\n",
    "            discard_color, discard_card = player_last_discard\n",
    "            if self.center_piles[discard_color] and self.center_piles[discard_color][-1] == discard_card:\n",
    "                if discard_color in draws:\n",
    "                    draws.remove(discard_color)\n",
    "\n",
    "        # Filter out existing draws\n",
    "        filtered_draws = []\n",
    "\n",
    "        # New legal block, drawing an X when already started color\n",
    "        deck_remaining = len(self.deck)\n",
    "        \n",
    "        for d in draws:\n",
    "            if d == 'deck':\n",
    "                filtered_draws.append(d)\n",
    "            elif deck_remaining < 6:\n",
    "                # Allow any center draws when deck is low\n",
    "                filtered_draws.append(d)\n",
    "            else:\n",
    "                center_pile = self.center_piles[d]\n",
    "                if center_pile:\n",
    "                    top_card = center_pile[-1]\n",
    "                    if top_card[1] == 'X':\n",
    "                        expedition_started = bool(self.expeditions[player][d])  # expedition already started\n",
    "                        if not expedition_started:\n",
    "                            filtered_draws.append(d)\n",
    "                        # else → skip this draw: can't use multiplier once expedition started\n",
    "                    else:\n",
    "                        filtered_draws.append(d)\n",
    "\n",
    "        # Now reassign\n",
    "        draws=filtered_draws\n",
    "\n",
    "        return actions, draws\n",
    "\n",
    "    def step(self, action, draw_choice):\n",
    "        if self.done:\n",
    "            return self.get_state(), 0, True\n",
    "    \n",
    "        player = self.players[self.current_player_idx]\n",
    "        action_type, card = action\n",
    "    \n",
    "        # ✅ Remove card from hand BEFORE anything else\n",
    "        assert card in self.hands[player], f\"Player {player} does not have card {card}!\"\n",
    "        self.hands[player].remove(card)\n",
    "    \n",
    "        # ✅ Play action: place card on expedition or center pile\n",
    "        if action_type == 'expedition':\n",
    "            self.expeditions[player][card[0]].append(card)\n",
    "            self.last_discards[player] = None\n",
    "        elif action_type == 'center':\n",
    "            self.center_piles[card[0]].append(card)\n",
    "            self.last_discards[player] = (card[0], card)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown action type: {action_type}\")\n",
    "    \n",
    "        # ✅ Draw phase (only happens ONCE per turn)\n",
    "        if draw_choice == 'deck':\n",
    "            if self.deck:\n",
    "                self.hands[player].append(self.deck.pop())\n",
    "            else:\n",
    "                # No deck left, but should trigger game over below\n",
    "                pass\n",
    "        elif draw_choice in self.center_piles and self.center_piles[draw_choice]:\n",
    "            self.hands[player].append(self.center_piles[draw_choice].pop())\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid draw_choice: {draw_choice}\")\n",
    "    \n",
    "        # ✅ Hand must return to exactly 3 cards\n",
    "        assert len(self.hands[player]) == 3, f\"{player} has {len(self.hands[player])} cards in hand!\"\n",
    "    \n",
    "        # ✅ Check for end of game (deck empty)\n",
    "        if not self.deck:\n",
    "            self.done = True\n",
    "            reward = self.compute_score(player)\n",
    "            return self.get_state(), reward, True\n",
    "    \n",
    "        # === ASSERTIONS ===\n",
    "\n",
    "        # 1. Each player must have exactly 3 cards\n",
    "        for p in self.players:\n",
    "            assert len(self.hands[p]) == 3, f\"{p} has {len(self.hands[p])} cards!\"\n",
    "    \n",
    "        # 2. Each center pile must have at most 6 cards (can't discard more than that in 18-card game)\n",
    "        for color, pile in self.center_piles.items():\n",
    "            assert len(pile) <= per_color, f\"Center pile {color} has {len(pile)} cards!\"\n",
    "    \n",
    "        # 3. Each expedition pile must have at most 6 cards (max number per color)\n",
    "        for player_exped in self.expeditions.values():\n",
    "            for color, pile in player_exped.items():\n",
    "                assert len(pile) <= per_color, f\"Expedition {color} has {len(pile)} cards!\"\n",
    "            \n",
    "        # ✅ Card count integrity check (should always be card_cnt)\n",
    "        total_cards = sum(len(h) for h in self.hands.values()) + \\\n",
    "                      sum(len(p) for p in self.center_piles.values()) + \\\n",
    "                      sum(len(pile) for player_piles in self.expeditions.values() for pile in player_piles.values()) + \\\n",
    "                      len(self.deck)\n",
    "        assert total_cards == card_cnt, f\"Card count mismatch! Total cards: {total_cards}\"\n",
    "\n",
    "        # Validate expedition state for current player\n",
    "        player_exped = self.expeditions[player]\n",
    "        \n",
    "        # Get list of expedition colors where at least one card has been played\n",
    "        started_expeditions = [color for color, pile in player_exped.items() if pile]\n",
    "        \n",
    "        # Assert: Never more than 3 expeditions started\n",
    "        assert len(started_expeditions) <= color_cnt, f\"Too many expeditions started: {started_expeditions}\"\n",
    "        \n",
    "        # Assert: No duplicate colors (guaranteed by defaultdict keys, but we double-check)\n",
    "        assert len(started_expeditions) == len(set(started_expeditions)), f\"Duplicate expedition colors: {started_expeditions}\"\n",
    "\n",
    "        # ✅ Switch to next player\n",
    "        self.current_player_idx = (self.current_player_idx + 1) % len(self.players)\n",
    "\n",
    "        return self.get_state(), 0, False\n",
    "\n",
    "    def compute_score(self, player):\n",
    "        total = 0\n",
    "        for color, cards in self.expeditions[player].items():\n",
    "            if cards:\n",
    "                values = [int(card[1]) for card in cards if card[1] != 'X']\n",
    "                multiplier = 1 + sum(1 for card in cards if card[1] == 'X')\n",
    "                expedition_score = multiplier * (sum(values) - tgt_pts)\n",
    "                total += expedition_score\n",
    "        return total\n",
    "\n",
    "# Enhanced Feature Extraction\n",
    "def extract_features(state):\n",
    "    current_player = state['current_player']\n",
    "    other_player = [p for p in state['hands'] if p != current_player][0]\n",
    "\n",
    "    # Hand cards (18)\n",
    "    hand_counts = np.zeros(len(CARD_TO_IDX))\n",
    "    for card in state['hands'][current_player]:\n",
    "        idx = CARD_TO_IDX[card]\n",
    "        hand_counts[idx] += 1\n",
    "\n",
    "    # Player expeditions (9 features)\n",
    "    player_exped = []\n",
    "    for color in COLORS:\n",
    "        cards = state['expeditions'][current_player].get(color, [])\n",
    "        values = [int(c[1]) for c in cards if c[1] != 'X']\n",
    "        total = sum(values)\n",
    "        multiplier = int(any(c[1] == 'X' for c in cards))\n",
    "        count = len(cards)\n",
    "        player_exped.extend([total, multiplier, count])\n",
    "\n",
    "    # Discard piles (6)\n",
    "    discard_info = []\n",
    "    for color in COLORS:\n",
    "        pile = state['center'][color]\n",
    "        top_card = pile[-1][1] if pile else '0'\n",
    "        top = int(top_card) if top_card != 'X' else 0\n",
    "        # top = int(pile[-1][1]) if pile else 0\n",
    "        count = len(pile)\n",
    "        discard_info.extend([top, count])\n",
    "\n",
    "    # Opponent expeditions (9 features)\n",
    "    opp_exped = []\n",
    "    for color in COLORS:\n",
    "        cards = state['expeditions'][other_player].get(color, [])\n",
    "        values = [int(c[1]) for c in cards if c[1] != 'X']\n",
    "        total = sum(values)\n",
    "        multiplier = int(any(c[1] == 'X' for c in cards))\n",
    "        count = len(cards)\n",
    "        opp_exped.extend([total, multiplier, count])\n",
    "\n",
    "    # Deck size (1)\n",
    "    deck_norm = state['deck_size'] / card_cnt\n",
    "\n",
    "    return np.concatenate([hand_counts, player_exped, discard_info, opp_exped, [deck_norm]])\n",
    "\n",
    "def summarize_rule_firings():\n",
    "    return pprint.pformat(dict(rule_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab7a697-41e3-4970-b655-8176a10f95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor-Critic Network\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, draw_size):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 96) # 1=64\n",
    "        self.fc2 = nn.Linear(96, 32)         # 1=32\n",
    "        self.dropout = nn.Dropout(p=0.15)    # 1=0.05\n",
    "\n",
    "        # super(ActorCritic, self).__init__()\n",
    "        # self.fc1 = nn.Linear(state_size, 64)\n",
    "        # # self.fc2 = nn.Linear(64, 32)\n",
    "        # # self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Two separate policy heads\n",
    "        self.policy_action_head = nn.Linear(32, action_size)\n",
    "        self.policy_draw_head = nn.Linear(32, draw_size)\n",
    "        # self.policy_action_head = nn.Linear(64, action_size)\n",
    "        # self.policy_draw_head = nn.Linear(64, draw_size)\n",
    "\n",
    "        # Single value head\n",
    "        self.value_head = nn.Linear(32, 1)\n",
    "        # self.value_head = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        policy_action_logits = self.policy_action_head(x)\n",
    "        policy_draw_logits = self.policy_draw_head(x)\n",
    "        value = self.value_head(x)\n",
    "\n",
    "        return policy_action_logits, policy_draw_logits, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e364be26-004f-4524-aa68-b044bbb691da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_step_reward(state, action, draw_choice, env):\n",
    "    # Setup\n",
    "    step_reward = 0.0\n",
    "    max_reward = 2.0\n",
    "    player_hand = state['hands'][state['current_player']]\n",
    "    is_expedition = action[0] == 'expedition'\n",
    "    is_number_card = action[1][1] != 'X'\n",
    "    played_color = action[1][0]\n",
    "    played_value = int(action[1][1]) if is_number_card else None\n",
    "    expedition_pile = env.expeditions[state['current_player']][played_color]\n",
    "    existing_numbers = [int(c[1]) for c in expedition_pile if c[1] != 'X']\n",
    "    deck_remaining = state['deck_size']\n",
    "   \n",
    "    # Bad Move 1: Playing high card when holding lower card\n",
    "    same_color_cards = [c for c in player_hand if c[0] == action[1][0] and c[1] != 'X']\n",
    "    if same_color_cards and action[0] == 'expedition' and is_number_card:\n",
    "        min_in_hand = min([int(c[1]) for c in same_color_cards])\n",
    "        if int(action[1][1]) > min_in_hand:\n",
    "            step_reward -= 1.0\n",
    "            rule_counter[\"lower_val_avail\"] += 1\n",
    "\n",
    "    # Bad Move 2: Starting expedition with <6 points in hand\n",
    "    if is_expedition and len(env.expeditions[state['current_player']][action[1][0]]) == 0:\n",
    "        color_sum = sum([int(c[1]) for c in player_hand if c[0] == action[1][0] and c[1] != 'X'])\n",
    "        if color_sum < tgt_pts:\n",
    "            step_reward -= 0.5\n",
    "            rule_counter[\"too_few_pts\"] += 1\n",
    "\n",
    "    # Bad Move 3: Starting expedition when opponent blocks reaching 7\n",
    "    opponent = [p for p in env.players if p != state['current_player']][0]\n",
    "    opp_cards = env.expeditions[opponent].get(action[1][0], [])\n",
    "    opp_sum = sum([int(c[1]) for c in opp_cards if c[1] != 'X'])\n",
    "    hand_sum = sum([int(c[1]) for c in player_hand if c[0] == action[1][0] and c[1] != 'X'])\n",
    "    if action[0] == 'expedition' and len(env.expeditions[state['current_player']][action[1][0]]) == 0:\n",
    "        if opp_sum + hand_sum < tgt_pts:\n",
    "            step_reward -= 0.8\n",
    "            rule_counter[\"blocked_7\"] += 1\n",
    "\n",
    "    # Bad Move 4: Starting expedition with <=3 cards left\n",
    "    if is_expedition and len(env.expeditions[state['current_player']][action[1][0]]) == 0:\n",
    "        if state['deck_size'] <= 3:\n",
    "            step_reward -= 0.5\n",
    "            rule_counter[\"exp_small_deck\"] += 1\n",
    "\n",
    "    # Bad Move 5: Discarding to center when expedition is started and playable\n",
    "    expedition_pile = env.expeditions[state['current_player']][action[1][0]]\n",
    "    if action[0] == 'center' and expedition_pile:\n",
    "        top_val = max([int(c[1]) for c in expedition_pile if c[1] != 'X'], default=0)\n",
    "        card_val = int(action[1][1]) if action[1][1] != 'X' else None\n",
    "        if card_val is not None and card_val >= top_val:\n",
    "            step_reward -= 1.5\n",
    "            rule_counter[\"exp_was_live\"] += 1\n",
    "\n",
    "    # Good Move: Playing strong expedition (holding >=6 points)\n",
    "    if is_expedition:\n",
    "        color_sum = sum([int(c[1]) for c in player_hand if c[0] == action[1][0] and c[1] != 'X'])\n",
    "        if color_sum >= tgt_pts-1:\n",
    "            step_reward += 0.3\n",
    "            rule_counter[\"good_exp_1\"] += 1\n",
    "        if color_sum >= tgt_pts:\n",
    "            step_reward += 1.0\n",
    "            rule_counter[\"good_exp\"] += 1\n",
    "\n",
    "    # Penalty 3: Playing RX/BX/GX with no number cards in hand\n",
    "    if is_expedition and action[1][1] == 'X':\n",
    "        same_color_numbers = [c for c in player_hand if c[0] == action[1][0] and c[1] != 'X']\n",
    "        if not same_color_numbers:\n",
    "            step_reward -= 1.2\n",
    "            rule_counter[\"bad_X\"] += 1\n",
    "\n",
    "    # Penalty 4: Playing R5 while holding R2 or R3\n",
    "    if is_expedition and action[1][1] != 'X':\n",
    "        played_value = int(action[1][1])\n",
    "        lower_cards = [int(c[1]) for c in player_hand if c[0] == action[1][0] and c[1] != 'X' and int(c[1]) < played_value]\n",
    "        if lower_cards:\n",
    "            step_reward -= 0.8\n",
    "            rule_counter[\"bad_bigger_val\"] += 1\n",
    "\n",
    "    # Bonus: Excellent lowest-card play with multiple cards in hand\n",
    "    if is_expedition and is_number_card:\n",
    "        played_color = action[1][0]\n",
    "        played_value = int(action[1][1])\n",
    "        same_color_cards = [int(c[1]) for c in player_hand if c[0] == played_color and c[1] != 'X']\n",
    "        total_points_in_hand = sum(same_color_cards)\n",
    "        num_cards_in_hand = len(same_color_cards)\n",
    "        if num_cards_in_hand >= 2 and total_points_in_hand >= tgt_pts-1 and played_value <= min(same_color_cards):\n",
    "            step_reward += 1.0\n",
    "            rule_counter[\"good_low_val\"] += 1\n",
    "\n",
    "    # Good Draw Move: Drawing card to create >=8 points\n",
    "    if draw_choice in COLORS:\n",
    "        center_pile = state['center'][draw_choice]\n",
    "        if center_pile:\n",
    "            center_card = center_pile[-1]\n",
    "            if center_card[1] != 'X':\n",
    "                center_val = int(center_card[1])\n",
    "                color_cards = [int(c[1]) for c in player_hand if c[0] == draw_choice and c[1] != 'X']\n",
    "                total_points = sum(color_cards)\n",
    "                num_cards = len(color_cards)\n",
    "                if num_cards in [1, 2] and (total_points + center_val) >= 8:\n",
    "                    step_reward += 1.5\n",
    "                    rule_counter[\"draw_to_8\"] += 1\n",
    "\n",
    "    # Apply penalty: playing a number card to an empty expedition when holding the multiplier,\n",
    "    # and when the total known value in hand for this color would make the expedition profitable (7+)\n",
    "    # Bad Move 7: Playing number card before multiplier when expedition is empty and enough points exist\n",
    "    if is_expedition and is_number_card:\n",
    "        played_color = action[1][0]\n",
    "        expedition_pile = env.expeditions[state['current_player']][played_color]\n",
    "        \n",
    "        # Check if expedition is empty\n",
    "        if not expedition_pile:\n",
    "            # Get all cards in hand for this color\n",
    "            color_cards_in_hand = [c for c in player_hand if c[0] == played_color]\n",
    "            number_points = sum(int(c[1]) for c in color_cards_in_hand if c[1] != 'X')\n",
    "            has_multiplier = any(c[1] == 'X' for c in color_cards_in_hand)\n",
    "            \n",
    "            if has_multiplier and number_points >= tgt_pts and state['deck_size'] >= 5:\n",
    "                # Player should have played the multiplier first!\n",
    "                step_reward -= 2.0  # penalty can be adjusted\n",
    "                rule_counter[\"had_X\"] += 1\n",
    "\n",
    "    # This is captured above as too_few_pts\n",
    "    # # Penalty: Starting a new expedition with less than 7 points in hand\n",
    "    # if is_expedition:\n",
    "    #     color = action[1][0]\n",
    "    #     expedition_pile = env.expeditions[state['current_player']][color]\n",
    "    #     if not expedition_pile:  # Starting new expedition\n",
    "    #         # color_points = sum(int(c[1]) for c in player_hand if c[0] == color and c[1] in '23456')\n",
    "    #         color_points = sum(int(c[1]) for c in player_hand if c[0] == color and c[1] != 'X')\n",
    "    #         if color_points < tgt_pts:\n",
    "    #             # print(f\"Penalty triggered: starting {color} expedition with {color_points} points in hand.\")\n",
    "    #             step_reward -= 1.333\n",
    "    #             rule_counter[\"less_7\"] += 1\n",
    "                \n",
    "    # Bonus: Playing the immediate next card in sequence (no gaps)\n",
    "    if is_expedition and is_number_card:\n",
    "        played_color = action[1][0]\n",
    "        played_value = int(action[1][1])\n",
    "    \n",
    "        expedition_pile = env.expeditions[state['current_player']][played_color]\n",
    "        existing_numbers = [int(c[1]) for c in expedition_pile if c[1] != 'X']\n",
    "    \n",
    "        if existing_numbers:\n",
    "            top_value = max(existing_numbers)\n",
    "            if played_value == top_value + 1:\n",
    "                step_reward += 0.3\n",
    "                rule_counter[\"next_value\"] += 1\n",
    "                if random.random() < 1e-8:\n",
    "                    print(f\"Reward playing next value card {action} on {played_color}{top_value}\")\n",
    "\n",
    "    # ❌ Bad Move: Discarding card of color with strong expedition potential and enough deck remaining\n",
    "    if action[0] == 'center' and deck_remaining>=5:\n",
    "        color = action[1][0]\n",
    "        if not env.expeditions[state['current_player']][color]:  # expedition not started\n",
    "            color_values = [int(c[1]) for c in player_hand if c[0] == color and c[1] != 'X']\n",
    "            color_sum = sum(color_values)\n",
    "            if color_sum >= tgt_pts:\n",
    "                step_reward -= 1.25  # Adjust weight if needed\n",
    "                rule_counter[\"bad_center\"] += 1\n",
    "                if random.random() < 1e-4:\n",
    "                    print(f\"Bad center {action} holding {player_hand}\")\n",
    "\n",
    "    # Reward a smart discard of a value less than the top card on the opp exp pile\n",
    "    if action[0] == 'center':\n",
    "        color = action[1][0]\n",
    "        card_val = int(action[1][1]) if action[1][1] != 'X' else None\n",
    "        opp_pile = env.expeditions[opponent].get(color, [])\n",
    "        opp_vals = [int(c[1]) for c in opp_pile if c[1] != 'X']\n",
    "        if card_val is not None and any(v > card_val for v in opp_vals):\n",
    "            step_reward += 0.5\n",
    "            rule_counter[\"smart_opp_center\"] += 1\n",
    "            if random.random() < 1e-4:\n",
    "                print(f\"Smart center play {action} with opp exp {opp_pile}\")\n",
    "\n",
    "    # This is flawed\n",
    "    # # ✅ Bonus: Closing out expedition – playing highest remaining card in sequence\n",
    "    # if is_expedition and is_number_card:\n",
    "    #     color = played_color\n",
    "    #     value = played_value\n",
    "    #     # What values of this color are still in hand after this play?\n",
    "    #     hand_vals = [int(c[1]) for c in player_hand if c[0] == color and c[1] != 'X']\n",
    "    #     # What’s on the board?\n",
    "    #     expedition_vals = [int(c[1]) for c in expedition_pile if c[1] != 'X']\n",
    "        \n",
    "    #     if hand_vals:\n",
    "    #         # If this is the max of hand + board, and all other cards are already played\n",
    "    #         max_val = max(hand_vals + expedition_vals + [value])\n",
    "    #         if value == max_val and not any(v > value for v in hand_vals):\n",
    "    #             step_reward += 0.25\n",
    "    #             # rule_counter[\"CloseOutExpedition\"] += 1\n",
    "    #             if random.random() < 1e-1:\n",
    "    #                 print(f\"Close out {action} holding {player_hand} on {env.expeditions[state['current_player']][color]}\")\n",
    "\n",
    "    if step_reward>max_reward:\n",
    "        step_reward=max_reward\n",
    "        \n",
    "    return step_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c1d284-41ab-42ae-945b-c7ea70d062bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200, Average Reward Last 400: -2.39, eps=0.3486\n",
      "Episode 400, Average Reward Last 800: -2.08, eps=0.3472\n",
      "Episode 600, Average Reward Last 1000: -2.11, eps=0.3459\n",
      "Episode 800, Average Reward Last 1000: -2.19, eps=0.3445\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 5192\n",
      "too_few_pts                   : 4310\n",
      "good_exp                      : 3120\n",
      "blocked_7                     : 2848\n",
      "good_low_val                  : 2489\n",
      "smart_opp_center              : 2319\n",
      "next_value                    : 2016\n",
      "draw_to_8                     : 1816\n",
      "bad_center                    : 1231\n",
      "lower_val_avail               : 793\n",
      "bad_bigger_val                : 793\n",
      "exp_small_deck                : 612\n",
      "bad_X                         : 603\n",
      "exp_was_live                  : 523\n",
      "had_X                         : 33\n",
      "Episode 1000, Average Reward Last 1000: -2.24, eps=0.3432\n",
      "Episode 1200, Average Reward Last 1000: -2.13, eps=0.3419\n",
      "Episode 1400, Average Reward Last 1000: -2.13, eps=0.3406\n",
      "Episode 1600, Average Reward Last 1000: -2.09, eps=0.3392\n",
      "Episode 1800, Average Reward Last 1000: -2.08, eps=0.3379\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 10383\n",
      "too_few_pts                   : 8643\n",
      "good_exp                      : 6250\n",
      "blocked_7                     : 5696\n",
      "good_low_val                  : 4952\n",
      "smart_opp_center              : 4661\n",
      "next_value                    : 4032\n",
      "draw_to_8                     : 3600\n",
      "bad_center                    : 2422\n",
      "lower_val_avail               : 1611\n",
      "bad_bigger_val                : 1611\n",
      "bad_X                         : 1266\n",
      "exp_small_deck                : 1262\n",
      "exp_was_live                  : 1078\n",
      "had_X                         : 67\n",
      "Episode 2000, Average Reward Last 1000: -1.99, eps=0.3366\n",
      "Episode 2200, Average Reward Last 1000: -2.13, eps=0.3353\n",
      "Episode 2400, Average Reward Last 1000: -2.25, eps=0.3339\n",
      "Episode 2600, Average Reward Last 1000: -2.33, eps=0.3326\n",
      "Episode 2800, Average Reward Last 1000: -2.30, eps=0.3313\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 15520\n",
      "too_few_pts                   : 12976\n",
      "good_exp                      : 9348\n",
      "blocked_7                     : 8546\n",
      "good_low_val                  : 7403\n",
      "smart_opp_center              : 7219\n",
      "next_value                    : 6008\n",
      "draw_to_8                     : 5510\n",
      "bad_center                    : 3668\n",
      "lower_val_avail               : 2444\n",
      "bad_bigger_val                : 2444\n",
      "bad_X                         : 1945\n",
      "exp_small_deck                : 1849\n",
      "exp_was_live                  : 1615\n",
      "had_X                         : 100\n",
      "Episode 3000, Average Reward Last 1000: -2.37, eps=0.3299\n",
      "Episode 3200, Average Reward Last 1000: -2.34, eps=0.3286\n",
      "Episode 3400, Average Reward Last 1000: -2.33, eps=0.3273\n",
      "Episode 3600, Average Reward Last 1000: -2.31, eps=0.3260\n",
      "Smart center play ('center', 'B3') with opp exp ['B2', 'B4']\n",
      "Episode 3800, Average Reward Last 1000: -2.38, eps=0.3247\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 20698\n",
      "too_few_pts                   : 17282\n",
      "good_exp                      : 12482\n",
      "blocked_7                     : 11397\n",
      "good_low_val                  : 9863\n",
      "smart_opp_center              : 9700\n",
      "next_value                    : 7976\n",
      "draw_to_8                     : 7415\n",
      "bad_center                    : 4893\n",
      "lower_val_avail               : 3277\n",
      "bad_bigger_val                : 3277\n",
      "bad_X                         : 2619\n",
      "exp_small_deck                : 2486\n",
      "exp_was_live                  : 2177\n",
      "had_X                         : 133\n",
      "Episode 4000, Average Reward Last 1000: -2.38, eps=0.3234\n",
      "Episode 4200, Average Reward Last 1000: -2.28, eps=0.3221\n",
      "Episode 4400, Average Reward Last 1000: -2.27, eps=0.3208\n",
      "Episode 4600, Average Reward Last 1000: -2.34, eps=0.3195\n",
      "P1 1 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * -12 + -0.2 = -0.2\n",
      "P1 4 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -12 + -1.5 = -1.5\n",
      "P1 6 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * -12 + -1.3 = -1.3\n",
      "P1 9 - 0.0 * -12 + 0.5 = 0.5\n",
      "P1 10 - 0.0 * -12 + -2.8 = -2.8\n",
      "Episode 4800, Average Reward Last 1000: -2.38, eps=0.3183\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 25861\n",
      "too_few_pts                   : 21495\n",
      "good_exp                      : 15601\n",
      "blocked_7                     : 14182\n",
      "good_low_val                  : 12263\n",
      "smart_opp_center              : 12163\n",
      "next_value                    : 9933\n",
      "draw_to_8                     : 9361\n",
      "bad_center                    : 6085\n",
      "lower_val_avail               : 4141\n",
      "bad_bigger_val                : 4141\n",
      "bad_X                         : 3298\n",
      "exp_small_deck                : 3139\n",
      "exp_was_live                  : 2716\n",
      "had_X                         : 167\n",
      "Episode 5000, Average Reward Last 1000: -2.38, eps=0.3170\n",
      "Episode 5200, Average Reward Last 1000: -2.42, eps=0.3157\n",
      "Episode 5400, Average Reward Last 1000: -2.53, eps=0.3145\n",
      "Episode 5600, Average Reward Last 1000: -2.48, eps=0.3133\n",
      "P1 1 - 0.0 * -6 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -6 + -1.3 = -1.3\n",
      "P1 3 - 0.0 * -6 + -1.3 = -1.3\n",
      "P1 4 - 0.0 * -6 + -0.5 = -0.5\n",
      "P1 5 - 0.0 * -6 + 0.3 = 0.3\n",
      "P1 6 - 0.0 * -6 + -1.0 = -1.0\n",
      "P1 7 - 0.0 * -6 + -0.5 = -0.5\n",
      "P1 1 - 0.0 * 14 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 14 + -0.5 = -0.5\n",
      "P1 3 - 0.0 * 14 + -2.5 = -2.5\n",
      "P1 4 - 0.0 * 14 + 2.0 = 2.0\n",
      "P1 5 - 0.0 * 14 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * 14 + 2.0 = 2.0\n",
      "P1 7 - 0.0 * 14 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * 14 + 1.0 = 1.0\n",
      "P1 9 - 0.0 * 14 + -0.5 = -0.5\n",
      "P1 10 - 0.0 * 14 + 0.3 = 0.3\n",
      "Episode 5800, Average Reward Last 1000: -2.35, eps=0.3120\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 31100\n",
      "too_few_pts                   : 25765\n",
      "good_exp                      : 18793\n",
      "blocked_7                     : 17000\n",
      "good_low_val                  : 14804\n",
      "smart_opp_center              : 14557\n",
      "next_value                    : 11974\n",
      "draw_to_8                     : 11311\n",
      "bad_center                    : 7280\n",
      "lower_val_avail               : 4975\n",
      "bad_bigger_val                : 4975\n",
      "bad_X                         : 4030\n",
      "exp_small_deck                : 3788\n",
      "exp_was_live                  : 3212\n",
      "had_X                         : 209\n",
      "Episode 6000, Average Reward Last 1000: -2.36, eps=0.3108\n",
      "Bad center ('center', 'G6') holding ['B4', 'G4', 'G6']\n",
      "Episode 6200, Average Reward Last 1000: -2.35, eps=0.3095\n",
      "Episode 6400, Average Reward Last 1000: -2.14, eps=0.3083\n",
      "Episode 6600, Average Reward Last 1000: -2.10, eps=0.3070\n",
      "Episode 6800, Average Reward Last 1000: -2.10, eps=0.3058\n",
      "P1 1 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 4 + 2.0 = 2.0\n",
      "P1 4 - 0.0 * 4 + 1.8 = 1.8\n",
      "P1 5 - 0.0 * 4 + 2.0 = 2.0\n",
      "P1 6 - 0.0 * 4 + -0.5 = -0.5\n",
      "P1 7 - 0.0 * 4 + 0.3 = 0.3\n",
      "P1 8 - 0.0 * 4 + 0.3 = 0.3\n",
      "P1 9 - 0.0 * 4 + 0.0 = 0.0\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 36390\n",
      "too_few_pts                   : 29986\n",
      "good_exp                      : 22041\n",
      "blocked_7                     : 19775\n",
      "good_low_val                  : 17356\n",
      "smart_opp_center              : 16968\n",
      "next_value                    : 14113\n",
      "draw_to_8                     : 13284\n",
      "bad_center                    : 8519\n",
      "lower_val_avail               : 5841\n",
      "bad_bigger_val                : 5841\n",
      "bad_X                         : 4746\n",
      "exp_small_deck                : 4455\n",
      "exp_was_live                  : 3700\n",
      "had_X                         : 242\n",
      "Episode 7000, Average Reward Last 1000: -2.00, eps=0.3045\n",
      "Episode 7200, Average Reward Last 1000: -1.94, eps=0.3033\n",
      "Episode 7400, Average Reward Last 1000: -2.03, eps=0.3021\n",
      "Smart center play ('center', 'R4') with opp exp ['R5']\n",
      "Episode 7600, Average Reward Last 1000: -1.98, eps=0.3009\n",
      "P1 1 - 0.0 * -12 + -1.3 = -1.3\n",
      "P1 2 - 0.0 * -12 + -2.5 = -2.5\n",
      "P1 3 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * -12 + -0.5 = -0.5\n",
      "P1 5 - 0.0 * -12 + 0.5 = 0.5\n",
      "P1 6 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * -12 + 0.5 = 0.5\n",
      "P1 9 - 0.0 * -12 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * -12 + 0.5 = 0.5\n",
      "Episode 7800, Average Reward Last 1000: -2.02, eps=0.2997\n",
      "Bad center ('center', 'R4') holding ['G2', 'R4', 'R5']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 41674\n",
      "too_few_pts                   : 34195\n",
      "good_exp                      : 25350\n",
      "blocked_7                     : 22505\n",
      "good_low_val                  : 19941\n",
      "smart_opp_center              : 19342\n",
      "next_value                    : 16235\n",
      "draw_to_8                     : 15196\n",
      "bad_center                    : 9740\n",
      "lower_val_avail               : 6696\n",
      "bad_bigger_val                : 6696\n",
      "bad_X                         : 5480\n",
      "exp_small_deck                : 5114\n",
      "exp_was_live                  : 4208\n",
      "had_X                         : 275\n",
      "Episode 8000, Average Reward Last 1000: -2.03, eps=0.2985\n",
      "Episode 8200, Average Reward Last 1000: -2.01, eps=0.2973\n",
      "P1 1 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 5 - 0.0 * 6 + 2.0 = 2.0\n",
      "P1 6 - 0.0 * 6 + -1.3 = -1.3\n",
      "P1 7 - 0.0 * 6 + 0.3 = 0.3\n",
      "P1 8 - 0.0 * 6 + -0.5 = -0.5\n",
      "P1 9 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 10 - 0.0 * 6 + -0.2 = -0.2\n",
      "P1 11 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 13 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 6 + 0.0 = 0.0\n",
      "Episode 8400, Average Reward Last 1000: -1.78, eps=0.2961\n",
      "P1 1 - 0.0 * -14 + -1.3 = -1.3\n",
      "P1 2 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * -14 + -1.0 = -1.0\n",
      "P1 4 - 0.0 * -14 + -2.5 = -2.5\n",
      "P1 5 - 0.0 * -14 + -1.5 = -1.5\n",
      "P1 6 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -14 + 0.5 = 0.5\n",
      "P1 8 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -14 + 0.3 = 0.3\n",
      "P1 10 - 0.0 * -14 + 0.5 = 0.5\n",
      "Episode 8600, Average Reward Last 1000: -1.75, eps=0.2949\n",
      "Episode 8800, Average Reward Last 1000: -1.56, eps=0.2938\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 47098\n",
      "too_few_pts                   : 38313\n",
      "good_exp                      : 28754\n",
      "blocked_7                     : 25161\n",
      "good_low_val                  : 22684\n",
      "smart_opp_center              : 21550\n",
      "next_value                    : 18527\n",
      "draw_to_8                     : 16969\n",
      "bad_center                    : 10845\n",
      "lower_val_avail               : 7518\n",
      "bad_bigger_val                : 7518\n",
      "bad_X                         : 6127\n",
      "exp_small_deck                : 5709\n",
      "exp_was_live                  : 4618\n",
      "had_X                         : 317\n",
      "Episode 9000, Average Reward Last 1000: -1.38, eps=0.2926\n",
      "P1 1 - 0.0 * 0 + -1.3 = -1.3\n",
      "P1 2 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 3 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 6 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 8 - 0.0 * 0 + -1.3 = -1.3\n",
      "P1 9 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * 0 + 0.0 = 0.0\n",
      "Episode 9200, Average Reward Last 1000: -1.43, eps=0.2914\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "Episode 9400, Average Reward Last 1000: -1.55, eps=0.2903\n",
      "Episode 9600, Average Reward Last 1000: -1.32, eps=0.2891\n",
      "Episode 9800, Average Reward Last 1000: -1.13, eps=0.2879\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 52621\n",
      "too_few_pts                   : 42363\n",
      "good_exp                      : 32219\n",
      "blocked_7                     : 27709\n",
      "good_low_val                  : 25507\n",
      "smart_opp_center              : 23790\n",
      "next_value                    : 20844\n",
      "draw_to_8                     : 18828\n",
      "bad_center                    : 12013\n",
      "lower_val_avail               : 8344\n",
      "bad_bigger_val                : 8344\n",
      "bad_X                         : 6745\n",
      "exp_small_deck                : 6304\n",
      "exp_was_live                  : 4979\n",
      "had_X                         : 360\n",
      "Episode 10000, Average Reward Last 1000: -1.08, eps=0.2868\n",
      "Episode 10200, Average Reward Last 1000: -0.89, eps=0.2856\n",
      "Episode 10400, Average Reward Last 1000: -1.09, eps=0.2844\n",
      "Episode 10600, Average Reward Last 1000: -1.34, eps=0.2830\n",
      "Bad center ('center', 'R2') holding ['R2', 'R3', 'R5']\n",
      "Episode 10800, Average Reward Last 1000: -1.66, eps=0.2816\n",
      "P1 1 - 0.0 * -10 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * -10 + 1.5 = 1.5\n",
      "P1 3 - 0.0 * -10 + -1.3 = -1.3\n",
      "P1 4 - 0.0 * -10 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * -10 + 0.3 = 0.3\n",
      "P1 6 - 0.0 * -10 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * -10 + 1.3 = 1.3\n",
      "P1 8 - 0.0 * -10 + -1.5 = -1.5\n",
      "P1 9 - 0.0 * -10 + 1.0 = 1.0\n",
      "P1 10 - 0.0 * -10 + -1.5 = -1.5\n",
      "P1 11 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * -10 + -0.2 = -0.2\n",
      "P1 13 - 0.0 * -10 + -1.5 = -1.5\n",
      "P1 14 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * -10 + 0.5 = 0.5\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 57865\n",
      "too_few_pts                   : 46465\n",
      "good_exp                      : 35509\n",
      "blocked_7                     : 30375\n",
      "good_low_val                  : 28099\n",
      "smart_opp_center              : 26532\n",
      "next_value                    : 23080\n",
      "draw_to_8                     : 21552\n",
      "bad_center                    : 13845\n",
      "lower_val_avail               : 9172\n",
      "bad_bigger_val                : 9172\n",
      "bad_X                         : 7416\n",
      "exp_small_deck                : 6981\n",
      "exp_was_live                  : 5701\n",
      "had_X                         : 404\n",
      "Episode 11000, Average Reward Last 1000: -1.89, eps=0.2802\n",
      "Episode 11200, Average Reward Last 1000: -1.96, eps=0.2788\n",
      "Episode 11400, Average Reward Last 1000: -1.86, eps=0.2775\n",
      "Episode 11600, Average Reward Last 1000: -1.90, eps=0.2763\n",
      "Episode 11800, Average Reward Last 1000: -1.85, eps=0.2750\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 63246\n",
      "too_few_pts                   : 50566\n",
      "good_exp                      : 38856\n",
      "blocked_7                     : 33056\n",
      "good_low_val                  : 30801\n",
      "smart_opp_center              : 29455\n",
      "next_value                    : 25294\n",
      "draw_to_8                     : 24243\n",
      "bad_center                    : 15659\n",
      "lower_val_avail               : 10001\n",
      "bad_bigger_val                : 10001\n",
      "bad_X                         : 8074\n",
      "exp_small_deck                : 7669\n",
      "exp_was_live                  : 6378\n",
      "had_X                         : 437\n",
      "Episode 12000, Average Reward Last 1000: -1.57, eps=0.2737\n",
      "Episode 12200, Average Reward Last 1000: -1.44, eps=0.2724\n",
      "Episode 12400, Average Reward Last 1000: -1.19, eps=0.2711\n",
      "Episode 12600, Average Reward Last 1000: -0.97, eps=0.2698\n",
      "Episode 12800, Average Reward Last 1000: -0.86, eps=0.2685\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 68726\n",
      "too_few_pts                   : 54502\n",
      "good_exp                      : 42287\n",
      "blocked_7                     : 35526\n",
      "good_low_val                  : 33587\n",
      "smart_opp_center              : 32318\n",
      "next_value                    : 27646\n",
      "draw_to_8                     : 26910\n",
      "bad_center                    : 17477\n",
      "lower_val_avail               : 10826\n",
      "bad_bigger_val                : 10826\n",
      "bad_X                         : 8677\n",
      "exp_small_deck                : 8422\n",
      "exp_was_live                  : 6976\n",
      "had_X                         : 488\n",
      "Episode 13000, Average Reward Last 1000: -1.07, eps=0.2672\n",
      "P1 1 - 0.0 * -8 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * -8 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -8 + -0.75 = -0.75\n",
      "P1 8 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * -8 + -0.75 = -0.75\n",
      "P1 12 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -8 + 0.5 = 0.5\n",
      "P1 14 - 0.0 * -8 + -0.5 = -0.5\n",
      "P1 15 - 0.0 * -8 + 2.0 = 2.0\n",
      "P1 16 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * -8 + -0.30000000000000004 = -0.30000000000000004\n",
      "P1 19 - 0.0 * -8 + 0.5 = 0.5\n",
      "P1 20 - 0.0 * -8 + 0.5 = 0.5\n",
      "P1 21 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * -8 + 1.5 = 1.5\n",
      "P1 25 - 0.0 * -8 + 2.0 = 2.0\n",
      "P1 26 - 0.0 * -8 + 0.3 = 0.3\n",
      "Episode 13200, Average Reward Last 1000: -1.64, eps=0.2654\n",
      "Episode 13400, Average Reward Last 1000: -2.07, eps=0.2639\n",
      "Smart center play ('center', 'G3') with opp exp ['G5', 'G6']\n",
      "Episode 13600, Average Reward Last 1000: -2.45, eps=0.2625\n",
      "Episode 13800, Average Reward Last 1000: -2.80, eps=0.2612\n",
      "P1 1 - 0.0 * -2 + 2.0 = 2.0\n",
      "P1 2 - 0.0 * -2 + -1.3 = -1.3\n",
      "P1 3 - 0.0 * -2 + 0.3 = 0.3\n",
      "P1 4 - 0.0 * -2 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -2 + 0.19999999999999996 = 0.19999999999999996\n",
      "P1 6 - 0.0 * -2 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -2 + 0.3 = 0.3\n",
      "P1 8 - 0.0 * -2 + 0.5 = 0.5\n",
      "P1 9 - 0.0 * -2 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * -2 + 0.0 = 0.0\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 73480\n",
      "too_few_pts                   : 58549\n",
      "good_exp                      : 45206\n",
      "blocked_7                     : 38289\n",
      "smart_opp_center              : 36044\n",
      "good_low_val                  : 35879\n",
      "draw_to_8                     : 30729\n",
      "next_value                    : 29658\n",
      "bad_center                    : 20108\n",
      "lower_val_avail               : 11630\n",
      "bad_bigger_val                : 11630\n",
      "bad_X                         : 9496\n",
      "exp_small_deck                : 9255\n",
      "exp_was_live                  : 8144\n",
      "had_X                         : 508\n",
      "Episode 14000, Average Reward Last 1000: -3.05, eps=0.2599\n",
      "Episode 14200, Average Reward Last 1000: -2.81, eps=0.2583\n",
      "Episode 14400, Average Reward Last 1000: -2.82, eps=0.2568\n",
      "Smart center play ('center', 'B2') with opp exp ['B4', 'B5', 'B6']\n",
      "Episode 14600, Average Reward Last 1000: -2.93, eps=0.2554\n",
      "Episode 14800, Average Reward Last 1000: -2.92, eps=0.2541\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 78288\n",
      "too_few_pts                   : 62595\n",
      "good_exp                      : 48167\n",
      "blocked_7                     : 41054\n",
      "smart_opp_center              : 40054\n",
      "good_low_val                  : 38112\n",
      "draw_to_8                     : 35019\n",
      "next_value                    : 31621\n",
      "bad_center                    : 22945\n",
      "lower_val_avail               : 12505\n",
      "bad_bigger_val                : 12505\n",
      "bad_X                         : 10256\n",
      "exp_small_deck                : 10102\n",
      "exp_was_live                  : 9637\n",
      "had_X                         : 528\n",
      "Episode 15000, Average Reward Last 1000: -3.11, eps=0.2524\n",
      "Episode 15200, Average Reward Last 1000: -3.35, eps=0.2507\n",
      "Episode 15400, Average Reward Last 1000: -3.41, eps=0.2487\n",
      "Episode 15600, Average Reward Last 1000: -3.38, eps=0.2471\n",
      "Episode 15800, Average Reward Last 1000: -3.43, eps=0.2457\n",
      "Smart center play ('center', 'B2') with opp exp ['B5']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 82859\n",
      "too_few_pts                   : 66557\n",
      "good_exp                      : 50974\n",
      "smart_opp_center              : 44476\n",
      "blocked_7                     : 43825\n",
      "good_low_val                  : 40215\n",
      "draw_to_8                     : 40202\n",
      "next_value                    : 33586\n",
      "bad_center                    : 26642\n",
      "lower_val_avail               : 13334\n",
      "bad_bigger_val                : 13334\n",
      "exp_was_live                  : 11555\n",
      "exp_small_deck                : 10974\n",
      "bad_X                         : 10969\n",
      "had_X                         : 547\n",
      "Episode 16000, Average Reward Last 1000: -3.24, eps=0.2444\n",
      "Bad center ('center', 'G6') holding ['B5', 'G2', 'G6']\n",
      "Episode 16200, Average Reward Last 1000: -3.16, eps=0.2432\n",
      "Episode 16400, Average Reward Last 1000: -3.09, eps=0.2420\n",
      "Smart center play ('center', 'G3') with opp exp ['G5']\n",
      "Episode 16600, Average Reward Last 1000: -3.00, eps=0.2406\n",
      "P1 1 - 0.0 * 5 + 2.0 = 2.0\n",
      "P1 2 - 0.0 * 5 + -0.5 = -0.5\n",
      "P1 3 - 0.0 * 5 + -1.0 = -1.0\n",
      "P1 4 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * 5 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * 5 + 0.5 = 0.5\n",
      "P1 9 - 0.0 * 5 + 0.6 = 0.6\n",
      "P1 10 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 14 - 0.0 * 5 + -1.0 = -1.0\n",
      "P1 15 - 0.0 * 5 + 0.0 = 0.0\n",
      "Smart center play ('center', 'G2') with opp exp ['G4']\n",
      "Episode 16800, Average Reward Last 1000: -3.01, eps=0.2392\n",
      "Smart center play ('center', 'B2') with opp exp ['B5']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 87605\n",
      "too_few_pts                   : 70568\n",
      "good_exp                      : 53913\n",
      "smart_opp_center              : 48538\n",
      "blocked_7                     : 46569\n",
      "draw_to_8                     : 44294\n",
      "good_low_val                  : 42368\n",
      "next_value                    : 35489\n",
      "bad_center                    : 29380\n",
      "lower_val_avail               : 14226\n",
      "bad_bigger_val                : 14226\n",
      "exp_was_live                  : 12926\n",
      "exp_small_deck                : 11841\n",
      "bad_X                         : 11728\n",
      "had_X                         : 568\n",
      "Episode 17000, Average Reward Last 1000: -3.04, eps=0.2376\n",
      "Episode 17200, Average Reward Last 1000: -3.01, eps=0.2359\n",
      "Episode 17400, Average Reward Last 1000: -3.11, eps=0.2342\n",
      "Episode 17600, Average Reward Last 1000: -2.97, eps=0.2326\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "P1 1 - 0.0 * 5 + -1.0 = -1.0\n",
      "P1 2 - 0.0 * 5 + 2.0 = 2.0\n",
      "P1 3 - 0.0 * 5 + -1.5 = -1.5\n",
      "P1 4 - 0.0 * 5 + -0.5 = -0.5\n",
      "P1 5 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * 5 + -1.5 = -1.5\n",
      "P1 7 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 8 - 0.0 * 5 + 0.5 = 0.5\n",
      "P1 9 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * 5 + 2.0 = 2.0\n",
      "Episode 17800, Average Reward Last 1000: -2.83, eps=0.2310\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 92282\n",
      "too_few_pts                   : 74404\n",
      "good_exp                      : 56862\n",
      "smart_opp_center              : 53385\n",
      "draw_to_8                     : 49911\n",
      "blocked_7                     : 49261\n",
      "good_low_val                  : 44646\n",
      "next_value                    : 37541\n",
      "bad_center                    : 33360\n",
      "lower_val_avail               : 15028\n",
      "bad_bigger_val                : 15028\n",
      "exp_was_live                  : 14855\n",
      "exp_small_deck                : 12746\n",
      "bad_X                         : 12500\n",
      "had_X                         : 590\n",
      "Episode 18000, Average Reward Last 1000: -2.87, eps=0.2294\n",
      "Episode 18200, Average Reward Last 1000: -2.75, eps=0.2277\n",
      "Smart center play ('center', 'G3') with opp exp ['G5']\n",
      "Episode 18400, Average Reward Last 1000: -2.42, eps=0.2259\n",
      "Episode 18600, Average Reward Last 1000: -2.48, eps=0.2243\n",
      "Episode 18800, Average Reward Last 1000: -2.56, eps=0.2228\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 97040\n",
      "too_few_pts                   : 78239\n",
      "good_exp                      : 59847\n",
      "smart_opp_center              : 58186\n",
      "draw_to_8                     : 55380\n",
      "blocked_7                     : 51883\n",
      "good_low_val                  : 46929\n",
      "next_value                    : 39727\n",
      "bad_center                    : 37452\n",
      "exp_was_live                  : 16491\n",
      "lower_val_avail               : 15836\n",
      "bad_bigger_val                : 15836\n",
      "exp_small_deck                : 13647\n",
      "bad_X                         : 13168\n",
      "had_X                         : 625\n",
      "Episode 19000, Average Reward Last 1000: -2.21, eps=0.2214\n",
      "Episode 19200, Average Reward Last 1000: -1.88, eps=0.2202\n",
      "Episode 19400, Average Reward Last 1000: -1.65, eps=0.2189\n",
      "P1 1 - 0.0 * 16 + -2.5 = -2.5\n",
      "P1 2 - 0.0 * 16 + -1.3 = -1.3\n",
      "P1 3 - 0.0 * 16 + -1.5 = -1.5\n",
      "P1 4 - 0.0 * 16 + -1.5 = -1.5\n",
      "P1 5 - 0.0 * 16 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 16 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * 16 + -1.3 = -1.3\n",
      "P1 8 - 0.0 * 16 + 2.0 = 2.0\n",
      "P1 9 - 0.0 * 16 + 0.3 = 0.3\n",
      "P1 10 - 0.0 * 16 + 1.8 = 1.8\n",
      "P1 11 - 0.0 * 16 + 1.8 = 1.8\n",
      "P1 12 - 0.0 * 16 + -0.2 = -0.2\n",
      "Episode 19600, Average Reward Last 1000: -1.38, eps=0.2175\n",
      "Episode 19800, Average Reward Last 1000: -0.87, eps=0.2160\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 102320\n",
      "too_few_pts                   : 81873\n",
      "good_exp                      : 63241\n",
      "smart_opp_center              : 62139\n",
      "draw_to_8                     : 59901\n",
      "blocked_7                     : 54310\n",
      "good_low_val                  : 49630\n",
      "next_value                    : 42142\n",
      "bad_center                    : 40797\n",
      "exp_was_live                  : 17545\n",
      "lower_val_avail               : 16670\n",
      "bad_bigger_val                : 16670\n",
      "exp_small_deck                : 14455\n",
      "bad_X                         : 13815\n",
      "had_X                         : 661\n",
      "Episode 20000, Average Reward Last 1000: -0.76, eps=0.2146\n",
      "Episode 20200, Average Reward Last 1000: -0.81, eps=0.2131\n",
      "Episode 20400, Average Reward Last 1000: -0.93, eps=0.2118\n",
      "Episode 20600, Average Reward Last 1000: -0.97, eps=0.2104\n",
      "Bad center ('center', 'R5') holding ['B5', 'R2', 'R5']\n",
      "Smart center play ('center', 'B2') with opp exp ['B3', 'B5']\n",
      "Episode 20800, Average Reward Last 1000: -1.18, eps=0.2090\n",
      "P1 1 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 3 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 4 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 6 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 9 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 0 + -0.75 = -0.75\n",
      "P1 11 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 12 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 13 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 14 - 0.0 * 0 + -0.75 = -0.75\n",
      "P1 15 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 16 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 18 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 19 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 21 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 22 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * 0 + 0.5 = 0.5\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 107455\n",
      "too_few_pts                   : 85639\n",
      "good_exp                      : 66528\n",
      "smart_opp_center              : 66435\n",
      "draw_to_8                     : 64491\n",
      "blocked_7                     : 56857\n",
      "good_low_val                  : 52207\n",
      "next_value                    : 44457\n",
      "bad_center                    : 44263\n",
      "exp_was_live                  : 18643\n",
      "lower_val_avail               : 17548\n",
      "bad_bigger_val                : 17548\n",
      "exp_small_deck                : 15292\n",
      "bad_X                         : 14538\n",
      "had_X                         : 681\n",
      "Episode 21000, Average Reward Last 1000: -1.30, eps=0.2078\n",
      "Episode 21200, Average Reward Last 1000: -1.41, eps=0.2066\n",
      "Episode 21400, Average Reward Last 1000: -1.50, eps=0.2051\n",
      "Episode 21600, Average Reward Last 1000: -1.57, eps=0.2036\n",
      "P1 1 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 3 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -14 + -1.0 = -1.0\n",
      "P1 8 - 0.0 * -14 + 0.5 = 0.5\n",
      "P1 9 - 0.0 * -14 + -1.5 = -1.5\n",
      "P1 10 - 0.0 * -14 + 2.0 = 2.0\n",
      "P1 11 - 0.0 * -14 + -1.0 = -1.0\n",
      "P1 12 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -14 + -1.0 = -1.0\n",
      "P1 14 - 0.0 * -14 + 0.5 = 0.5\n",
      "P1 15 - 0.0 * -14 + -1.0 = -1.0\n",
      "Episode 21800, Average Reward Last 1000: -1.67, eps=0.2021\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 112384\n",
      "too_few_pts                   : 89363\n",
      "smart_opp_center              : 71307\n",
      "draw_to_8                     : 69895\n",
      "good_exp                      : 69624\n",
      "blocked_7                     : 59402\n",
      "good_low_val                  : 54572\n",
      "bad_center                    : 48122\n",
      "next_value                    : 46633\n",
      "exp_was_live                  : 20242\n",
      "lower_val_avail               : 18434\n",
      "bad_bigger_val                : 18434\n",
      "exp_small_deck                : 16160\n",
      "bad_X                         : 15208\n",
      "had_X                         : 706\n",
      "Episode 22000, Average Reward Last 1000: -1.82, eps=0.2005\n",
      "Episode 22200, Average Reward Last 1000: -1.64, eps=0.1991\n",
      "Bad center ('center', 'B4') holding ['B4', 'B5', 'G2']\n",
      "Episode 22400, Average Reward Last 1000: -1.40, eps=0.1976\n",
      "Smart center play ('center', 'G4') with opp exp ['G5']\n",
      "Episode 22600, Average Reward Last 1000: -1.30, eps=0.1961\n",
      "Episode 22800, Average Reward Last 1000: -1.10, eps=0.1945\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 117408\n",
      "too_few_pts                   : 92893\n",
      "smart_opp_center              : 76771\n",
      "draw_to_8                     : 76302\n",
      "good_exp                      : 72873\n",
      "blocked_7                     : 61856\n",
      "good_low_val                  : 57026\n",
      "bad_center                    : 52913\n",
      "next_value                    : 48905\n",
      "exp_was_live                  : 21876\n",
      "lower_val_avail               : 19360\n",
      "bad_bigger_val                : 19360\n",
      "exp_small_deck                : 17055\n",
      "bad_X                         : 15789\n",
      "had_X                         : 723\n",
      "Episode 23000, Average Reward Last 1000: -0.92, eps=0.1927\n",
      "Episode 23200, Average Reward Last 1000: -1.06, eps=0.1910\n",
      "P1 1 - 0.0 * 22 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * 22 + -1.25 = -1.25\n",
      "P1 3 - 0.0 * 22 + 1.5 = 1.5\n",
      "P1 4 - 0.0 * 22 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 22 + 2.0 = 2.0\n",
      "P1 6 - 0.0 * 22 + 2.0 = 2.0\n",
      "P1 7 - 0.0 * 22 + 2.0 = 2.0\n",
      "P1 8 - 0.0 * 22 + 2.0 = 2.0\n",
      "P1 9 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 22 + 1.5 = 1.5\n",
      "P1 11 - 0.0 * 22 + 2.0 = 2.0\n",
      "P1 12 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 22 + -1.8 = -1.8\n",
      "P1 15 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 22 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * 22 + 0.6 = 0.6\n",
      "P1 21 - 0.0 * 22 + 0.6 = 0.6\n",
      "P1 1 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * -1 + 0.25 = 0.25\n",
      "P1 3 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 10 - 0.0 * -1 + 0.25 = 0.25\n",
      "P1 11 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 12 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -1 + 2.0 = 2.0\n",
      "P1 14 - 0.0 * -1 + 1.3 = 1.3\n",
      "P1 15 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 19 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 21 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 23 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * -1 + -0.5 = -0.5\n",
      "P1 26 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 27 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 28 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 29 - 0.0 * -1 + 0.5 = 0.5\n",
      "Episode 23400, Average Reward Last 1000: -1.34, eps=0.1891\n",
      "Episode 23600, Average Reward Last 1000: -1.52, eps=0.1872\n",
      "Episode 23800, Average Reward Last 1000: -1.60, eps=0.1855\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 122021\n",
      "too_few_pts                   : 96377\n",
      "draw_to_8                     : 84925\n",
      "smart_opp_center              : 82954\n",
      "good_exp                      : 75906\n",
      "blocked_7                     : 64391\n",
      "good_low_val                  : 59315\n",
      "bad_center                    : 59311\n",
      "next_value                    : 51015\n",
      "exp_was_live                  : 24567\n",
      "lower_val_avail               : 20176\n",
      "bad_bigger_val                : 20176\n",
      "exp_small_deck                : 17947\n",
      "bad_X                         : 16407\n",
      "had_X                         : 770\n",
      "Episode 24000, Average Reward Last 1000: -1.77, eps=0.1836\n",
      "Episode 24200, Average Reward Last 1000: -2.14, eps=0.1815\n",
      "Episode 24400, Average Reward Last 1000: -2.10, eps=0.1796\n",
      "Bad center ('center', 'B3') holding ['B3', 'B6', 'G5']\n",
      "Episode 24600, Average Reward Last 1000: -1.98, eps=0.1776\n",
      "P1 1 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 10 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 11 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 16 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 17 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 18 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * -1 + -1.0 = -1.0\n",
      "P1 20 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 26 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 27 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 28 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 29 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 30 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 31 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 32 - 0.0 * -1 + -1.25 = -1.25\n",
      "P1 33 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 34 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 35 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 36 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 37 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 38 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 39 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 40 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 41 - 0.0 * -1 + 0.5 = 0.5\n",
      "P1 42 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 43 - 0.0 * -1 + 2.0 = 2.0\n",
      "P1 44 - 0.0 * -1 + 2.0 = 2.0\n",
      "P1 45 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 46 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 47 - 0.0 * -1 + 0.5 = 0.5\n",
      "Episode 24800, Average Reward Last 1000: -1.87, eps=0.1758\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 126598\n",
      "too_few_pts                   : 99785\n",
      "draw_to_8                     : 94684\n",
      "smart_opp_center              : 90179\n",
      "good_exp                      : 78952\n",
      "blocked_7                     : 66896\n",
      "bad_center                    : 66614\n",
      "good_low_val                  : 61576\n",
      "next_value                    : 53155\n",
      "exp_was_live                  : 27395\n",
      "lower_val_avail               : 21023\n",
      "bad_bigger_val                : 21023\n",
      "exp_small_deck                : 18882\n",
      "bad_X                         : 16970\n",
      "had_X                         : 801\n",
      "Episode 25000, Average Reward Last 1000: -1.68, eps=0.1740\n",
      "Episode 25200, Average Reward Last 1000: -1.21, eps=0.1724\n",
      "Episode 25400, Average Reward Last 1000: -0.90, eps=0.1709\n",
      "Smart center play ('center', 'R4') with opp exp ['R3', 'R5']\n",
      "Bad center ('center', 'G3') holding ['B2', 'G3', 'G4']\n",
      "Episode 25600, Average Reward Last 1000: -0.98, eps=0.1691\n",
      "Episode 25800, Average Reward Last 1000: -1.23, eps=0.1674\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 131287\n",
      "draw_to_8                     : 103415\n",
      "too_few_pts                   : 103218\n",
      "smart_opp_center              : 96652\n",
      "good_exp                      : 81958\n",
      "bad_center                    : 73374\n",
      "blocked_7                     : 69396\n",
      "good_low_val                  : 63819\n",
      "next_value                    : 55331\n",
      "exp_was_live                  : 29705\n",
      "lower_val_avail               : 21885\n",
      "bad_bigger_val                : 21885\n",
      "exp_small_deck                : 19770\n",
      "bad_X                         : 17560\n",
      "had_X                         : 834\n",
      "Episode 26000, Average Reward Last 1000: -1.28, eps=0.1657\n",
      "Episode 26200, Average Reward Last 1000: -1.33, eps=0.1641\n",
      "P1 1 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 6 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * 6 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 8 - 0.0 * 6 + -1.25 = -1.25\n",
      "P1 9 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 11 - 0.0 * 6 + 2.0 = 2.0\n",
      "P1 12 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 6 + -1.3 = -1.3\n",
      "P1 14 - 0.0 * 6 + 0.3 = 0.3\n",
      "P1 15 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 16 - 0.0 * 6 + 2.0 = 2.0\n",
      "P1 17 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * 6 + -0.5 = -0.5\n",
      "Episode 26400, Average Reward Last 1000: -1.40, eps=0.1625\n",
      "Episode 26600, Average Reward Last 1000: -1.17, eps=0.1609\n",
      "Episode 26800, Average Reward Last 1000: -1.12, eps=0.1594\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 136145\n",
      "draw_to_8                     : 111542\n",
      "too_few_pts                   : 106701\n",
      "smart_opp_center              : 103061\n",
      "good_exp                      : 85096\n",
      "bad_center                    : 79515\n",
      "blocked_7                     : 71898\n",
      "good_low_val                  : 66247\n",
      "next_value                    : 57625\n",
      "exp_was_live                  : 31900\n",
      "lower_val_avail               : 22721\n",
      "bad_bigger_val                : 22721\n",
      "exp_small_deck                : 20680\n",
      "bad_X                         : 18137\n",
      "had_X                         : 869\n",
      "Episode 27000, Average Reward Last 1000: -0.91, eps=0.1580\n",
      "Episode 27200, Average Reward Last 1000: -0.85, eps=0.1565\n",
      "Smart center play ('center', 'G3') with opp exp ['G2', 'G6']\n",
      "Episode 27400, Average Reward Last 1000: -0.80, eps=0.1549\n",
      "Bad center ('center', 'B2') holding ['B2', 'B6', 'G6']\n",
      "Episode 27600, Average Reward Last 1000: -0.88, eps=0.1534\n",
      "Episode 27800, Average Reward Last 1000: -0.70, eps=0.1519\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 140843\n",
      "draw_to_8                     : 120097\n",
      "too_few_pts                   : 110032\n",
      "smart_opp_center              : 109733\n",
      "good_exp                      : 88164\n",
      "bad_center                    : 86215\n",
      "blocked_7                     : 74333\n",
      "good_low_val                  : 68562\n",
      "next_value                    : 59935\n",
      "exp_was_live                  : 34081\n",
      "lower_val_avail               : 23563\n",
      "bad_bigger_val                : 23563\n",
      "exp_small_deck                : 21599\n",
      "bad_X                         : 18703\n",
      "had_X                         : 895\n",
      "Episode 28000, Average Reward Last 1000: -0.71, eps=0.1503\n",
      "Bad center ('center', 'G2') holding ['G2', 'G5', 'R5']\n",
      "Episode 28200, Average Reward Last 1000: -0.68, eps=0.1488\n",
      "Bad center ('center', 'R6') holding ['G3', 'R5', 'R6']\n",
      "Episode 28400, Average Reward Last 1000: -0.62, eps=0.1472\n",
      "Episode 28600, Average Reward Last 1000: -0.63, eps=0.1456\n",
      "Episode 28800, Average Reward Last 1000: -0.75, eps=0.1440\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 145589\n",
      "draw_to_8                     : 129494\n",
      "smart_opp_center              : 116993\n",
      "too_few_pts                   : 113284\n",
      "bad_center                    : 93479\n",
      "good_exp                      : 91355\n",
      "blocked_7                     : 76716\n",
      "good_low_val                  : 70938\n",
      "next_value                    : 62251\n",
      "exp_was_live                  : 36487\n",
      "lower_val_avail               : 24462\n",
      "bad_bigger_val                : 24462\n",
      "exp_small_deck                : 22416\n",
      "bad_X                         : 19225\n",
      "had_X                         : 922\n",
      "Episode 29000, Average Reward Last 1000: -0.81, eps=0.1425\n",
      "Episode 29200, Average Reward Last 1000: -0.92, eps=0.1408\n",
      "Episode 29400, Average Reward Last 1000: -1.32, eps=0.1392\n",
      "Smart center play ('center', 'B3') with opp exp ['B4', 'B5']\n",
      "Episode 29600, Average Reward Last 1000: -1.47, eps=0.1375\n",
      "Episode 29800, Average Reward Last 1000: -1.45, eps=0.1358\n",
      "Smart center play ('center', 'G2') with opp exp ['GX', 'G4']\n",
      "Smart center play ('center', 'R3') with opp exp ['R4', 'R6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 150245\n",
      "draw_to_8                     : 140443\n",
      "smart_opp_center              : 125473\n",
      "too_few_pts                   : 116582\n",
      "bad_center                    : 101325\n",
      "good_exp                      : 94454\n",
      "blocked_7                     : 79173\n",
      "good_low_val                  : 73251\n",
      "next_value                    : 64371\n",
      "exp_was_live                  : 39743\n",
      "lower_val_avail               : 25345\n",
      "bad_bigger_val                : 25345\n",
      "exp_small_deck                : 23381\n",
      "bad_X                         : 19746\n",
      "had_X                         : 952\n",
      "Episode 30000, Average Reward Last 1000: -1.47, eps=0.1342\n",
      "P1 1 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 5 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 7 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 9 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * 0 + -1.25 = -1.25\n",
      "P1 11 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 12 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 0 + 2.0 = 2.0\n",
      "P1 15 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 16 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 17 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 18 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 19 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 20 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 21 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * 0 + 1.5 = 1.5\n",
      "P1 23 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 25 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 26 - 0.0 * 0 + 0.5 = 0.5\n",
      "P1 27 - 0.0 * 0 + 0.0 = 0.0\n",
      "P1 28 - 0.0 * 0 + 0.0 = 0.0\n",
      "Smart center play ('center', 'B2') with opp exp ['B5', 'B6']\n",
      "Episode 30200, Average Reward Last 1000: -1.60, eps=0.1325\n",
      "Episode 30400, Average Reward Last 1000: -1.29, eps=0.1310\n",
      "Bad center ('center', 'G6') holding ['G5', 'G6', 'R5']\n",
      "Episode 30600, Average Reward Last 1000: -1.23, eps=0.1295\n",
      "Episode 30800, Average Reward Last 1000: -0.98, eps=0.1280\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "good_exp_1                    : 154863\n",
      "draw_to_8                     : 151087\n",
      "smart_opp_center              : 134079\n",
      "too_few_pts                   : 120003\n",
      "bad_center                    : 108972\n",
      "good_exp                      : 97463\n",
      "blocked_7                     : 81661\n",
      "good_low_val                  : 75459\n",
      "next_value                    : 66635\n",
      "exp_was_live                  : 42589\n",
      "lower_val_avail               : 26247\n",
      "bad_bigger_val                : 26247\n",
      "exp_small_deck                : 24320\n",
      "bad_X                         : 20320\n",
      "had_X                         : 984\n",
      "Episode 31000, Average Reward Last 1000: -1.05, eps=0.1264\n",
      "Episode 31200, Average Reward Last 1000: -0.96, eps=0.1250\n",
      "Episode 31400, Average Reward Last 1000: -1.09, eps=0.1236\n",
      "Bad center ('center', 'R6') holding ['R3', 'R6', 'RX']\n",
      "Bad center ('center', 'G4') holding ['BX', 'G4', 'G6']\n",
      "Episode 31600, Average Reward Last 1000: -1.05, eps=0.1221\n",
      "Smart center play ('center', 'R2') with opp exp ['R3', 'R5']\n",
      "Smart center play ('center', 'G2') with opp exp ['G4', 'G6']\n",
      "Episode 31800, Average Reward Last 1000: -1.12, eps=0.1206\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 161741\n",
      "good_exp_1                    : 159502\n",
      "smart_opp_center              : 142393\n",
      "too_few_pts                   : 123311\n",
      "bad_center                    : 116786\n",
      "good_exp                      : 100523\n",
      "blocked_7                     : 84077\n",
      "good_low_val                  : 77754\n",
      "next_value                    : 68868\n",
      "exp_was_live                  : 45559\n",
      "lower_val_avail               : 27099\n",
      "bad_bigger_val                : 27099\n",
      "exp_small_deck                : 25250\n",
      "bad_X                         : 20916\n",
      "had_X                         : 1017\n",
      "Episode 32000, Average Reward Last 1000: -1.06, eps=0.1192\n",
      "Smart center play ('center', 'R3') with opp exp ['R2', 'R5']\n",
      "Episode 32200, Average Reward Last 1000: -0.92, eps=0.1178\n",
      "Plays: 235 in episode 32328\n",
      "Episode 32400, Average Reward Last 1000: -0.75, eps=0.1164\n",
      "Episode 32600, Average Reward Last 1000: -0.74, eps=0.1151\n",
      "Episode 32800, Average Reward Last 1000: -0.84, eps=0.1137\n",
      "Bad center ('center', 'G4') holding ['B2', 'G4', 'G6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 172268\n",
      "good_exp_1                    : 164054\n",
      "smart_opp_center              : 150726\n",
      "too_few_pts                   : 126707\n",
      "bad_center                    : 124659\n",
      "good_exp                      : 103430\n",
      "blocked_7                     : 86597\n",
      "good_low_val                  : 79919\n",
      "next_value                    : 71051\n",
      "exp_was_live                  : 48454\n",
      "lower_val_avail               : 27944\n",
      "bad_bigger_val                : 27944\n",
      "exp_small_deck                : 26119\n",
      "bad_X                         : 21481\n",
      "had_X                         : 1050\n",
      "Episode 33000, Average Reward Last 1000: -0.79, eps=0.1123\n",
      "P1 1 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 3 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 4 + -1.3 = -1.3\n",
      "P1 7 - 0.0 * 4 + 1.5 = 1.5\n",
      "P1 8 - 0.0 * 4 + -1.25 = -1.25\n",
      "P1 9 - 0.0 * 4 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * 4 + 1.5 = 1.5\n",
      "P1 12 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 4 + -1.3 = -1.3\n",
      "P1 14 - 0.0 * 4 + 1.5 = 1.5\n",
      "P1 15 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 4 + 1.5 = 1.5\n",
      "P1 19 - 0.0 * 4 + -0.5 = -0.5\n",
      "P1 20 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 26 - 0.0 * 4 + 0.5 = 0.5\n",
      "P1 27 - 0.0 * 4 + 0.3 = 0.3\n",
      "P1 28 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 29 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 30 - 0.0 * 4 + 1.5 = 1.5\n",
      "P1 31 - 0.0 * 4 + 0.5 = 0.5\n",
      "P1 32 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 33 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 34 - 0.0 * 4 + 0.0 = 0.0\n",
      "P1 35 - 0.0 * 4 + 0.0 = 0.0\n",
      "Episode 33200, Average Reward Last 1000: -0.92, eps=0.1110\n",
      "Plays: 245 in episode 33224\n",
      "Episode 33400, Average Reward Last 1000: -1.18, eps=0.1096\n",
      "Episode 33600, Average Reward Last 1000: -1.24, eps=0.1082\n",
      "Bad center ('center', 'B2') holding ['B2', 'B3', 'B5']\n",
      "Episode 33800, Average Reward Last 1000: -1.28, eps=0.1068\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 183720\n",
      "good_exp_1                    : 168698\n",
      "smart_opp_center              : 159674\n",
      "bad_center                    : 132930\n",
      "too_few_pts                   : 130094\n",
      "good_exp                      : 106434\n",
      "blocked_7                     : 89073\n",
      "good_low_val                  : 82198\n",
      "next_value                    : 73297\n",
      "exp_was_live                  : 51935\n",
      "lower_val_avail               : 28732\n",
      "bad_bigger_val                : 28732\n",
      "exp_small_deck                : 26991\n",
      "bad_X                         : 22059\n",
      "had_X                         : 1083\n",
      "Episode 34000, Average Reward Last 1000: -1.41, eps=0.1055\n",
      "Episode 34200, Average Reward Last 1000: -1.28, eps=0.1042\n",
      "Smart center play ('center', 'B5') with opp exp ['B4', 'B6']\n",
      "Episode 34400, Average Reward Last 1000: -1.15, eps=0.1029\n",
      "Bad center ('center', 'R4') holding ['G4', 'R4', 'R5']\n",
      "Episode 34600, Average Reward Last 1000: -0.90, eps=0.1015\n",
      "Episode 34800, Average Reward Last 1000: -0.98, eps=0.1002\n",
      "Smart center play ('center', 'R2') with opp exp ['R6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 195153\n",
      "good_exp_1                    : 173422\n",
      "smart_opp_center              : 168597\n",
      "bad_center                    : 141583\n",
      "too_few_pts                   : 133350\n",
      "good_exp                      : 109618\n",
      "blocked_7                     : 91444\n",
      "good_low_val                  : 84563\n",
      "next_value                    : 75632\n",
      "exp_was_live                  : 54864\n",
      "lower_val_avail               : 29621\n",
      "bad_bigger_val                : 29621\n",
      "exp_small_deck                : 27889\n",
      "bad_X                         : 22606\n",
      "had_X                         : 1128\n",
      "Episode 35000, Average Reward Last 1000: -0.92, eps=0.0989\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "Episode 35200, Average Reward Last 1000: -1.00, eps=0.0976\n",
      "Episode 35400, Average Reward Last 1000: -0.91, eps=0.0964\n",
      "Episode 35600, Average Reward Last 1000: -1.04, eps=0.0952\n",
      "Smart center play ('center', 'B3') with opp exp ['B2', 'B4', 'B5']\n",
      "Episode 35800, Average Reward Last 1000: -1.01, eps=0.0940\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 206701\n",
      "good_exp_1                    : 178167\n",
      "smart_opp_center              : 177390\n",
      "bad_center                    : 150161\n",
      "too_few_pts                   : 136660\n",
      "good_exp                      : 112734\n",
      "blocked_7                     : 93918\n",
      "good_low_val                  : 86919\n",
      "next_value                    : 77882\n",
      "exp_was_live                  : 58037\n",
      "lower_val_avail               : 30467\n",
      "bad_bigger_val                : 30467\n",
      "exp_small_deck                : 28751\n",
      "bad_X                         : 23190\n",
      "had_X                         : 1162\n",
      "Episode 36000, Average Reward Last 1000: -0.99, eps=0.0928\n",
      "Episode 36200, Average Reward Last 1000: -1.08, eps=0.0915\n",
      "Episode 36400, Average Reward Last 1000: -1.44, eps=0.0903\n",
      "Bad center ('center', 'RX') holding ['R2', 'R6', 'RX']\n",
      "Plays: 205 in episode 36531\n",
      "Episode 36600, Average Reward Last 1000: -1.51, eps=0.0891\n",
      "P1 1 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 5 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 6 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 9 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 10 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 11 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 12 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 13 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 14 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 15 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 16 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 19 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 20 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 21 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 22 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 25 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 26 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 27 - 0.0 * 2 + -1.3 = -1.3\n",
      "P1 28 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 29 - 0.0 * 2 + -1.5 = -1.5\n",
      "P1 30 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 31 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 32 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 33 - 0.0 * 2 + -1.5 = -1.5\n",
      "P1 34 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 35 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 36 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 37 - 0.0 * 2 + -1.5 = -1.5\n",
      "P1 38 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 39 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 40 - 0.0 * 2 + -1.25 = -1.25\n",
      "P1 41 - 0.0 * 2 + 2.0 = 2.0\n",
      "P1 42 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 43 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 44 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 45 - 0.0 * 2 + 2.0 = 2.0\n",
      "P1 46 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 47 - 0.0 * 2 + 1.5 = 1.5\n",
      "P1 48 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 49 - 0.0 * 2 + 2.0 = 2.0\n",
      "P1 50 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 51 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 52 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 53 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 54 - 0.0 * 2 + 2.0 = 2.0\n",
      "P1 55 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 56 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 57 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 58 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 59 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 60 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 61 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 62 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 63 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 64 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 65 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 66 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 67 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 68 - 0.0 * 2 + 0.0 = 0.0\n",
      "P1 69 - 0.0 * 2 + 0.5 = 0.5\n",
      "P1 70 - 0.0 * 2 + 0.5 = 0.5\n",
      "Episode 36800, Average Reward Last 1000: -1.41, eps=0.0879\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "Smart center play ('center', 'G4') with opp exp ['G2', 'G3', 'G6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 218588\n",
      "smart_opp_center              : 186873\n",
      "good_exp_1                    : 182920\n",
      "bad_center                    : 158766\n",
      "too_few_pts                   : 139984\n",
      "good_exp                      : 115925\n",
      "blocked_7                     : 96334\n",
      "good_low_val                  : 89280\n",
      "next_value                    : 80180\n",
      "exp_was_live                  : 61573\n",
      "lower_val_avail               : 31358\n",
      "bad_bigger_val                : 31358\n",
      "exp_small_deck                : 29650\n",
      "bad_X                         : 23787\n",
      "had_X                         : 1195\n",
      "Episode 37000, Average Reward Last 1000: -1.37, eps=0.0868\n",
      "Bad center ('center', 'R6') holding ['G4', 'R3', 'R6']\n",
      "Episode 37200, Average Reward Last 1000: -1.25, eps=0.0858\n",
      "Bad center ('center', 'G3') holding ['B6', 'G3', 'G5']\n",
      "Episode 37400, Average Reward Last 1000: -1.03, eps=0.0847\n",
      "Episode 37600, Average Reward Last 1000: -1.05, eps=0.0837\n",
      "Episode 37800, Average Reward Last 1000: -1.13, eps=0.0827\n",
      "Bad center ('center', 'R6') holding ['G3', 'R4', 'R6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 229506\n",
      "smart_opp_center              : 195881\n",
      "good_exp_1                    : 187674\n",
      "bad_center                    : 166894\n",
      "too_few_pts                   : 143408\n",
      "good_exp                      : 118965\n",
      "blocked_7                     : 98798\n",
      "good_low_val                  : 91606\n",
      "next_value                    : 82500\n",
      "exp_was_live                  : 64519\n",
      "lower_val_avail               : 32164\n",
      "bad_bigger_val                : 32164\n",
      "exp_small_deck                : 30555\n",
      "bad_X                         : 24420\n",
      "had_X                         : 1233\n",
      "Episode 38000, Average Reward Last 1000: -1.02, eps=0.0816\n",
      "Episode 38200, Average Reward Last 1000: -1.01, eps=0.0806\n",
      "Episode 38400, Average Reward Last 1000: -0.93, eps=0.0797\n",
      "Episode 38600, Average Reward Last 1000: -0.65, eps=0.0786\n",
      "Plays: 206 in episode 38645\n",
      "Episode 38800, Average Reward Last 1000: -0.36, eps=0.0776\n",
      "Smart center play ('center', 'G3') with opp exp ['G5']\n",
      "Smart center play ('center', 'B3') with opp exp ['B2', 'B4', 'B5', 'B6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 240418\n",
      "smart_opp_center              : 204942\n",
      "good_exp_1                    : 192483\n",
      "bad_center                    : 175227\n",
      "too_few_pts                   : 146733\n",
      "good_exp                      : 122128\n",
      "blocked_7                     : 101235\n",
      "good_low_val                  : 93980\n",
      "next_value                    : 84920\n",
      "exp_was_live                  : 67146\n",
      "lower_val_avail               : 33058\n",
      "bad_bigger_val                : 33058\n",
      "exp_small_deck                : 31412\n",
      "bad_X                         : 24997\n",
      "had_X                         : 1274\n",
      "Episode 39000, Average Reward Last 1000: -0.25, eps=0.0767\n",
      "Plays: 210 in episode 39115\n",
      "Bad center ('center', 'R6') holding ['R2', 'R4', 'R6']\n",
      "Episode 39200, Average Reward Last 1000: -0.07, eps=0.0757\n",
      "Episode 39400, Average Reward Last 1000: 0.10, eps=0.0748\n",
      "P1 1 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -10 + 1.5 = 1.5\n",
      "P1 3 - 0.0 * -10 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -10 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * -10 + 2.0 = 2.0\n",
      "P1 9 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * -10 + -0.5 = -0.5\n",
      "P1 12 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -10 + 0.3 = 0.3\n",
      "P1 14 - 0.0 * -10 + 0.5 = 0.5\n",
      "P1 15 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -10 + -1.0 = -1.0\n",
      "P1 17 - 0.0 * -10 + 0.5 = 0.5\n",
      "P1 18 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -10 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * -10 + -1.0 = -1.0\n",
      "P1 24 - 0.0 * -10 + 0.5 = 0.5\n",
      "Plays: 233 in episode 39507\n",
      "Episode 39600, Average Reward Last 1000: 0.03, eps=0.0738\n",
      "Episode 39800, Average Reward Last 1000: 0.06, eps=0.0729\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 251780\n",
      "smart_opp_center              : 214827\n",
      "good_exp_1                    : 197323\n",
      "bad_center                    : 183658\n",
      "too_few_pts                   : 150081\n",
      "good_exp                      : 125224\n",
      "blocked_7                     : 103685\n",
      "good_low_val                  : 96289\n",
      "next_value                    : 87268\n",
      "exp_was_live                  : 70061\n",
      "lower_val_avail               : 33949\n",
      "bad_bigger_val                : 33949\n",
      "exp_small_deck                : 32233\n",
      "bad_X                         : 25584\n",
      "had_X                         : 1312\n",
      "Episode 40000, Average Reward Last 1000: -0.18, eps=0.0719\n",
      "Episode 40200, Average Reward Last 1000: -0.42, eps=0.0710\n",
      "Episode 40400, Average Reward Last 1000: -0.51, eps=0.0700\n",
      "Episode 40600, Average Reward Last 1000: -0.51, eps=0.0690\n",
      "Plays: 213 in episode 40605\n",
      "Episode 40800, Average Reward Last 1000: -0.66, eps=0.0681\n",
      "Plays: 211 in episode 40818\n",
      "P1 1 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -1 + 2.0 = 2.0\n",
      "P1 3 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -1 + -1.3 = -1.3\n",
      "P1 7 - 0.0 * -1 + 2.0 = 2.0\n",
      "P1 8 - 0.0 * -1 + 1.8 = 1.8\n",
      "P1 9 - 0.0 * -1 + 1.5 = 1.5\n",
      "P1 10 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * -1 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -1 + -1.0 = -1.0\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 263623\n",
      "smart_opp_center              : 224754\n",
      "good_exp_1                    : 202168\n",
      "bad_center                    : 192500\n",
      "too_few_pts                   : 153397\n",
      "good_exp                      : 128429\n",
      "blocked_7                     : 106063\n",
      "good_low_val                  : 98659\n",
      "next_value                    : 89690\n",
      "exp_was_live                  : 73246\n",
      "lower_val_avail               : 34875\n",
      "bad_bigger_val                : 34875\n",
      "exp_small_deck                : 33067\n",
      "bad_X                         : 26160\n",
      "had_X                         : 1353\n",
      "Episode 41000, Average Reward Last 1000: -0.55, eps=0.0672\n",
      "Plays: 209 in episode 41123\n",
      "Episode 41200, Average Reward Last 1000: -0.48, eps=0.0663\n",
      "Plays: 246 in episode 41306\n",
      "Bad center ('center', 'G6') holding ['G5', 'G6', 'R4']\n",
      "Plays: 203 in episode 41343\n",
      "Episode 41400, Average Reward Last 1000: -0.64, eps=0.0653\n",
      "Plays: 270 in episode 41597\n",
      "Episode 41600, Average Reward Last 1000: -0.79, eps=0.0643\n",
      "Smart center play ('center', 'G2') with opp exp ['G3']\n",
      "Episode 41800, Average Reward Last 1000: -0.96, eps=0.0633\n",
      "Bad center ('center', 'G5') holding ['B2', 'G4', 'G5']\n",
      "Plays: 218 in episode 41985\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 277463\n",
      "smart_opp_center              : 235359\n",
      "good_exp_1                    : 206970\n",
      "bad_center                    : 202627\n",
      "too_few_pts                   : 156649\n",
      "good_exp                      : 131699\n",
      "blocked_7                     : 108447\n",
      "good_low_val                  : 101073\n",
      "next_value                    : 92015\n",
      "exp_was_live                  : 76982\n",
      "lower_val_avail               : 35796\n",
      "bad_bigger_val                : 35796\n",
      "exp_small_deck                : 33956\n",
      "bad_X                         : 26689\n",
      "had_X                         : 1402\n",
      "Episode 42000, Average Reward Last 1000: -0.94, eps=0.0624\n",
      "Episode 42200, Average Reward Last 1000: -0.73, eps=0.0615\n",
      "Plays: 209 in episode 42298\n",
      "Episode 42400, Average Reward Last 1000: -0.62, eps=0.0607\n",
      "Plays: 209 in episode 42419\n",
      "P1 1 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -5 + -1.25 = -1.25\n",
      "P1 3 - 0.0 * -5 + 0.25 = 0.25\n",
      "P1 4 - 0.0 * -5 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * -5 + 1.5 = 1.5\n",
      "P1 6 - 0.0 * -5 + -1.25 = -1.25\n",
      "P1 7 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -5 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * -5 + -1.25 = -1.25\n",
      "P1 11 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 12 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 15 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -5 + 2.0 = 2.0\n",
      "P1 17 - 0.0 * -5 + -1.25 = -1.25\n",
      "P1 18 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * -5 + -0.5 = -0.5\n",
      "P1 20 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 23 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 25 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 26 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 27 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 28 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 29 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 30 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 31 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 32 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 33 - 0.0 * -5 + -1.0 = -1.0\n",
      "P1 34 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 35 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 36 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 37 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 38 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 39 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 40 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 41 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 42 - 0.0 * -5 + 0.5 = 0.5\n",
      "P1 43 - 0.0 * -5 + 0.0 = 0.0\n",
      "P1 44 - 0.0 * -5 + 0.5 = 0.5\n",
      "Plays: 224 in episode 42512\n",
      "Plays: 226 in episode 42521\n",
      "Episode 42600, Average Reward Last 1000: -0.39, eps=0.0598\n",
      "Smart center play ('center', 'B3') with opp exp ['B4', 'B5', 'B6']\n",
      "Episode 42800, Average Reward Last 1000: -0.21, eps=0.0590\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 289937\n",
      "smart_opp_center              : 245425\n",
      "bad_center                    : 211995\n",
      "good_exp_1                    : 211988\n",
      "too_few_pts                   : 159951\n",
      "good_exp                      : 135037\n",
      "blocked_7                     : 110847\n",
      "good_low_val                  : 103591\n",
      "next_value                    : 94514\n",
      "exp_was_live                  : 80000\n",
      "lower_val_avail               : 36711\n",
      "bad_bigger_val                : 36711\n",
      "exp_small_deck                : 34834\n",
      "bad_X                         : 27285\n",
      "had_X                         : 1442\n",
      "Episode 43000, Average Reward Last 1000: -0.21, eps=0.0582\n",
      "Bad center ('center', 'R5') holding ['B4', 'R5', 'R6']\n",
      "Episode 43200, Average Reward Last 1000: -0.30, eps=0.0574\n",
      "Plays: 201 in episode 43245\n",
      "Smart center play ('center', 'G3') with opp exp ['GX', 'G6']\n",
      "Episode 43400, Average Reward Last 1000: -0.38, eps=0.0566\n",
      "Episode 43600, Average Reward Last 1000: -0.66, eps=0.0559\n",
      "Episode 43800, Average Reward Last 1000: -0.73, eps=0.0551\n",
      "Plays: 201 in episode 43836\n",
      "Plays: 207 in episode 43847\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 301712\n",
      "smart_opp_center              : 255311\n",
      "bad_center                    : 220848\n",
      "good_exp_1                    : 216846\n",
      "too_few_pts                   : 163405\n",
      "good_exp                      : 138273\n",
      "blocked_7                     : 113329\n",
      "good_low_val                  : 105979\n",
      "next_value                    : 96898\n",
      "exp_was_live                  : 83233\n",
      "lower_val_avail               : 37653\n",
      "bad_bigger_val                : 37653\n",
      "exp_small_deck                : 35690\n",
      "bad_X                         : 27926\n",
      "had_X                         : 1489\n",
      "Episode 44000, Average Reward Last 1000: -0.67, eps=0.0544\n",
      "Smart center play ('center', 'B3') with opp exp ['B4', 'B5']\n",
      "Plays: 207 in episode 44071\n",
      "Episode 44200, Average Reward Last 1000: -0.67, eps=0.0537\n",
      "Plays: 249 in episode 44223\n",
      "Episode 44400, Average Reward Last 1000: -0.62, eps=0.0531\n",
      "Plays: 208 in episode 44514\n",
      "Episode 44600, Average Reward Last 1000: -0.44, eps=0.0524\n",
      "Plays: 202 in episode 44698\n",
      "Bad center ('center', 'R5') holding ['G5', 'R5', 'R6']\n",
      "Episode 44800, Average Reward Last 1000: -0.28, eps=0.0518\n",
      "Plays: 211 in episode 44976\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 312733\n",
      "smart_opp_center              : 264705\n",
      "bad_center                    : 229175\n",
      "good_exp_1                    : 221764\n",
      "too_few_pts                   : 166897\n",
      "good_exp                      : 141500\n",
      "blocked_7                     : 115795\n",
      "good_low_val                  : 108381\n",
      "next_value                    : 99271\n",
      "exp_was_live                  : 86003\n",
      "lower_val_avail               : 38616\n",
      "bad_bigger_val                : 38616\n",
      "exp_small_deck                : 36554\n",
      "bad_X                         : 28568\n",
      "had_X                         : 1525\n",
      "Episode 45000, Average Reward Last 1000: -0.56, eps=0.0511\n",
      "Episode 45200, Average Reward Last 1000: -0.86, eps=0.0505\n",
      "Bad center ('center', 'B3') holding ['B3', 'B4', 'B6']\n",
      "Episode 45400, Average Reward Last 1000: -1.01, eps=0.0498\n",
      "Episode 45600, Average Reward Last 1000: -1.12, eps=0.0491\n",
      "Episode 45800, Average Reward Last 1000: -1.41, eps=0.0485\n",
      "Plays: 226 in episode 45998\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 324034\n",
      "smart_opp_center              : 274118\n",
      "bad_center                    : 237595\n",
      "good_exp_1                    : 226639\n",
      "too_few_pts                   : 170396\n",
      "good_exp                      : 144717\n",
      "blocked_7                     : 118269\n",
      "good_low_val                  : 110802\n",
      "next_value                    : 101626\n",
      "exp_was_live                  : 89390\n",
      "lower_val_avail               : 39515\n",
      "bad_bigger_val                : 39515\n",
      "exp_small_deck                : 37406\n",
      "bad_X                         : 29227\n",
      "had_X                         : 1557\n",
      "Episode 46000, Average Reward Last 1000: -1.22, eps=0.0480\n",
      "Episode 46200, Average Reward Last 1000: -0.96, eps=0.0474\n",
      "Plays: 204 in episode 46266\n",
      "Episode 46400, Average Reward Last 1000: -0.92, eps=0.0467\n",
      "Plays: 231 in episode 46403\n",
      "Plays: 201 in episode 46499\n",
      "Episode 46600, Average Reward Last 1000: -1.05, eps=0.0461\n",
      "Episode 46800, Average Reward Last 1000: -1.08, eps=0.0454\n",
      "Plays: 203 in episode 46963\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 336454\n",
      "smart_opp_center              : 283933\n",
      "bad_center                    : 246861\n",
      "good_exp_1                    : 231599\n",
      "too_few_pts                   : 173885\n",
      "good_exp                      : 148056\n",
      "blocked_7                     : 120767\n",
      "good_low_val                  : 113310\n",
      "next_value                    : 104010\n",
      "exp_was_live                  : 92914\n",
      "lower_val_avail               : 40435\n",
      "bad_bigger_val                : 40435\n",
      "exp_small_deck                : 38297\n",
      "bad_X                         : 29942\n",
      "had_X                         : 1586\n",
      "Episode 47000, Average Reward Last 1000: -1.19, eps=0.0448\n",
      "Bad center ('center', 'B4') holding ['B2', 'B4', 'B5']\n",
      "Plays: 214 in episode 47131\n",
      "Bad center ('center', 'R6') holding ['G3', 'R5', 'R6']\n",
      "Episode 47200, Average Reward Last 1000: -1.30, eps=0.0441\n",
      "Episode 47400, Average Reward Last 1000: -1.04, eps=0.0434\n",
      "Plays: 209 in episode 47472\n",
      "Bad center ('center', 'B6') holding ['B3', 'B6', 'BX']\n",
      "Plays: 234 in episode 47559\n",
      "Episode 47600, Average Reward Last 1000: -1.06, eps=0.0428\n",
      "Plays: 205 in episode 47673\n",
      "Plays: 207 in episode 47729\n",
      "Episode 47800, Average Reward Last 1000: -0.98, eps=0.0421\n",
      "Plays: 207 in episode 47919\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 350317\n",
      "smart_opp_center              : 294888\n",
      "bad_center                    : 257350\n",
      "good_exp_1                    : 236566\n",
      "too_few_pts                   : 177309\n",
      "good_exp                      : 151403\n",
      "blocked_7                     : 123225\n",
      "good_low_val                  : 115835\n",
      "next_value                    : 106463\n",
      "exp_was_live                  : 96455\n",
      "lower_val_avail               : 41342\n",
      "bad_bigger_val                : 41342\n",
      "exp_small_deck                : 39245\n",
      "bad_X                         : 30594\n",
      "had_X                         : 1613\n",
      "Episode 48000, Average Reward Last 1000: -0.94, eps=0.0415\n",
      "Episode 48200, Average Reward Last 1000: -0.86, eps=0.0410\n",
      "Plays: 202 in episode 48308\n",
      "Episode 48400, Average Reward Last 1000: -1.15, eps=0.0404\n",
      "Plays: 210 in episode 48588\n",
      "Episode 48600, Average Reward Last 1000: -1.03, eps=0.0398\n",
      "Plays: 202 in episode 48695\n",
      "Episode 48800, Average Reward Last 1000: -1.07, eps=0.0392\n",
      "Plays: 263 in episode 48846\n",
      "Smart center play ('center', 'B2') with opp exp ['B6']\n",
      "Plays: 230 in episode 48949\n",
      "Plays: 335 in episode 48992\n",
      "Plays: 212 in episode 48997\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 363702\n",
      "smart_opp_center              : 305349\n",
      "bad_center                    : 267169\n",
      "good_exp_1                    : 241548\n",
      "too_few_pts                   : 180811\n",
      "good_exp                      : 154741\n",
      "blocked_7                     : 125693\n",
      "good_low_val                  : 118370\n",
      "next_value                    : 108950\n",
      "exp_was_live                  : 100355\n",
      "lower_val_avail               : 42244\n",
      "bad_bigger_val                : 42244\n",
      "exp_small_deck                : 40251\n",
      "bad_X                         : 31290\n",
      "had_X                         : 1664\n",
      "Episode 49000, Average Reward Last 1000: -1.09, eps=0.0386\n",
      "Plays: 222 in episode 49012\n",
      "Plays: 209 in episode 49032\n",
      "Plays: 218 in episode 49196\n",
      "Episode 49200, Average Reward Last 1000: -1.19, eps=0.0380\n",
      "Plays: 207 in episode 49246\n",
      "Episode 49400, Average Reward Last 1000: -1.24, eps=0.0374\n",
      "P1 1 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -13 + 1.5 = 1.5\n",
      "P1 3 - 0.0 * -13 + 2.0 = 2.0\n",
      "P1 4 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -13 + -2.5 = -2.5\n",
      "P1 10 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * -13 + -1.7 = -1.7\n",
      "P1 12 - 0.0 * -13 + -1.0 = -1.0\n",
      "P1 13 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -13 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * -13 + 1.5 = 1.5\n",
      "Episode 49600, Average Reward Last 1000: -1.35, eps=0.0369\n",
      "Plays: 238 in episode 49626\n",
      "Episode 49800, Average Reward Last 1000: -1.23, eps=0.0364\n",
      "Plays: 202 in episode 49803\n",
      "Bad center ('center', 'B5') holding ['B4', 'B5', 'R3']\n",
      "Plays: 204 in episode 49920\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 377050\n",
      "smart_opp_center              : 315706\n",
      "bad_center                    : 277216\n",
      "good_exp_1                    : 246564\n",
      "too_few_pts                   : 184283\n",
      "good_exp                      : 158135\n",
      "blocked_7                     : 128132\n",
      "good_low_val                  : 120984\n",
      "next_value                    : 111480\n",
      "exp_was_live                  : 103742\n",
      "lower_val_avail               : 43108\n",
      "bad_bigger_val                : 43108\n",
      "exp_small_deck                : 41188\n",
      "bad_X                         : 31982\n",
      "had_X                         : 1707\n",
      "Episode 50000, Average Reward Last 1000: -1.39, eps=0.0359\n",
      "Plays: 242 in episode 50007\n",
      "Plays: 241 in episode 50042\n",
      "Plays: 221 in episode 50097\n",
      "Plays: 341 in episode 50198\n",
      "Episode 50200, Average Reward Last 1000: -1.48, eps=0.0353\n",
      "Plays: 202 in episode 50353\n",
      "P1 1 - 0.0 * -8 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * -8 + 0.5 = 0.5\n",
      "P1 3 - 0.0 * -8 + -1.5 = -1.5\n",
      "P1 4 - 0.0 * -8 + 1.5 = 1.5\n",
      "P1 5 - 0.0 * -8 + -1.5 = -1.5\n",
      "P1 6 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * -8 + 1.5 = 1.5\n",
      "P1 8 - 0.0 * -8 + -1.5 = -1.5\n",
      "P1 9 - 0.0 * -8 + -1.3 = -1.3\n",
      "P1 10 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * -8 + -1.5 = -1.5\n",
      "P1 12 - 0.0 * -8 + 0.3 = 0.3\n",
      "P1 13 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -8 + -1.25 = -1.25\n",
      "P1 15 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * -8 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * -8 + 0.5 = 0.5\n",
      "Episode 50400, Average Reward Last 1000: -1.41, eps=0.0349\n",
      "P1 1 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -14 + 1.5 = 1.5\n",
      "P1 3 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * -14 + -1.3 = -1.3\n",
      "P1 5 - 0.0 * -14 + 1.5 = 1.5\n",
      "P1 6 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 7 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * -14 + 1.5 = 1.5\n",
      "P1 9 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 10 - 0.0 * -14 + 1.8 = 1.8\n",
      "P1 11 - 0.0 * -14 + -1.25 = -1.25\n",
      "P1 12 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * -14 + 0.5 = 0.5\n",
      "P1 15 - 0.0 * -14 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * -14 + -2.2 = -2.2\n",
      "Plays: 210 in episode 50580\n",
      "Episode 50600, Average Reward Last 1000: -1.42, eps=0.0344\n",
      "Plays: 293 in episode 50608\n",
      "Episode 50800, Average Reward Last 1000: -1.57, eps=0.0340\n",
      "Bad center ('center', 'G6') holding ['G4', 'G6', 'GX']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 388795\n",
      "smart_opp_center              : 325177\n",
      "bad_center                    : 285959\n",
      "good_exp_1                    : 251580\n",
      "too_few_pts                   : 187876\n",
      "good_exp                      : 161475\n",
      "blocked_7                     : 130632\n",
      "good_low_val                  : 123551\n",
      "next_value                    : 113886\n",
      "exp_was_live                  : 107064\n",
      "lower_val_avail               : 43995\n",
      "bad_bigger_val                : 43995\n",
      "exp_small_deck                : 42083\n",
      "bad_X                         : 32722\n",
      "had_X                         : 1742\n",
      "Episode 51000, Average Reward Last 1000: -1.59, eps=0.0336\n",
      "Episode 51200, Average Reward Last 1000: -1.50, eps=0.0332\n",
      "Plays: 208 in episode 51203\n",
      "P1 1 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 3 - 0.0 * 3 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 6 - 0.0 * 3 + -1.25 = -1.25\n",
      "P1 7 - 0.0 * 3 + 2.0 = 2.0\n",
      "P1 8 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 3 + 1.8 = 1.8\n",
      "P1 11 - 0.0 * 3 + -1.25 = -1.25\n",
      "P1 12 - 0.0 * 3 + 2.0 = 2.0\n",
      "P1 13 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 15 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 17 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 3 + 2.0 = 2.0\n",
      "P1 20 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 22 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * 3 + 1.5 = 1.5\n",
      "P1 24 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 26 - 0.0 * 3 + 0.5 = 0.5\n",
      "P1 27 - 0.0 * 3 + 0.0 = 0.0\n",
      "P1 28 - 0.0 * 3 + 0.0 = 0.0\n",
      "Episode 51400, Average Reward Last 1000: -1.60, eps=0.0328\n",
      "Episode 51600, Average Reward Last 1000: -1.81, eps=0.0324\n",
      "Episode 51800, Average Reward Last 1000: -1.91, eps=0.0320\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 399085\n",
      "smart_opp_center              : 333896\n",
      "bad_center                    : 293354\n",
      "good_exp_1                    : 256406\n",
      "too_few_pts                   : 191572\n",
      "good_exp                      : 164632\n",
      "blocked_7                     : 133252\n",
      "good_low_val                  : 125992\n",
      "next_value                    : 116311\n",
      "exp_was_live                  : 110239\n",
      "lower_val_avail               : 44872\n",
      "bad_bigger_val                : 44872\n",
      "exp_small_deck                : 42974\n",
      "bad_X                         : 33510\n",
      "had_X                         : 1764\n",
      "Episode 52000, Average Reward Last 1000: -2.12, eps=0.0317\n",
      "Smart center play ('center', 'G2') with opp exp ['G4', 'G5']\n",
      "Smart center play ('center', 'R3') with opp exp ['R2', 'R6']\n",
      "Episode 52200, Average Reward Last 1000: -2.34, eps=0.0313\n",
      "Episode 52400, Average Reward Last 1000: -2.50, eps=0.0310\n",
      "P1 1 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 5 + -1.25 = -1.25\n",
      "P1 3 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 4 - 0.0 * 5 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 6 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 8 - 0.0 * 5 + 2.0 = 2.0\n",
      "P1 9 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 10 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * 5 + 0.19999999999999996 = 0.19999999999999996\n",
      "P1 12 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 5 + 0.19999999999999996 = 0.19999999999999996\n",
      "P1 14 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * 5 + 1.8 = 1.8\n",
      "P1 16 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 5 + 1.5 = 1.5\n",
      "P1 18 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 5 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * 5 + 2.0 = 2.0\n",
      "P1 21 - 0.0 * 5 + 0.0 = 0.0\n",
      "Episode 52600, Average Reward Last 1000: -2.31, eps=0.0306\n",
      "Episode 52800, Average Reward Last 1000: -2.46, eps=0.0302\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 409768\n",
      "smart_opp_center              : 343318\n",
      "bad_center                    : 300922\n",
      "good_exp_1                    : 261195\n",
      "too_few_pts                   : 195277\n",
      "good_exp                      : 167774\n",
      "blocked_7                     : 135868\n",
      "good_low_val                  : 128350\n",
      "next_value                    : 118615\n",
      "exp_was_live                  : 113854\n",
      "lower_val_avail               : 45780\n",
      "bad_bigger_val                : 45780\n",
      "exp_small_deck                : 43915\n",
      "bad_X                         : 34323\n",
      "had_X                         : 1788\n",
      "Episode 53000, Average Reward Last 1000: -2.24, eps=0.0300\n",
      "Plays: 263 in episode 53106\n",
      "Episode 53200, Average Reward Last 1000: -2.00, eps=0.0300\n",
      "Plays: 241 in episode 53218\n",
      "Episode 53400, Average Reward Last 1000: -2.01, eps=0.0300\n",
      "Plays: 218 in episode 53553\n",
      "P1 1 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * 6 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 7 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * 6 + -0.75 = -0.75\n",
      "P1 9 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 10 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 11 - 0.0 * 6 + -0.75 = -0.75\n",
      "P1 12 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 14 - 0.0 * 6 + -1.25 = -1.25\n",
      "P1 15 - 0.0 * 6 + -0.75 = -0.75\n",
      "P1 16 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 17 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 20 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 21 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 23 - 0.0 * 6 + 2.0 = 2.0\n",
      "P1 24 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 26 - 0.0 * 6 + 2.0 = 2.0\n",
      "P1 27 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 28 - 0.0 * 6 + 0.6 = 0.6\n",
      "P1 29 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 30 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 31 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 32 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 33 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 34 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 35 - 0.0 * 6 + 0.0 = 0.0\n",
      "P1 36 - 0.0 * 6 + 1.5 = 1.5\n",
      "P1 37 - 0.0 * 6 + 0.5 = 0.5\n",
      "P1 38 - 0.0 * 6 + 0.5 = 0.5\n",
      "Episode 53600, Average Reward Last 1000: -2.13, eps=0.0300\n",
      "Plays: 201 in episode 53651\n",
      "Plays: 361 in episode 53775\n",
      "Episode 53800, Average Reward Last 1000: -2.02, eps=0.0300\n",
      "P1 1 - 0.0 * 7 + -1.25 = -1.25\n",
      "P1 2 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * 7 + 1.5 = 1.5\n",
      "P1 4 - 0.0 * 7 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 7 - 0.0 * 7 + -0.5 = -0.5\n",
      "P1 8 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * 7 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * 7 + 2.0 = 2.0\n",
      "P1 11 - 0.0 * 7 + 0.3 = 0.3\n",
      "P1 12 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * 7 + 0.0 = 0.0\n",
      "P1 16 - 0.0 * 7 + -0.5 = -0.5\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 421316\n",
      "smart_opp_center              : 353374\n",
      "bad_center                    : 308829\n",
      "good_exp_1                    : 266074\n",
      "too_few_pts                   : 198975\n",
      "good_exp                      : 170978\n",
      "blocked_7                     : 138431\n",
      "good_low_val                  : 130809\n",
      "next_value                    : 120995\n",
      "exp_was_live                  : 117445\n",
      "lower_val_avail               : 46628\n",
      "bad_bigger_val                : 46628\n",
      "exp_small_deck                : 44895\n",
      "bad_X                         : 35104\n",
      "had_X                         : 1812\n",
      "Episode 54000, Average Reward Last 1000: -2.23, eps=0.0300\n",
      "Bad center ('center', 'G5') holding ['G5', 'G6', 'GX']\n",
      "Episode 54200, Average Reward Last 1000: -2.59, eps=0.0300\n",
      "Smart center play ('center', 'G4') with opp exp ['G3', 'G5']\n",
      "Episode 54400, Average Reward Last 1000: -2.52, eps=0.0300\n",
      "Episode 54600, Average Reward Last 1000: -2.45, eps=0.0300\n",
      "Plays: 223 in episode 54737\n",
      "Episode 54800, Average Reward Last 1000: -2.34, eps=0.0300\n",
      "Plays: 224 in episode 54817\n",
      "Plays: 324 in episode 54821\n",
      "Plays: 210 in episode 54893\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 433280\n",
      "smart_opp_center              : 363394\n",
      "bad_center                    : 317318\n",
      "good_exp_1                    : 270883\n",
      "too_few_pts                   : 202661\n",
      "good_exp                      : 174134\n",
      "blocked_7                     : 141035\n",
      "good_low_val                  : 133176\n",
      "next_value                    : 123354\n",
      "exp_was_live                  : 121129\n",
      "lower_val_avail               : 47512\n",
      "bad_bigger_val                : 47512\n",
      "exp_small_deck                : 45841\n",
      "bad_X                         : 35891\n",
      "had_X                         : 1840\n",
      "Episode 55000, Average Reward Last 1000: -2.15, eps=0.0300\n",
      "Plays: 233 in episode 55061\n",
      "Episode 55200, Average Reward Last 1000: -1.93, eps=0.0300\n",
      "Smart center play ('center', 'R2') with opp exp ['R3', 'R4', 'R5', 'R6']\n",
      "Plays: 219 in episode 55342\n",
      "Episode 55400, Average Reward Last 1000: -1.98, eps=0.0300\n",
      "Plays: 239 in episode 55437\n",
      "Smart center play ('center', 'G3') with opp exp ['G4']\n",
      "Plays: 296 in episode 55487\n",
      "Plays: 204 in episode 55592\n",
      "Episode 55600, Average Reward Last 1000: -1.97, eps=0.0300\n",
      "Plays: 250 in episode 55603\n",
      "Plays: 323 in episode 55709\n",
      "Episode 55800, Average Reward Last 1000: -1.95, eps=0.0300\n",
      "Plays: 228 in episode 55857\n",
      "Plays: 213 in episode 55860\n",
      "Bad center ('center', 'G6') holding ['BX', 'G2', 'G6']\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "Plays: 212 in episode 55933\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 446300\n",
      "smart_opp_center              : 373662\n",
      "bad_center                    : 326974\n",
      "good_exp_1                    : 275861\n",
      "too_few_pts                   : 206238\n",
      "good_exp                      : 177479\n",
      "blocked_7                     : 143556\n",
      "good_low_val                  : 135739\n",
      "next_value                    : 125797\n",
      "exp_was_live                  : 124651\n",
      "lower_val_avail               : 48404\n",
      "bad_bigger_val                : 48404\n",
      "exp_small_deck                : 46792\n",
      "bad_X                         : 36607\n",
      "had_X                         : 1878\n",
      "Episode 56000, Average Reward Last 1000: -1.54, eps=0.0300\n",
      "Smart center play ('center', 'B3') with opp exp ['B4']\n",
      "Plays: 208 in episode 56123\n",
      "Episode 56200, Average Reward Last 1000: -1.44, eps=0.0300\n",
      "Bad center ('center', 'R4') holding ['GX', 'R4', 'R6']\n",
      "Plays: 227 in episode 56209\n",
      "Plays: 209 in episode 56227\n",
      "Plays: 311 in episode 56376\n",
      "Episode 56400, Average Reward Last 1000: -1.14, eps=0.0300\n",
      "Plays: 252 in episode 56522\n",
      "Smart center play ('center', 'G2') with opp exp ['G6']\n",
      "Plays: 264 in episode 56586\n",
      "Episode 56600, Average Reward Last 1000: -1.12, eps=0.0300\n",
      "Plays: 237 in episode 56601\n",
      "Episode 56800, Average Reward Last 1000: -1.21, eps=0.0300\n",
      "Plays: 224 in episode 56867\n",
      "Plays: 202 in episode 56883\n",
      "P1 1 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 3 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 4 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 5 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 6 - 0.0 * -33 + 1.5 = 1.5\n",
      "P1 7 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 8 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 10 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 11 - 0.0 * -33 + 0.5 = 0.5\n",
      "P1 12 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 13 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 14 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 15 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 16 - 0.0 * -33 + -1.25 = -1.25\n",
      "P1 17 - 0.0 * -33 + 0.5 = 0.5\n",
      "P1 18 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 20 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 22 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 23 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * -33 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 26 - 0.0 * -33 + 2.0 = 2.0\n",
      "P1 27 - 0.0 * -33 + -1.7 = -1.7\n",
      "P1 28 - 0.0 * -33 + 0.5 = 0.5\n",
      "P1 29 - 0.0 * -33 + 0.5 = 0.5\n",
      "P1 30 - 0.0 * -33 + -2.2 = -2.2\n",
      "Plays: 210 in episode 56997\n",
      "Plays: 248 in episode 56999\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 459643\n",
      "smart_opp_center              : 383836\n",
      "bad_center                    : 337034\n",
      "good_exp_1                    : 280880\n",
      "too_few_pts                   : 209815\n",
      "good_exp                      : 180867\n",
      "blocked_7                     : 146070\n",
      "good_low_val                  : 138339\n",
      "exp_was_live                  : 128368\n",
      "next_value                    : 128292\n",
      "lower_val_avail               : 49315\n",
      "bad_bigger_val                : 49315\n",
      "exp_small_deck                : 47706\n",
      "bad_X                         : 37312\n",
      "had_X                         : 1910\n",
      "Episode 57000, Average Reward Last 1000: -1.67, eps=0.0300\n",
      "Plays: 213 in episode 57021\n",
      "Smart center play ('center', 'G4') with opp exp ['G2', 'G3', 'G6']\n",
      "Plays: 215 in episode 57185\n",
      "Episode 57200, Average Reward Last 1000: -1.64, eps=0.0300\n",
      "Plays: 315 in episode 57225\n",
      "Plays: 225 in episode 57311\n",
      "Plays: 373 in episode 57374\n",
      "Plays: 241 in episode 57386\n",
      "Plays: 217 in episode 57399\n",
      "Episode 57400, Average Reward Last 1000: -1.91, eps=0.0300\n",
      "Plays: 210 in episode 57418\n",
      "Plays: 318 in episode 57446\n",
      "Plays: 219 in episode 57532\n",
      "Bad center ('center', 'B4') holding ['B3', 'B4', 'R2']\n",
      "Episode 57600, Average Reward Last 1000: -1.95, eps=0.0300\n",
      "Plays: 225 in episode 57648\n",
      "Plays: 231 in episode 57706\n",
      "Plays: 318 in episode 57721\n",
      "Plays: 240 in episode 57725\n",
      "Plays: 245 in episode 57767\n",
      "Episode 57800, Average Reward Last 1000: -1.77, eps=0.0300\n",
      "Plays: 223 in episode 57901\n",
      "Plays: 203 in episode 57917\n",
      "Plays: 222 in episode 57927\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 474735\n",
      "smart_opp_center              : 395402\n",
      "bad_center                    : 347928\n",
      "good_exp_1                    : 285761\n",
      "too_few_pts                   : 213292\n",
      "good_exp                      : 184235\n",
      "blocked_7                     : 148581\n",
      "good_low_val                  : 140922\n",
      "exp_was_live                  : 132773\n",
      "next_value                    : 130778\n",
      "lower_val_avail               : 50180\n",
      "bad_bigger_val                : 50180\n",
      "exp_small_deck                : 48630\n",
      "bad_X                         : 38033\n",
      "had_X                         : 1948\n",
      "Episode 58000, Average Reward Last 1000: -1.53, eps=0.0300\n",
      "Plays: 321 in episode 58002\n",
      "Plays: 223 in episode 58006\n",
      "Plays: 272 in episode 58043\n",
      "Plays: 362 in episode 58198\n",
      "Episode 58200, Average Reward Last 1000: -1.58, eps=0.0300\n",
      "Plays: 203 in episode 58379\n",
      "Episode 58400, Average Reward Last 1000: -1.32, eps=0.0300\n",
      "Plays: 216 in episode 58413\n",
      "Plays: 222 in episode 58451\n",
      "Plays: 232 in episode 58591\n",
      "Episode 58600, Average Reward Last 1000: -1.15, eps=0.0300\n",
      "Plays: 203 in episode 58651\n",
      "Episode 58800, Average Reward Last 1000: -1.09, eps=0.0300\n",
      "Plays: 264 in episode 58867\n",
      "P1 1 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 2 - 0.0 * 1 + 2.0 = 2.0\n",
      "P1 3 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 4 - 0.0 * 1 + -1.25 = -1.25\n",
      "P1 5 - 0.0 * 1 + 1.5 = 1.5\n",
      "P1 6 - 0.0 * 1 + -1.25 = -1.25\n",
      "P1 7 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 8 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 9 - 0.0 * 1 + 0.5 = 0.5\n",
      "P1 10 - 0.0 * 1 + 0.25 = 0.25\n",
      "P1 11 - 0.0 * 1 + 1.5 = 1.5\n",
      "P1 12 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 13 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 14 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 15 - 0.0 * 1 + 1.0 = 1.0\n",
      "P1 16 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 17 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 18 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 19 - 0.0 * 1 + 2.0 = 2.0\n",
      "P1 20 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 21 - 0.0 * 1 + 0.6 = 0.6\n",
      "P1 22 - 0.0 * 1 + 1.5 = 1.5\n",
      "P1 23 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 24 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 25 - 0.0 * 1 + 0.5 = 0.5\n",
      "P1 26 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 27 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 28 - 0.0 * 1 + 1.5 = 1.5\n",
      "P1 29 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 30 - 0.0 * 1 + 0.5 = 0.5\n",
      "P1 31 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 32 - 0.0 * 1 + -1.8 = -1.8\n",
      "P1 33 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 34 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 35 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 36 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 37 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 38 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 39 - 0.0 * 1 + 0.5 = 0.5\n",
      "P1 40 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 41 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 42 - 0.0 * 1 + 0.0 = 0.0\n",
      "P1 43 - 0.0 * 1 + 0.5 = 0.5\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 487302\n",
      "smart_opp_center              : 405845\n",
      "bad_center                    : 357125\n",
      "good_exp_1                    : 290772\n",
      "too_few_pts                   : 216814\n",
      "good_exp                      : 187641\n",
      "blocked_7                     : 151069\n",
      "good_low_val                  : 143511\n",
      "exp_was_live                  : 135937\n",
      "next_value                    : 133326\n",
      "lower_val_avail               : 51100\n",
      "bad_bigger_val                : 51100\n",
      "exp_small_deck                : 49553\n",
      "bad_X                         : 38686\n",
      "had_X                         : 1986\n",
      "Episode 59000, Average Reward Last 1000: -1.00, eps=0.0300\n",
      "Plays: 241 in episode 59026\n",
      "Plays: 201 in episode 59110\n",
      "Bad center ('center', 'B5') holding ['B2', 'B5', 'G5']\n",
      "Plays: 207 in episode 59118\n",
      "Bad center ('center', 'B6') holding ['B2', 'B6', 'R6']\n",
      "Episode 59200, Average Reward Last 1000: -0.89, eps=0.0300\n",
      "Plays: 204 in episode 59307\n",
      "Episode 59400, Average Reward Last 1000: -1.05, eps=0.0300\n",
      "Plays: 216 in episode 59409\n",
      "Episode 59600, Average Reward Last 1000: -1.00, eps=0.0300\n",
      "Plays: 328 in episode 59665\n",
      "Plays: 240 in episode 59769\n",
      "Plays: 218 in episode 59793\n",
      "Episode 59800, Average Reward Last 1000: -1.02, eps=0.0300\n",
      "Plays: 221 in episode 59830\n",
      "Smart center play ('center', 'G4') with opp exp ['G6']\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_8                     : 499253\n",
      "smart_opp_center              : 416013\n",
      "bad_center                    : 365967\n",
      "good_exp_1                    : 295868\n",
      "too_few_pts                   : 220362\n",
      "good_exp                      : 191108\n",
      "blocked_7                     : 153571\n",
      "good_low_val                  : 146147\n",
      "exp_was_live                  : 138931\n",
      "next_value                    : 135818\n",
      "lower_val_avail               : 52040\n",
      "bad_bigger_val                : 52040\n",
      "exp_small_deck                : 50473\n",
      "bad_X                         : 39358\n",
      "had_X                         : 2022\n",
      "Episode 60000, Average Reward Last 1000: -1.11, eps=0.0300\n"
     ]
    }
   ],
   "source": [
    "# Modified Training Loop with Action + Draw Selection from Policy\n",
    "\n",
    "file_name='all_rewards.V1C.3.csv'\n",
    "\n",
    "# V1B.1\n",
    "num_episodes = 60_000\n",
    "batch_size = 64\n",
    "batch_cnt = 3\n",
    "train_every = 2\n",
    "step_booster = 5.0\n",
    "episode_booster = 0.0 # 0.5 for 1, 1.0 for 2, 0.0 for 3\n",
    "all_rewards = []\n",
    "mean_rewards = []\n",
    "epsilon = 0.35\n",
    "epsilon_min = 0.030 # was 0.35 for .2.\n",
    "epsilon_decay = 0.999999  # adjust this rate as needed - 0.99995 is too low\n",
    "\n",
    "env = LostCitiesEnv()\n",
    "state_size = 43  # Your extracted feature size\n",
    "num_card_actions = card_cnt\n",
    "num_draw_choices = color_cnt+1\n",
    "model = ActorCritic(state_size=state_size, action_size=num_card_actions, draw_size=num_draw_choices)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "replay_buffer = deque(maxlen=10000) # was 12000, then 10000 .3.\n",
    "rule_counter = defaultdict(int)\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    # episode_reward = 0\n",
    "    mean_reward = 0.0\n",
    "    play_cnt=0\n",
    "    plays_p1 = []\n",
    "    plays_p2 = []\n",
    "\n",
    "    while not done:\n",
    "        play_cnt+=1\n",
    "        features_np = extract_features(state)\n",
    "        features = torch.tensor(features_np, dtype=torch.float32)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        card_logits, draw_logits, value = model(features)\n",
    "\n",
    "        # Get legal actions and legal draws\n",
    "        # actions, draws = env.get_legal_actions(state['current_player'])\n",
    "        actions, draws = env.get_legal_actions(state['current_player'])\n",
    "        legal_action_indices = list(range(len(actions)))\n",
    "\n",
    "        valid_draws = [d for d in draws if d == 'deck' or (d in env.center_piles and env.center_piles[d])]\n",
    "        if not valid_draws:\n",
    "            print(\"No valid draws—forcing episode end.\")\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "        # legal_draw_indices = list(range(len(valid_draws)))  # typically ['deck', 'R', 'B', 'G']\n",
    "\n",
    "        # Stop this game is no legal actions - though this is of course not true, but...\n",
    "        # Print discard and draw for plays 1001 to 1020\n",
    "        if 10001 <= play_cnt <= 10020:\n",
    "            print(f\"Legal actions: {actions}\")\n",
    "            print(f\"Action indices: {[i for i in range(len(actions))]}\")\n",
    "            # Not valid at this point\n",
    "            # print(f\"Play {play_cnt}: Discard action = {chosen_action}, Draw choice = {chosen_draw}\")\n",
    "        if play_cnt>=10020:\n",
    "            print(play_cnt, actions, draws, valid_draws)\n",
    "            print(f\"\\n--- STUCK STATE at play {play_cnt} ---\")\n",
    "            print(f\"Deck size: {state['deck_size']}\")\n",
    "            print(f\"Player hand: {state['hands'][state['current_player']]}\")\n",
    "            print(f\"Expeditions:\")\n",
    "            for color in env.expeditions[state['current_player']]:\n",
    "                print(f\"  {color}: {env.expeditions[state['current_player']][color]}\")\n",
    "            print(f\"Center piles:\")\n",
    "            for color in env.center_piles:\n",
    "                print(f\"  {color}: {env.center_piles[color]}\")\n",
    "            print(f\"Available actions: {actions}\")\n",
    "            print(f\"Available draws: {draws}\")\n",
    "            print(f\"----------------------\\n\")\n",
    "            raise SystemExit(f\"STOP\")\n",
    "        \n",
    "        if not actions:\n",
    "            print(f\"No legal actions for player {state['current_player']}. Ending episode early.\")\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "        # Sample card action with epsilon-greedy\n",
    "        if random.random() < epsilon:\n",
    "            # Random action\n",
    "            card_idx = random.randint(0, len(actions) - 1)\n",
    "        else:\n",
    "            # Model-based action\n",
    "            card_probs = torch.softmax(card_logits[:len(actions)], dim=0)\n",
    "            card_dist = torch.distributions.Categorical(card_probs)\n",
    "            card_idx = card_dist.sample().item()\n",
    "        \n",
    "        chosen_action = actions[card_idx]\n",
    "\n",
    "        # Filter valid draws based on chosen_action (if it's a center discard)\n",
    "        discard_color = None\n",
    "        if chosen_action[0] == 'center':\n",
    "            discard_color = chosen_action[1][0]\n",
    "        \n",
    "        filtered_draws = [\n",
    "            d for d in valid_draws if d != discard_color\n",
    "        ]\n",
    "        if not filtered_draws:\n",
    "            # Failsafe: fallback to deck\n",
    "            filtered_draws = ['deck']\n",
    "\n",
    "        valid_draws=filtered_draws\n",
    "\n",
    "        # Sample draw choice (FIXED)\n",
    "        if random.random() < epsilon:\n",
    "            chosen_draw = random.choice(valid_draws)\n",
    "        else:\n",
    "            # Correct mapping: get logits only for valid draws\n",
    "            draw_indices_in_logits = [draw_to_index[d] for d in valid_draws]\n",
    "            draw_logits_filtered = draw_logits[draw_indices_in_logits]\n",
    "            draw_probs = torch.softmax(draw_logits_filtered, dim=0)\n",
    "            draw_dist = torch.distributions.Categorical(draw_probs)\n",
    "            draw_idx = draw_dist.sample().item()\n",
    "            chosen_draw = valid_draws[draw_idx]\n",
    "\n",
    "        # Compute shaped intermediate reward\n",
    "        step_reward = compute_step_reward(state, chosen_action, chosen_draw, env)\n",
    "\n",
    "        # Map draw_choice to its index for policy update\n",
    "        chosen_draw_idx = draw_to_index[chosen_draw]\n",
    "\n",
    "        # Save the current player before doing env.step\n",
    "        current_player=state['current_player']\n",
    "        \n",
    "        # Take action and draw based on policies\n",
    "        next_state, reward, done = env.step(chosen_action, chosen_draw)\n",
    "\n",
    "        # Combine shaped reward + final score (if any)\n",
    "        # total_reward = reward + booster * step_reward\n",
    "        total_reward = step_booster * step_reward\n",
    "\n",
    "        # Store full experience (must include both action idx and draw idx!)\n",
    "        # replay_buffer.append((features_np, card_idx, chosen_draw_idx, total_reward))\n",
    "        # Now, do it all at end of game\n",
    "        if current_player=='P1':\n",
    "            plays_p1.append((features_np, card_idx, chosen_draw_idx, step_reward))\n",
    "        else:\n",
    "            plays_p2.append((features_np, card_idx, chosen_draw_idx, step_reward))\n",
    "            \n",
    "        # Advance state\n",
    "        state = next_state\n",
    "        mean_reward += total_reward\n",
    "\n",
    "        # Annealing\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "        ddebug = random.random()<0.0005\n",
    "        if done:\n",
    "            reward_p1 = env.compute_score('P1')\n",
    "            reward_p2 = env.compute_score('P2')\n",
    "            p1cnt=0\n",
    "            for (features_np, card_idx, draw_idx, step_reward) in plays_p1:\n",
    "                total_reward = episode_booster * reward_p1 + step_reward\n",
    "                replay_buffer.append((features_np, card_idx, draw_idx, total_reward))\n",
    "                if ddebug:\n",
    "                    p1cnt+=1\n",
    "                    print(f\"P1 {p1cnt} - {episode_booster} * {reward_p1} + {step_reward} = {total_reward}\")\n",
    "            for (features_np, card_idx, draw_idx, step_reward) in plays_p2:\n",
    "                total_reward = episode_booster * reward_p2 + step_reward\n",
    "                replay_buffer.append((features_np, card_idx, draw_idx, total_reward))\n",
    "\n",
    "    # Final mean reward is the average over plays - approximate over P1 and P2\n",
    "    mean_reward=1.0*mean_reward/play_cnt\n",
    "    \n",
    "    if play_cnt>200:\n",
    "        print(f\"Plays: {play_cnt} in episode {episode}\")\n",
    "\n",
    "    # Train\n",
    "    if episode % train_every == 0 and len(replay_buffer) >= batch_size:\n",
    "        for _ in range(batch_cnt):\n",
    "            minibatch = random.sample(replay_buffer, batch_size)\n",
    "    \n",
    "            # Unpack minibatch into separate lists\n",
    "            states_b, actions_b, draws_b, rewards_b = zip(*minibatch)\n",
    "\n",
    "            # Convert lists to tensors\n",
    "            states_np = np.array(states_b)  # Convert list of arrays → single array\n",
    "            states_t = torch.tensor(states_np, dtype=torch.float32)\n",
    "    \n",
    "            # Convert to tensors in batch\n",
    "            # states_t = torch.tensor(states_b, dtype=torch.float32)  # Shape: [batch_size, state_size]\n",
    "            actions_t = torch.tensor(actions_b, dtype=torch.long)   # Shape: [batch_size]\n",
    "            draws_t = torch.tensor(draws_b, dtype=torch.long)       # Shape: [batch_size]\n",
    "            rewards_t = torch.tensor(rewards_b, dtype=torch.float32)  # Shape: [batch_size]\n",
    "    \n",
    "            # Forward pass in batch\n",
    "            card_logits_b, draw_logits_b, values_b = model(states_t)  # Each output shape: [batch_size, num_actions/draws]\n",
    "    \n",
    "            # Compute log probs for card actions\n",
    "            card_probs_b = torch.softmax(card_logits_b, dim=1)\n",
    "            log_card_probs_b = torch.log(card_probs_b + 1e-8)\n",
    "            selected_log_card_probs = log_card_probs_b[range(batch_size), actions_t]\n",
    "    \n",
    "            # Compute log probs for draws\n",
    "            draw_probs_b = torch.softmax(draw_logits_b, dim=1)\n",
    "            log_draw_probs_b = torch.log(draw_probs_b + 1e-8)\n",
    "            selected_log_draw_probs = log_draw_probs_b[range(batch_size), draws_t]\n",
    "    \n",
    "            # Compute advantage\n",
    "            advantages = rewards_t - values_b.squeeze(1)  # Shape: [batch_size]\n",
    "    \n",
    "            # Losses\n",
    "            critic_loss = advantages.pow(2).mean()\n",
    "            actor_loss_card = -(selected_log_card_probs * advantages).mean()\n",
    "            actor_loss_draw = -(selected_log_draw_probs * advantages).mean()\n",
    "    \n",
    "            total_loss = critic_loss + actor_loss_card + actor_loss_draw\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    all_rewards.append(reward_p1)\n",
    "    all_rewards.append(reward_p2)    \n",
    "    mean_rewards.append(mean_reward)\n",
    "\n",
    "    if episode % 1000 == 0:\n",
    "        print(\"\\n=== Step Rule Firing Counts ===\")\n",
    "        for rule, count in sorted(rule_counter.items(), key=lambda x: -x[1]):\n",
    "            print(f\"{rule:<30}: {count}\")    \n",
    "    \n",
    "    if episode % 200 == 0:\n",
    "        avg_score = np.mean(all_rewards[-2000:]) if len(all_rewards) >= 2000 else np.mean(all_rewards)\n",
    "        print(f\"Episode {episode}, Average Reward Last {min(len(all_rewards), 1000)}: {avg_score:.2f}, eps={epsilon:.4f}\")\n",
    "        pd.Series(all_rewards).to_csv(file_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81139b17-fc42-47cf-bde3-448596ffd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lc_model_v1C_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e178f444-1675-4da7-a529-08eaf5010431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_bot(epsilon=0.0):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    play_cnt = 0\n",
    "\n",
    "    while not done:\n",
    "        play_cnt += 1\n",
    "        current_player = state['current_player']\n",
    "\n",
    "        print(f\"\\n=== Turn {play_cnt} — {current_player} ===\")\n",
    "\n",
    "        actions, draws = env.get_legal_actions(current_player)\n",
    "        valid_draws = [d for d in draws if d == 'deck' or (d in env.center_piles and env.center_piles[d])]\n",
    "\n",
    "        if not actions or not valid_draws:\n",
    "            print(\"No legal actions or draws. Ending game.\")\n",
    "            break\n",
    "\n",
    "        if current_player == 'P2':\n",
    "            # ===== HUMAN TURN =====\n",
    "            hand = state['hands'][current_player]\n",
    "            exped = env.expeditions[current_player]\n",
    "            center = env.center_piles\n",
    "            opp_exped = env.expeditions['P1']\n",
    "\n",
    "            exped_str = \" | \".join(f\"{color}:{exped.get(color, [])}\" for color in COLORS)\n",
    "            opp_exped_str = \" | \".join(f\"{color}:{opp_exped.get(color, [])}\" for color in COLORS)\n",
    "            center_str = \" | \".join(f\"{color}:{center[color]}\" for color in COLORS)\n",
    "\n",
    "            print(f\"Your hand: {hand}\")\n",
    "            print(f\"Your expeditions: {exped_str}\")\n",
    "            print(f\"Center piles: {center_str}\")\n",
    "            print(f\"Opponent expeditions: {opp_exped_str}\")\n",
    "            print(f\"Valid draws: {valid_draws}\")\n",
    "\n",
    "            user_input = input(\"Enter move as (E/C) CARD DRAW (e.g., E B3 D): \").strip().upper()\n",
    "            try:\n",
    "                move_type, card_str, draw_choice = user_input.split()\n",
    "                assert move_type in ['E', 'C']\n",
    "                assert any(card_str == card for _, card in actions), \"Invalid card\"\n",
    "                assert draw_choice in ['D'] + COLORS, \"Invalid draw\"\n",
    "            except Exception as e:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "\n",
    "            chosen_action = ('expedition', card_str) if move_type == 'E' else ('center', card_str)\n",
    "            chosen_draw = 'deck' if draw_choice == 'D' else draw_choice\n",
    "\n",
    "        else:\n",
    "            # ===== MODEL TURN =====\n",
    "            features_np = extract_features(state)\n",
    "            features = torch.tensor(features_np, dtype=torch.float32)\n",
    "            card_logits, draw_logits, value = model(features)\n",
    "\n",
    "            # Card action selection (no change)\n",
    "            card_probs = torch.softmax(card_logits[:len(actions)], dim=0)\n",
    "            card_dist = torch.distributions.Categorical(card_probs)\n",
    "            card_idx = card_dist.sample().item()\n",
    "            chosen_action = actions[card_idx]\n",
    "\n",
    "            # Filter valid draws based on chosen_action (if it's a center discard)\n",
    "            discard_color = None\n",
    "            if chosen_action[0] == 'center':\n",
    "                discard_color = chosen_action[1][0]\n",
    "            \n",
    "            filtered_draws = [\n",
    "                d for d in valid_draws if d != discard_color\n",
    "            ]\n",
    "            if not filtered_draws:\n",
    "                # Failsafe: fallback to deck\n",
    "                filtered_draws = ['deck']\n",
    "\n",
    "            valid_draws=filtered_draws\n",
    "            \n",
    "            # Draw choice selection (FIXED)\n",
    "            if random.random() < epsilon:\n",
    "                chosen_draw = random.choice(valid_draws)\n",
    "            else:\n",
    "                # Map valid draws to their indices in logits\n",
    "                draw_indices_in_logits = [draw_to_index[d] for d in valid_draws]\n",
    "                draw_logits_filtered = draw_logits[draw_indices_in_logits]\n",
    "                draw_probs = torch.softmax(draw_logits_filtered, dim=0)\n",
    "                draw_dist = torch.distributions.Categorical(draw_probs)\n",
    "                draw_idx = draw_dist.sample().item()\n",
    "                chosen_draw = valid_draws[draw_idx]\n",
    "\n",
    "            opp_hand = state['hands'][current_player]\n",
    "            print(f\"P1 plays: {chosen_action} | Draws: {chosen_draw} -- holding {opp_hand}\")\n",
    "\n",
    "        # Step and advance\n",
    "        next_state, reward, done = env.step(chosen_action, chosen_draw)\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            p1_score = env.compute_score('P1')\n",
    "            p2_score = env.compute_score('P2')\n",
    "            print(f\"\\n=== Game Over ===\")\n",
    "            print(f\"Final Score — P1: {p1_score} | P2: {p2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04655e75-7777-4871-adbb-f9abc72cbfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCritic(\n",
       "  (fc1): Linear(in_features=43, out_features=96, bias=True)\n",
       "  (fc2): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.15, inplace=False)\n",
       "  (policy_action_head): Linear(in_features=32, out_features=18, bias=True)\n",
       "  (policy_draw_head): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (value_head): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lc_model_v1B_2.pt'))\n",
    "model.eval()  # Important: sets model to evaluation mode (no dropout etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3b70826-0775-469b-8c72-34e923f851c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1 — P1 ===\n",
      "P1 plays: ('center', 'B3') | Draws: deck -- holding ['B3', 'B4', 'B6']\n",
      "\n",
      "=== Turn 2 — P2 ===\n",
      "Your hand: ['R2', 'R3', 'R6']\n",
      "Your expeditions: R:[] | B:[] | G:[]\n",
      "Center piles: R:[] | B:['B3'] | G:[]\n",
      "Opponent expeditions: R:[] | B:[] | G:[]\n",
      "Valid draws: ['deck', 'B']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m play_bot(\u001b[38;5;241m0.00\u001b[39m)\n",
      "Cell \u001b[1;32mIn[93], line 36\u001b[0m, in \u001b[0;36mplay_bot\u001b[1;34m(epsilon)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpponent expeditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopp_exped_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid draws: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_draws\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter move as (E/C) CARD DRAW (e.g., E B3 D): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     move_type, card_str, draw_choice \u001b[38;5;241m=\u001b[39m user_input\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "play_bot(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f86ea-effa-4a7a-8a03-ef5b72e471fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
