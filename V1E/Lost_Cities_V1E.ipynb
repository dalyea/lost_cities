{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4408281-2787-40fb-9f04-f78bc9f93220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lost Cities V1E\n",
    "# Starting with V1C\n",
    "# Creating separate main file and capturing all parameters together\n",
    "# Still using 43 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f1080e-db86-41cb-8856-a86311492b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import V1E_main as main\n",
    "from V1E_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb95ef46-cafe-44b4-bb18-23174bb15cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f5a96c-24fc-478e-a709-1593f45768fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL PARAMETERS\n",
    "# File version\n",
    "fv='V1E_2'\n",
    "file_name='all_rewards.'+fv+'.csv'\n",
    "\n",
    "nn_layer_1=96\n",
    "nn_layer_2=32\n",
    "nn_layer_2_dropout=0.20\n",
    "learning_rate=0.001\n",
    "replay_size=18000\n",
    "num_episodes = 60_000\n",
    "batch_size = 64\n",
    "batch_cnt = 3\n",
    "train_every = 5\n",
    "step_booster = 5.0\n",
    "episode_booster = 0.10 # 0.5 for 1, 1.0 for 2, 0.0 for 3\n",
    "all_rewards = []\n",
    "mean_rewards = []\n",
    "epsilon = 0.35\n",
    "epsilon_min = 0.030 # was 0.35 for .2.\n",
    "epsilon_decay = 0.999999  # adjust this rate as needed - 0.99995 is too low\n",
    "\n",
    "# Simply comment out any functions not to be included\n",
    "step_functions=[\n",
    "'lover_val_avail',\n",
    "'too_few_pts',\n",
    "'blocked_7',\n",
    "'exp_small_deck',\n",
    "'exp_was_live',\n",
    "'good_exp',\n",
    "'bad_X',\n",
    "'bad_bigger_val',\n",
    "'good_low_val',\n",
    "'draw_to_tgt',\n",
    "# 'had_X',\n",
    "'next_value',\n",
    "# 'bad_center',\n",
    "# 'smart_opp_center'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e1523c-7c20-47c2-a807-07b0f129621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to config_V1E_2.txt\n"
     ]
    }
   ],
   "source": [
    "config_dict = {\n",
    "    \"nn_layer_1\": nn_layer_1,\n",
    "    \"nn_layer_2\": nn_layer_2,\n",
    "    \"nn_layer_2_dropout\": nn_layer_2_dropout,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"replay_size\": replay_size,\n",
    "    \"num_episodes\": num_episodes,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"batch_cnt\": batch_cnt,\n",
    "    \"train_every\": train_every,\n",
    "    \"step_booster\": step_booster,\n",
    "    \"episode_booster\": episode_booster,\n",
    "    \"epsilon\": epsilon,\n",
    "    \"epsilon_min\": epsilon_min,\n",
    "    \"epsilon_decay\": epsilon_decay\n",
    "}\n",
    "\n",
    "save_config_txt(fv, config_dict, step_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c1d284-41ab-42ae-945b-c7ea70d062bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200, Average Reward Last 400: -1.21, eps=0.3480\n",
      "Episode 400, Average Reward Last 800: -1.25, eps=0.3458\n",
      "Episode 600, Average Reward Last 1000: -1.22, eps=0.3437\n",
      "Episode 800, Average Reward Last 1000: -1.50, eps=0.3416\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 6056\n",
      "good_exp_1                    : 4837\n",
      "too_few_pts                   : 3784\n",
      "good_exp                      : 3060\n",
      "blocked_7                     : 2663\n",
      "good_low_val                  : 2405\n",
      "exp_was_live                  : 1626\n",
      "next_value                    : 1494\n",
      "lower_val_avail               : 831\n",
      "bad_bigger_val                : 831\n",
      "exp_small_deck                : 768\n",
      "bad_X                         : 450\n",
      "Episode 1000, Average Reward Last 1000: -1.83, eps=0.3395\n",
      "Episode 1200, Average Reward Last 1000: -1.98, eps=0.3374\n",
      "Episode 1400, Average Reward Last 1000: -2.25, eps=0.3354\n",
      "Episode 1600, Average Reward Last 1000: -2.62, eps=0.3334\n",
      "Episode 1800, Average Reward Last 1000: -2.69, eps=0.3314\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 11915\n",
      "good_exp_1                    : 9631\n",
      "too_few_pts                   : 7733\n",
      "good_exp                      : 6086\n",
      "blocked_7                     : 5453\n",
      "good_low_val                  : 4742\n",
      "exp_was_live                  : 3379\n",
      "next_value                    : 2983\n",
      "lower_val_avail               : 1739\n",
      "bad_bigger_val                : 1739\n",
      "exp_small_deck                : 1520\n",
      "bad_X                         : 955\n",
      "Episode 2000, Average Reward Last 1000: -2.50, eps=0.3294\n",
      "Episode 2200, Average Reward Last 1000: -2.75, eps=0.3273\n",
      "Episode 2400, Average Reward Last 1000: -2.72, eps=0.3254\n",
      "Episode 2600, Average Reward Last 1000: -2.67, eps=0.3234\n",
      "Episode 2800, Average Reward Last 1000: -2.76, eps=0.3214\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 18056\n",
      "good_exp_1                    : 14457\n",
      "too_few_pts                   : 11720\n",
      "good_exp                      : 9124\n",
      "blocked_7                     : 8225\n",
      "good_low_val                  : 7177\n",
      "exp_was_live                  : 5196\n",
      "next_value                    : 4438\n",
      "lower_val_avail               : 2576\n",
      "bad_bigger_val                : 2576\n",
      "exp_small_deck                : 2321\n",
      "bad_X                         : 1491\n",
      "Episode 3000, Average Reward Last 1000: -2.93, eps=0.3195\n",
      "Episode 3200, Average Reward Last 1000: -2.91, eps=0.3176\n",
      "Episode 3400, Average Reward Last 1000: -2.97, eps=0.3156\n",
      "Episode 3600, Average Reward Last 1000: -2.94, eps=0.3138\n",
      "Episode 3800, Average Reward Last 1000: -2.79, eps=0.3119\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 24165\n",
      "good_exp_1                    : 19322\n",
      "too_few_pts                   : 15705\n",
      "good_exp                      : 12221\n",
      "blocked_7                     : 10988\n",
      "good_low_val                  : 9597\n",
      "exp_was_live                  : 6955\n",
      "next_value                    : 5888\n",
      "lower_val_avail               : 3482\n",
      "bad_bigger_val                : 3482\n",
      "exp_small_deck                : 3106\n",
      "bad_X                         : 2030\n",
      "Episode 4000, Average Reward Last 1000: -2.64, eps=0.3100\n",
      "Episode 4200, Average Reward Last 1000: -2.58, eps=0.3080\n",
      "Episode 4400, Average Reward Last 1000: -2.48, eps=0.3061\n",
      "Episode 4600, Average Reward Last 1000: -2.40, eps=0.3042\n",
      "Episode 4800, Average Reward Last 1000: -2.35, eps=0.3023\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 30512\n",
      "good_exp_1                    : 24266\n",
      "too_few_pts                   : 19637\n",
      "good_exp                      : 15395\n",
      "blocked_7                     : 13740\n",
      "good_low_val                  : 12126\n",
      "exp_was_live                  : 8777\n",
      "next_value                    : 7443\n",
      "lower_val_avail               : 4372\n",
      "bad_bigger_val                : 4372\n",
      "exp_small_deck                : 3887\n",
      "bad_X                         : 2578\n",
      "Episode 5000, Average Reward Last 1000: -2.34, eps=0.3004\n",
      "Episode 5200, Average Reward Last 1000: -2.23, eps=0.2985\n",
      "P1 1 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 2 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 3 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 4 - 0.1 * -12 + -1.3 = -2.5\n",
      "P1 5 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 6 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 7 - 0.1 * -12 + -0.2 = -1.4000000000000001\n",
      "P1 8 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 9 - 0.1 * -12 + 0.19999999999999996 = -1.0000000000000002\n",
      "P1 10 - 0.1 * -12 + -1.5 = -2.7\n",
      "P1 11 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 12 - 0.1 * -12 + 2.0 = 0.7999999999999998\n",
      "P1 13 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 14 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 15 - 0.1 * -12 + -1.5 = -2.7\n",
      "P1 16 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 17 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "Episode 5400, Average Reward Last 1000: -2.30, eps=0.2966\n",
      "Episode 5600, Average Reward Last 1000: -2.35, eps=0.2948\n",
      "Episode 5800, Average Reward Last 1000: -2.48, eps=0.2930\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 36700\n",
      "good_exp_1                    : 29186\n",
      "too_few_pts                   : 23666\n",
      "good_exp                      : 18533\n",
      "blocked_7                     : 16533\n",
      "good_low_val                  : 14602\n",
      "exp_was_live                  : 10608\n",
      "next_value                    : 8975\n",
      "lower_val_avail               : 5275\n",
      "bad_bigger_val                : 5275\n",
      "exp_small_deck                : 4703\n",
      "bad_X                         : 3165\n",
      "Episode 6000, Average Reward Last 1000: -2.39, eps=0.2912\n",
      "P1 1 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 2 - 0.1 * -9 + -1.3 = -2.2\n",
      "P1 3 - 0.1 * -9 + -1.5 = -2.4\n",
      "P1 4 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 5 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 6 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 7 - 0.1 * -9 + -0.2 = -1.1\n",
      "P1 8 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 9 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 10 - 0.1 * -9 + -1.5 = -2.4\n",
      "P1 11 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 12 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 13 - 0.1 * -9 + 1.5 = 0.6\n",
      "Episode 6200, Average Reward Last 1000: -2.30, eps=0.2894\n",
      "Episode 6400, Average Reward Last 1000: -2.26, eps=0.2876\n",
      "P1 1 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 2 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 3 - 0.1 * 7 + 2.0 = 2.7\n",
      "P1 4 - 0.1 * 7 + 0.6 = 1.3\n",
      "P1 5 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 6 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 7 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 8 - 0.1 * 7 + 2.0 = 2.7\n",
      "P1 9 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 10 - 0.1 * 7 + -0.7 = 1.1102230246251565e-16\n",
      "P1 11 - 0.1 * 7 + -0.39999999999999997 = 0.3000000000000001\n",
      "P1 12 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 13 - 0.1 * 7 + 2.0 = 2.7\n",
      "Episode 6600, Average Reward Last 1000: -2.27, eps=0.2858\n",
      "Episode 6800, Average Reward Last 1000: -2.14, eps=0.2840\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 42951\n",
      "good_exp_1                    : 34093\n",
      "too_few_pts                   : 27638\n",
      "good_exp                      : 21625\n",
      "blocked_7                     : 19308\n",
      "good_low_val                  : 17006\n",
      "exp_was_live                  : 12365\n",
      "next_value                    : 10508\n",
      "lower_val_avail               : 6196\n",
      "bad_bigger_val                : 6196\n",
      "exp_small_deck                : 5543\n",
      "bad_X                         : 3706\n",
      "Episode 7000, Average Reward Last 1000: -2.33, eps=0.2822\n",
      "Episode 7200, Average Reward Last 1000: -2.23, eps=0.2805\n",
      "Episode 7400, Average Reward Last 1000: -2.12, eps=0.2788\n",
      "Episode 7600, Average Reward Last 1000: -2.07, eps=0.2771\n",
      "Episode 7800, Average Reward Last 1000: -1.95, eps=0.2754\n",
      "P1 1 - 0.1 * 12 + -1.3 = -0.09999999999999987\n",
      "P1 2 - 0.1 * 12 + 0.0 = 1.2000000000000002\n",
      "P1 3 - 0.1 * 12 + 1.5 = 2.7\n",
      "P1 4 - 0.1 * 12 + 1.5 = 2.7\n",
      "P1 5 - 0.1 * 12 + 2.0 = 3.2\n",
      "P1 6 - 0.1 * 12 + -1.3 = -0.09999999999999987\n",
      "P1 7 - 0.1 * 12 + 2.0 = 3.2\n",
      "P1 8 - 0.1 * 12 + 0.0 = 1.2000000000000002\n",
      "P1 9 - 0.1 * 12 + 2.0 = 3.2\n",
      "P1 10 - 0.1 * 12 + 1.8 = 3.0\n",
      "P1 11 - 0.1 * 12 + -0.7 = 0.5000000000000002\n",
      "P1 12 - 0.1 * 12 + 0.3 = 1.5000000000000002\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 49014\n",
      "good_exp_1                    : 39104\n",
      "too_few_pts                   : 31612\n",
      "good_exp                      : 24751\n",
      "blocked_7                     : 22000\n",
      "good_low_val                  : 19463\n",
      "exp_was_live                  : 13913\n",
      "next_value                    : 12065\n",
      "lower_val_avail               : 7092\n",
      "bad_bigger_val                : 7092\n",
      "exp_small_deck                : 6354\n",
      "bad_X                         : 4237\n",
      "Episode 8000, Average Reward Last 1000: -1.74, eps=0.2737\n",
      "Episode 8200, Average Reward Last 1000: -1.93, eps=0.2720\n",
      "Episode 8400, Average Reward Last 1000: -1.83, eps=0.2704\n",
      "Episode 8600, Average Reward Last 1000: -1.65, eps=0.2687\n",
      "Episode 8800, Average Reward Last 1000: -1.72, eps=0.2671\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 54833\n",
      "good_exp_1                    : 44107\n",
      "too_few_pts                   : 35636\n",
      "good_exp                      : 27878\n",
      "blocked_7                     : 24714\n",
      "good_low_val                  : 21972\n",
      "exp_was_live                  : 15381\n",
      "next_value                    : 13654\n",
      "lower_val_avail               : 7969\n",
      "bad_bigger_val                : 7969\n",
      "exp_small_deck                : 7135\n",
      "bad_X                         : 4802\n",
      "Episode 9000, Average Reward Last 1000: -1.74, eps=0.2655\n",
      "Episode 9200, Average Reward Last 1000: -1.60, eps=0.2639\n",
      "Episode 9400, Average Reward Last 1000: -1.60, eps=0.2622\n",
      "Episode 9600, Average Reward Last 1000: -1.65, eps=0.2606\n",
      "Episode 9800, Average Reward Last 1000: -1.59, eps=0.2590\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 60707\n",
      "good_exp_1                    : 49189\n",
      "too_few_pts                   : 39613\n",
      "good_exp                      : 31048\n",
      "blocked_7                     : 27431\n",
      "good_low_val                  : 24463\n",
      "exp_was_live                  : 16779\n",
      "next_value                    : 15283\n",
      "lower_val_avail               : 8898\n",
      "bad_bigger_val                : 8898\n",
      "exp_small_deck                : 7920\n",
      "bad_X                         : 5350\n",
      "Episode 10000, Average Reward Last 1000: -1.52, eps=0.2574\n",
      "Episode 10200, Average Reward Last 1000: -1.43, eps=0.2557\n",
      "Episode 10400, Average Reward Last 1000: -1.61, eps=0.2541\n",
      "Episode 10600, Average Reward Last 1000: -1.45, eps=0.2525\n",
      "Episode 10800, Average Reward Last 1000: -1.43, eps=0.2510\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 66781\n",
      "good_exp_1                    : 54316\n",
      "too_few_pts                   : 43574\n",
      "good_exp                      : 34268\n",
      "blocked_7                     : 30126\n",
      "good_low_val                  : 27049\n",
      "exp_was_live                  : 18241\n",
      "next_value                    : 16992\n",
      "lower_val_avail               : 9802\n",
      "bad_bigger_val                : 9802\n",
      "exp_small_deck                : 8765\n",
      "bad_X                         : 5915\n",
      "Episode 11000, Average Reward Last 1000: -1.33, eps=0.2494\n",
      "Episode 11200, Average Reward Last 1000: -1.36, eps=0.2479\n",
      "Episode 11400, Average Reward Last 1000: -1.08, eps=0.2464\n",
      "Episode 11600, Average Reward Last 1000: -1.24, eps=0.2449\n",
      "Episode 11800, Average Reward Last 1000: -1.27, eps=0.2434\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 72334\n",
      "good_exp_1                    : 59510\n",
      "too_few_pts                   : 47595\n",
      "good_exp                      : 37491\n",
      "blocked_7                     : 32828\n",
      "good_low_val                  : 29652\n",
      "exp_was_live                  : 19550\n",
      "next_value                    : 18668\n",
      "lower_val_avail               : 10685\n",
      "bad_bigger_val                : 10685\n",
      "exp_small_deck                : 9550\n",
      "bad_X                         : 6511\n",
      "Episode 12000, Average Reward Last 1000: -1.35, eps=0.2419\n",
      "Episode 12200, Average Reward Last 1000: -1.42, eps=0.2405\n",
      "Episode 12400, Average Reward Last 1000: -1.54, eps=0.2392\n",
      "Episode 12600, Average Reward Last 1000: -1.48, eps=0.2378\n",
      "P1 1 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 2 - 0.1 * -10 + -0.5 = -1.5\n",
      "P1 3 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 4 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 5 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 6 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 7 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 8 - 0.1 * -10 + 2.0 = 1.0\n",
      "P1 9 - 0.1 * -10 + 1.5 = 0.5\n",
      "P1 10 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 11 - 0.1 * -10 + 0.0 = -1.0\n",
      "P1 12 - 0.1 * -10 + 1.5 = 0.5\n",
      "P1 13 - 0.1 * -10 + 0.0 = -1.0\n",
      "Episode 12800, Average Reward Last 1000: -1.41, eps=0.2363\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 77753\n",
      "good_exp_1                    : 64747\n",
      "too_few_pts                   : 51617\n",
      "good_exp                      : 40806\n",
      "blocked_7                     : 35513\n",
      "good_low_val                  : 32333\n",
      "exp_was_live                  : 20855\n",
      "next_value                    : 20331\n",
      "lower_val_avail               : 11584\n",
      "bad_bigger_val                : 11584\n",
      "exp_small_deck                : 10337\n",
      "bad_X                         : 7108\n",
      "Episode 13000, Average Reward Last 1000: -1.41, eps=0.2349\n",
      "Episode 13200, Average Reward Last 1000: -1.39, eps=0.2335\n",
      "P1 1 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 2 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 3 - 0.1 * 3 + 0.5 = 0.8\n",
      "P1 4 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 5 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 6 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 7 - 0.1 * 3 + -1.3 = -1.0\n",
      "P1 8 - 0.1 * 3 + 0.6 = 0.9\n",
      "P1 9 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 10 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 11 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 12 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 13 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 14 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 15 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 16 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 17 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 18 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 19 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 20 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 21 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "Episode 13400, Average Reward Last 1000: -1.27, eps=0.2321\n",
      "Episode 13600, Average Reward Last 1000: -1.12, eps=0.2307\n",
      "Episode 13800, Average Reward Last 1000: -1.21, eps=0.2293\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 83403\n",
      "good_exp_1                    : 69999\n",
      "too_few_pts                   : 55679\n",
      "good_exp                      : 44076\n",
      "blocked_7                     : 38239\n",
      "good_low_val                  : 34988\n",
      "exp_was_live                  : 22129\n",
      "next_value                    : 22104\n",
      "lower_val_avail               : 12482\n",
      "bad_bigger_val                : 12482\n",
      "exp_small_deck                : 11139\n",
      "bad_X                         : 7680\n",
      "Episode 14000, Average Reward Last 1000: -1.32, eps=0.2279\n",
      "Episode 14200, Average Reward Last 1000: -1.47, eps=0.2266\n",
      "Episode 14400, Average Reward Last 1000: -1.60, eps=0.2253\n",
      "Episode 14600, Average Reward Last 1000: -1.59, eps=0.2239\n",
      "Episode 14800, Average Reward Last 1000: -1.49, eps=0.2226\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 88520\n",
      "good_exp_1                    : 75236\n",
      "too_few_pts                   : 59773\n",
      "good_exp                      : 47334\n",
      "blocked_7                     : 40966\n",
      "good_low_val                  : 37644\n",
      "next_value                    : 23870\n",
      "exp_was_live                  : 23270\n",
      "lower_val_avail               : 13369\n",
      "bad_bigger_val                : 13369\n",
      "exp_small_deck                : 11936\n",
      "bad_X                         : 8250\n",
      "Episode 15000, Average Reward Last 1000: -1.17, eps=0.2214\n",
      "Episode 15200, Average Reward Last 1000: -0.96, eps=0.2200\n",
      "Episode 15400, Average Reward Last 1000: -0.89, eps=0.2187\n",
      "Episode 15600, Average Reward Last 1000: -1.15, eps=0.2174\n",
      "Episode 15800, Average Reward Last 1000: -1.23, eps=0.2161\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 94018\n",
      "good_exp_1                    : 80391\n",
      "too_few_pts                   : 63828\n",
      "good_exp                      : 50556\n",
      "blocked_7                     : 43698\n",
      "good_low_val                  : 40224\n",
      "next_value                    : 25581\n",
      "exp_was_live                  : 24573\n",
      "lower_val_avail               : 14294\n",
      "bad_bigger_val                : 14294\n",
      "exp_small_deck                : 12776\n",
      "bad_X                         : 8809\n",
      "Episode 16000, Average Reward Last 1000: -1.47, eps=0.2149\n",
      "Episode 16200, Average Reward Last 1000: -1.67, eps=0.2136\n",
      "Episode 16400, Average Reward Last 1000: -1.91, eps=0.2122\n",
      "Episode 16600, Average Reward Last 1000: -1.96, eps=0.2110\n",
      "Episode 16800, Average Reward Last 1000: -2.17, eps=0.2099\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 99376\n",
      "good_exp_1                    : 85451\n",
      "too_few_pts                   : 67885\n",
      "good_exp                      : 53757\n",
      "blocked_7                     : 46407\n",
      "good_low_val                  : 42826\n",
      "next_value                    : 27218\n",
      "exp_was_live                  : 25874\n",
      "lower_val_avail               : 15160\n",
      "bad_bigger_val                : 15160\n",
      "exp_small_deck                : 13560\n",
      "bad_X                         : 9490\n",
      "Episode 17000, Average Reward Last 1000: -2.20, eps=0.2088\n",
      "Episode 17200, Average Reward Last 1000: -2.10, eps=0.2077\n",
      "Episode 17400, Average Reward Last 1000: -2.15, eps=0.2066\n",
      "Episode 17600, Average Reward Last 1000: -2.16, eps=0.2055\n",
      "Episode 17800, Average Reward Last 1000: -2.05, eps=0.2044\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 103810\n",
      "good_exp_1                    : 90745\n",
      "too_few_pts                   : 72100\n",
      "good_exp                      : 57055\n",
      "blocked_7                     : 49191\n",
      "good_low_val                  : 45579\n",
      "next_value                    : 28828\n",
      "exp_was_live                  : 26876\n",
      "lower_val_avail               : 16012\n",
      "bad_bigger_val                : 16012\n",
      "exp_small_deck                : 14280\n",
      "bad_X                         : 10193\n",
      "Episode 18000, Average Reward Last 1000: -2.03, eps=0.2033\n",
      "Episode 18200, Average Reward Last 1000: -2.07, eps=0.2023\n",
      "P1 1 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 2 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 3 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 4 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 5 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 6 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 7 - 0.1 * -14 + 1.5 = 0.09999999999999987\n",
      "P1 8 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 9 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 10 - 0.1 * -14 + 1.0 = -0.40000000000000013\n",
      "P1 11 - 0.1 * -14 + -2.5 = -3.9000000000000004\n",
      "P1 12 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 13 - 0.1 * -14 + 0.0 = -1.4000000000000001\n",
      "P1 14 - 0.1 * -14 + -0.7 = -2.1\n",
      "Episode 18400, Average Reward Last 1000: -1.94, eps=0.2012\n",
      "Episode 18600, Average Reward Last 1000: -1.78, eps=0.2002\n",
      "Episode 18800, Average Reward Last 1000: -1.88, eps=0.1991\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 107988\n",
      "good_exp_1                    : 96004\n",
      "too_few_pts                   : 76206\n",
      "good_exp                      : 60388\n",
      "blocked_7                     : 51855\n",
      "good_low_val                  : 48375\n",
      "next_value                    : 30500\n",
      "exp_was_live                  : 27722\n",
      "lower_val_avail               : 16876\n",
      "bad_bigger_val                : 16876\n",
      "exp_small_deck                : 15009\n",
      "bad_X                         : 10896\n",
      "Episode 19000, Average Reward Last 1000: -1.83, eps=0.1981\n",
      "Episode 19200, Average Reward Last 1000: -1.78, eps=0.1971\n",
      "Episode 19400, Average Reward Last 1000: -1.66, eps=0.1961\n",
      "Episode 19600, Average Reward Last 1000: -1.67, eps=0.1952\n",
      "Episode 19800, Average Reward Last 1000: -1.61, eps=0.1942\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 111925\n",
      "good_exp_1                    : 101276\n",
      "too_few_pts                   : 80391\n",
      "good_exp                      : 63659\n",
      "blocked_7                     : 54604\n",
      "good_low_val                  : 51117\n",
      "next_value                    : 32139\n",
      "exp_was_live                  : 28590\n",
      "lower_val_avail               : 17731\n",
      "bad_bigger_val                : 17731\n",
      "exp_small_deck                : 15700\n",
      "bad_X                         : 11533\n",
      "Episode 20000, Average Reward Last 1000: -1.63, eps=0.1932\n",
      "Episode 20200, Average Reward Last 1000: -1.47, eps=0.1922\n",
      "Episode 20400, Average Reward Last 1000: -1.34, eps=0.1913\n",
      "P1 1 - 0.1 * 23 + -1.0 = 1.3000000000000003\n",
      "P1 2 - 0.1 * 23 + 0.0 = 2.3000000000000003\n",
      "P1 3 - 0.1 * 23 + -1.3 = 1.0000000000000002\n",
      "P1 4 - 0.1 * 23 + 0.0 = 2.3000000000000003\n",
      "P1 5 - 0.1 * 23 + -3.3 = -0.9999999999999996\n",
      "P1 6 - 0.1 * 23 + 1.5 = 3.8000000000000003\n",
      "P1 7 - 0.1 * 23 + 0.3 = 2.6\n",
      "P1 8 - 0.1 * 23 + 0.0 = 2.3000000000000003\n",
      "P1 9 - 0.1 * 23 + 0.6 = 2.9000000000000004\n",
      "P1 10 - 0.1 * 23 + 0.0 = 2.3000000000000003\n",
      "P1 11 - 0.1 * 23 + 2.0 = 4.300000000000001\n",
      "P1 12 - 0.1 * 23 + 0.0 = 2.3000000000000003\n",
      "P1 13 - 0.1 * 23 + 0.3 = 2.6\n",
      "Episode 20600, Average Reward Last 1000: -1.21, eps=0.1903\n",
      "P1 1 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 2 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 3 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 4 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 5 - 0.1 * 2 + 1.0 = 1.2\n",
      "P1 6 - 0.1 * 2 + 2.0 = 2.2\n",
      "P1 7 - 0.1 * 2 + 2.0 = 2.2\n",
      "P1 8 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 9 - 0.1 * 2 + -1.0 = -0.8\n",
      "P1 10 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 11 - 0.1 * 2 + 0.0 = 0.2\n",
      "Episode 20800, Average Reward Last 1000: -0.95, eps=0.1894\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 115903\n",
      "good_exp_1                    : 106701\n",
      "too_few_pts                   : 84518\n",
      "good_exp                      : 66977\n",
      "blocked_7                     : 57241\n",
      "good_low_val                  : 53923\n",
      "next_value                    : 33927\n",
      "exp_was_live                  : 29299\n",
      "lower_val_avail               : 18548\n",
      "bad_bigger_val                : 18548\n",
      "exp_small_deck                : 16385\n",
      "bad_X                         : 12041\n",
      "Episode 21000, Average Reward Last 1000: -0.65, eps=0.1884\n",
      "Episode 21200, Average Reward Last 1000: -0.55, eps=0.1876\n",
      "Episode 21400, Average Reward Last 1000: -0.61, eps=0.1867\n",
      "Episode 21600, Average Reward Last 1000: -0.50, eps=0.1857\n",
      "P1 1 - 0.1 * 11 + -1.3 = -0.19999999999999996\n",
      "P1 2 - 0.1 * 11 + 2.0 = 3.1\n",
      "P1 3 - 0.1 * 11 + 0.0 = 1.1\n",
      "P1 4 - 0.1 * 11 + 0.5 = 1.6\n",
      "P1 5 - 0.1 * 11 + 0.8 = 1.9000000000000001\n",
      "P1 6 - 0.1 * 11 + 1.5 = 2.6\n",
      "P1 7 - 0.1 * 11 + 2.0 = 3.1\n",
      "P1 8 - 0.1 * 11 + 0.0 = 1.1\n",
      "P1 9 - 0.1 * 11 + 0.3 = 1.4000000000000001\n",
      "P1 10 - 0.1 * 11 + 0.0 = 1.1\n",
      "P1 11 - 0.1 * 11 + 0.0 = 1.1\n",
      "P1 12 - 0.1 * 11 + 0.0 = 1.1\n",
      "P1 13 - 0.1 * 11 + 0.3 = 1.4000000000000001\n",
      "P1 1 - 0.1 * 5 + 0.0 = 0.5\n",
      "P1 2 - 0.1 * 5 + -1.3 = -0.8\n",
      "P1 3 - 0.1 * 5 + 1.3 = 1.8\n",
      "P1 4 - 0.1 * 5 + 2.0 = 2.5\n",
      "P1 5 - 0.1 * 5 + 0.0 = 0.5\n",
      "P1 6 - 0.1 * 5 + 0.3 = 0.8\n",
      "P1 7 - 0.1 * 5 + 0.3 = 0.8\n",
      "P1 8 - 0.1 * 5 + 0.0 = 0.5\n",
      "Episode 21800, Average Reward Last 1000: -0.29, eps=0.1848\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 119807\n",
      "good_exp_1                    : 112122\n",
      "too_few_pts                   : 88663\n",
      "good_exp                      : 70259\n",
      "blocked_7                     : 59834\n",
      "good_low_val                  : 56657\n",
      "next_value                    : 35778\n",
      "exp_was_live                  : 30124\n",
      "lower_val_avail               : 19382\n",
      "bad_bigger_val                : 19382\n",
      "exp_small_deck                : 17071\n",
      "bad_X                         : 12490\n",
      "Episode 22000, Average Reward Last 1000: -0.50, eps=0.1838\n",
      "Episode 22200, Average Reward Last 1000: -0.66, eps=0.1828\n",
      "Episode 22400, Average Reward Last 1000: -0.67, eps=0.1817\n",
      "Episode 22600, Average Reward Last 1000: -0.86, eps=0.1807\n",
      "Episode 22800, Average Reward Last 1000: -1.08, eps=0.1798\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 124454\n",
      "good_exp_1                    : 117440\n",
      "too_few_pts                   : 92760\n",
      "good_exp                      : 73540\n",
      "blocked_7                     : 62485\n",
      "good_low_val                  : 59349\n",
      "next_value                    : 37529\n",
      "exp_was_live                  : 31177\n",
      "lower_val_avail               : 20250\n",
      "bad_bigger_val                : 20250\n",
      "exp_small_deck                : 17744\n",
      "bad_X                         : 13008\n",
      "Episode 23000, Average Reward Last 1000: -0.77, eps=0.1789\n",
      "Episode 23200, Average Reward Last 1000: -0.50, eps=0.1780\n",
      "Episode 23400, Average Reward Last 1000: -0.34, eps=0.1770\n",
      "Episode 23600, Average Reward Last 1000: -0.10, eps=0.1757\n",
      "Episode 23800, Average Reward Last 1000: -0.19, eps=0.1745\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 130875\n",
      "good_exp_1                    : 122624\n",
      "too_few_pts                   : 96683\n",
      "good_exp                      : 76805\n",
      "blocked_7                     : 65099\n",
      "good_low_val                  : 61990\n",
      "next_value                    : 39324\n",
      "exp_was_live                  : 32477\n",
      "lower_val_avail               : 21159\n",
      "bad_bigger_val                : 21159\n",
      "exp_small_deck                : 18529\n",
      "bad_X                         : 13461\n",
      "Episode 24000, Average Reward Last 1000: -0.47, eps=0.1731\n",
      "Episode 24200, Average Reward Last 1000: -0.87, eps=0.1716\n",
      "Episode 24400, Average Reward Last 1000: -1.16, eps=0.1702\n",
      "Episode 24600, Average Reward Last 1000: -1.25, eps=0.1689\n",
      "Episode 24800, Average Reward Last 1000: -1.08, eps=0.1677\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 139776\n",
      "good_exp_1                    : 127643\n",
      "too_few_pts                   : 100497\n",
      "good_exp                      : 80014\n",
      "blocked_7                     : 67738\n",
      "good_low_val                  : 64525\n",
      "next_value                    : 41029\n",
      "exp_was_live                  : 34848\n",
      "lower_val_avail               : 22066\n",
      "bad_bigger_val                : 22066\n",
      "exp_small_deck                : 19426\n",
      "bad_X                         : 13945\n",
      "Episode 25000, Average Reward Last 1000: -1.53, eps=0.1664\n",
      "Episode 25200, Average Reward Last 1000: -1.78, eps=0.1650\n",
      "P1 1 - 0.1 * 2 + -3.3 = -3.0999999999999996\n",
      "P1 2 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 3 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 4 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 5 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 6 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 7 - 0.1 * 2 + 0.19999999999999996 = 0.39999999999999997\n",
      "P1 8 - 0.1 * 2 + 0.3 = 0.5\n",
      "P1 9 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 10 - 0.1 * 2 + 2.0 = 2.2\n",
      "P1 11 - 0.1 * 2 + 0.3 = 0.5\n",
      "P1 12 - 0.1 * 2 + 0.0 = 0.2\n",
      "Episode 25400, Average Reward Last 1000: -2.26, eps=0.1640\n",
      "Episode 25600, Average Reward Last 1000: -2.98, eps=0.1628\n",
      "Episode 25800, Average Reward Last 1000: -3.49, eps=0.1617\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 147550\n",
      "good_exp_1                    : 132530\n",
      "too_few_pts                   : 104620\n",
      "good_exp                      : 83176\n",
      "blocked_7                     : 70586\n",
      "good_low_val                  : 67024\n",
      "next_value                    : 42615\n",
      "exp_was_live                  : 37180\n",
      "lower_val_avail               : 22900\n",
      "bad_bigger_val                : 22900\n",
      "exp_small_deck                : 20300\n",
      "bad_X                         : 14657\n",
      "Episode 26000, Average Reward Last 1000: -3.17, eps=0.1606\n",
      "Episode 26200, Average Reward Last 1000: -2.83, eps=0.1598\n",
      "Episode 26400, Average Reward Last 1000: -2.23, eps=0.1591\n",
      "P1 1 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 2 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 3 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 4 - 0.1 * 1 + -0.5 = -0.4\n",
      "P1 5 - 0.1 * 1 + 2.0 = 2.1\n",
      "P1 6 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 7 - 0.1 * 1 + 1.5 = 1.6\n",
      "P1 8 - 0.1 * 1 + 1.1 = 1.2000000000000002\n",
      "P1 9 - 0.1 * 1 + 1.8 = 1.9000000000000001\n",
      "P1 10 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 11 - 0.1 * 1 + 0.0 = 0.1\n",
      "P1 12 - 0.1 * 1 + -1.0 = -0.9\n",
      "P1 1 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 2 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 3 - 0.1 * -2 + 0.19999999999999996 = -5.551115123125783e-17\n",
      "P1 4 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 5 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 6 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 7 - 0.1 * -2 + 2.0 = 1.8\n",
      "P1 8 - 0.1 * -2 + -0.5 = -0.7\n",
      "P1 9 - 0.1 * -2 + 2.0 = 1.8\n",
      "P1 10 - 0.1 * -2 + 2.0 = 1.8\n",
      "P1 11 - 0.1 * -2 + 0.0 = -0.2\n",
      "Episode 26600, Average Reward Last 1000: -1.43, eps=0.1583\n",
      "Episode 26800, Average Reward Last 1000: -0.99, eps=0.1575\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 150973\n",
      "good_exp_1                    : 138079\n",
      "too_few_pts                   : 108691\n",
      "good_exp                      : 86625\n",
      "blocked_7                     : 73057\n",
      "good_low_val                  : 69981\n",
      "next_value                    : 44473\n",
      "exp_was_live                  : 37663\n",
      "lower_val_avail               : 23764\n",
      "bad_bigger_val                : 23764\n",
      "exp_small_deck                : 21062\n",
      "bad_X                         : 15293\n",
      "Episode 27000, Average Reward Last 1000: -0.80, eps=0.1568\n",
      "Episode 27200, Average Reward Last 1000: -0.45, eps=0.1561\n",
      "Episode 27400, Average Reward Last 1000: -0.15, eps=0.1554\n",
      "Episode 27600, Average Reward Last 1000: -0.13, eps=0.1543\n",
      "P1 1 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 2 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 3 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 4 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 5 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 6 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 7 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 8 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 9 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 10 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 11 - 0.1 * -2 + 2.0 = 1.8\n",
      "P1 12 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 13 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 14 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 15 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 16 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 17 - 0.1 * -2 + 0.0 = -0.2\n",
      "P1 18 - 0.1 * -2 + -1.0 = -1.2\n",
      "P1 19 - 0.1 * -2 + -0.7 = -0.8999999999999999\n",
      "Episode 27800, Average Reward Last 1000: 0.06, eps=0.1534\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 155608\n",
      "good_exp_1                    : 143720\n",
      "too_few_pts                   : 112470\n",
      "good_exp                      : 90182\n",
      "blocked_7                     : 75407\n",
      "good_low_val                  : 73013\n",
      "next_value                    : 46491\n",
      "exp_was_live                  : 38283\n",
      "lower_val_avail               : 24609\n",
      "bad_bigger_val                : 24609\n",
      "exp_small_deck                : 21870\n",
      "bad_X                         : 15834\n",
      "Episode 28000, Average Reward Last 1000: 0.29, eps=0.1525\n",
      "Episode 28200, Average Reward Last 1000: 0.35, eps=0.1515\n",
      "Episode 28400, Average Reward Last 1000: 0.41, eps=0.1505\n",
      "Episode 28600, Average Reward Last 1000: 0.64, eps=0.1495\n",
      "Episode 28800, Average Reward Last 1000: 0.73, eps=0.1484\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 162403\n",
      "good_exp_1                    : 149247\n",
      "too_few_pts                   : 116064\n",
      "good_exp                      : 93680\n",
      "blocked_7                     : 77696\n",
      "good_low_val                  : 75859\n",
      "next_value                    : 48620\n",
      "exp_was_live                  : 39244\n",
      "lower_val_avail               : 25550\n",
      "bad_bigger_val                : 25550\n",
      "exp_small_deck                : 22767\n",
      "bad_X                         : 16319\n",
      "Episode 29000, Average Reward Last 1000: 0.88, eps=0.1471\n",
      "Episode 29200, Average Reward Last 1000: 0.80, eps=0.1459\n",
      "Episode 29400, Average Reward Last 1000: 0.73, eps=0.1448\n",
      "Episode 29600, Average Reward Last 1000: 0.67, eps=0.1437\n",
      "Episode 29800, Average Reward Last 1000: 0.64, eps=0.1427\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 169565\n",
      "good_exp_1                    : 154784\n",
      "too_few_pts                   : 119664\n",
      "good_exp                      : 97181\n",
      "blocked_7                     : 80053\n",
      "good_low_val                  : 78792\n",
      "next_value                    : 50681\n",
      "exp_was_live                  : 40402\n",
      "lower_val_avail               : 26402\n",
      "bad_bigger_val                : 26402\n",
      "exp_small_deck                : 23655\n",
      "bad_X                         : 16808\n",
      "Episode 30000, Average Reward Last 1000: 0.50, eps=0.1418\n",
      "Episode 30200, Average Reward Last 1000: 0.39, eps=0.1410\n",
      "P1 1 - 0.1 * -9 + -1.3 = -2.2\n",
      "P1 2 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 3 - 0.1 * -9 + -1.3 = -2.2\n",
      "P1 4 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 5 - 0.1 * -9 + -3.3 = -4.2\n",
      "P1 6 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 7 - 0.1 * -9 + -1.5 = -2.4\n",
      "P1 8 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 9 - 0.1 * -9 + -1.5 = -2.4\n",
      "P1 10 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 11 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 12 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 13 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 14 - 0.1 * -9 + 1.5 = 0.6\n",
      "P1 15 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 16 - 0.1 * -9 + -0.7 = -1.6\n",
      "P1 17 - 0.1 * -9 + 0.0 = -0.9\n",
      "Episode 30400, Average Reward Last 1000: 0.13, eps=0.1402\n",
      "Episode 30600, Average Reward Last 1000: -0.22, eps=0.1393\n",
      "Episode 30800, Average Reward Last 1000: -0.15, eps=0.1385\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 175091\n",
      "good_exp_1                    : 160200\n",
      "too_few_pts                   : 123585\n",
      "good_exp                      : 100555\n",
      "blocked_7                     : 82576\n",
      "good_low_val                  : 81549\n",
      "next_value                    : 52624\n",
      "exp_was_live                  : 41587\n",
      "lower_val_avail               : 27350\n",
      "bad_bigger_val                : 27350\n",
      "exp_small_deck                : 24420\n",
      "bad_X                         : 17218\n",
      "Episode 31000, Average Reward Last 1000: -0.11, eps=0.1376\n",
      "Episode 31200, Average Reward Last 1000: 0.01, eps=0.1368\n",
      "Episode 31400, Average Reward Last 1000: 0.32, eps=0.1360\n",
      "P1 1 - 0.1 * 4 + -1.3 = -0.9\n",
      "P1 2 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 3 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 4 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 5 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 6 - 0.1 * 4 + -1.3 = -0.9\n",
      "P1 7 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 8 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 9 - 0.1 * 4 + -1.3 = -0.9\n",
      "P1 10 - 0.1 * 4 + -1.9000000000000001 = -1.5\n",
      "P1 11 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 12 - 0.1 * 4 + 0.6 = 1.0\n",
      "P1 13 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 14 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 15 - 0.1 * 4 + 0.0 = 0.4\n",
      "Episode 31600, Average Reward Last 1000: 0.64, eps=0.1353\n",
      "Episode 31800, Average Reward Last 1000: 0.69, eps=0.1343\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 181186\n",
      "good_exp_1                    : 165595\n",
      "too_few_pts                   : 127380\n",
      "good_exp                      : 103877\n",
      "blocked_7                     : 84979\n",
      "good_low_val                  : 84222\n",
      "next_value                    : 54567\n",
      "exp_was_live                  : 42683\n",
      "lower_val_avail               : 28269\n",
      "bad_bigger_val                : 28269\n",
      "exp_small_deck                : 25231\n",
      "bad_X                         : 17609\n",
      "Episode 32000, Average Reward Last 1000: 0.52, eps=0.1332\n",
      "Episode 32200, Average Reward Last 1000: 0.67, eps=0.1321\n",
      "Episode 32400, Average Reward Last 1000: 0.36, eps=0.1309\n",
      "Episode 32600, Average Reward Last 1000: 0.29, eps=0.1298\n",
      "P1 1 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 2 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 3 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 4 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 5 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 6 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 7 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 8 - 0.1 * -16 + 1.0 = -0.6000000000000001\n",
      "P1 9 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 10 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 11 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 12 - 0.1 * -16 + -3.3 = -4.9\n",
      "P1 13 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 14 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 15 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 16 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 17 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 18 - 0.1 * -16 + -0.2 = -1.8\n",
      "P1 19 - 0.1 * -16 + 2.0 = 0.3999999999999999\n",
      "P1 20 - 0.1 * -16 + -1.5 = -3.1\n",
      "Episode 32800, Average Reward Last 1000: 0.05, eps=0.1287\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 190395\n",
      "good_exp_1                    : 170781\n",
      "too_few_pts                   : 131009\n",
      "good_exp                      : 107198\n",
      "blocked_7                     : 87458\n",
      "good_low_val                  : 86787\n",
      "next_value                    : 56512\n",
      "exp_was_live                  : 44391\n",
      "lower_val_avail               : 29285\n",
      "bad_bigger_val                : 29285\n",
      "exp_small_deck                : 26133\n",
      "bad_X                         : 18059\n",
      "Episode 33000, Average Reward Last 1000: 0.22, eps=0.1276\n",
      "Episode 33200, Average Reward Last 1000: 0.20, eps=0.1266\n",
      "Episode 33400, Average Reward Last 1000: 0.62, eps=0.1258\n",
      "Episode 33600, Average Reward Last 1000: 0.74, eps=0.1251\n",
      "P1 1 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 2 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 3 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 4 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 5 - 0.1 * 8 + 0.3 = 1.1\n",
      "P1 6 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 7 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 8 - 0.1 * 8 + 0.3 = 1.1\n",
      "Episode 33800, Average Reward Last 1000: 1.02, eps=0.1244\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 195683\n",
      "good_exp_1                    : 176415\n",
      "too_few_pts                   : 134653\n",
      "good_exp                      : 110725\n",
      "good_low_val                  : 89693\n",
      "blocked_7                     : 89667\n",
      "next_value                    : 58649\n",
      "exp_was_live                  : 45052\n",
      "lower_val_avail               : 30206\n",
      "bad_bigger_val                : 30206\n",
      "exp_small_deck                : 26951\n",
      "bad_X                         : 18446\n",
      "Episode 34000, Average Reward Last 1000: 1.16, eps=0.1238\n",
      "Episode 34200, Average Reward Last 1000: 1.09, eps=0.1232\n",
      "Episode 34400, Average Reward Last 1000: 0.98, eps=0.1227\n",
      "Episode 34600, Average Reward Last 1000: 0.92, eps=0.1222\n",
      "Episode 34800, Average Reward Last 1000: 0.87, eps=0.1217\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 198334\n",
      "good_exp_1                    : 182271\n",
      "too_few_pts                   : 138435\n",
      "good_exp                      : 114287\n",
      "good_low_val                  : 92794\n",
      "blocked_7                     : 91836\n",
      "next_value                    : 60663\n",
      "exp_was_live                  : 45275\n",
      "lower_val_avail               : 31015\n",
      "bad_bigger_val                : 31015\n",
      "exp_small_deck                : 27678\n",
      "bad_X                         : 18918\n",
      "Episode 35000, Average Reward Last 1000: 0.88, eps=0.1212\n",
      "Episode 35200, Average Reward Last 1000: 0.97, eps=0.1205\n",
      "Episode 35400, Average Reward Last 1000: 0.98, eps=0.1199\n",
      "P1 1 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 2 - 0.1 * -9 + -1.3 = -2.2\n",
      "P1 3 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 4 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 5 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 6 - 0.1 * -9 + -3.3 = -4.2\n",
      "P1 7 - 0.1 * -9 + 2.0 = 1.1\n",
      "P1 8 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 9 - 0.1 * -9 + 0.3 = -0.6000000000000001\n",
      "P1 10 - 0.1 * -9 + 0.0 = -0.9\n",
      "P1 11 - 0.1 * -9 + 0.3 = -0.6000000000000001\n",
      "P1 12 - 0.1 * -9 + -1.5 = -2.4\n",
      "P1 13 - 0.1 * -9 + 0.0 = -0.9\n",
      "Episode 35600, Average Reward Last 1000: 0.99, eps=0.1193\n",
      "Episode 35800, Average Reward Last 1000: 1.03, eps=0.1185\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 203476\n",
      "good_exp_1                    : 187883\n",
      "too_few_pts                   : 142099\n",
      "good_exp                      : 117753\n",
      "good_low_val                  : 95714\n",
      "blocked_7                     : 94108\n",
      "next_value                    : 62696\n",
      "exp_was_live                  : 45941\n",
      "lower_val_avail               : 31932\n",
      "bad_bigger_val                : 31932\n",
      "exp_small_deck                : 28500\n",
      "bad_X                         : 19393\n",
      "Episode 36000, Average Reward Last 1000: 1.03, eps=0.1175\n",
      "Episode 36200, Average Reward Last 1000: 0.78, eps=0.1165\n",
      "Episode 36400, Average Reward Last 1000: 0.55, eps=0.1155\n",
      "Episode 36600, Average Reward Last 1000: 0.40, eps=0.1144\n",
      "Episode 36800, Average Reward Last 1000: 0.05, eps=0.1133\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 213672\n",
      "good_exp_1                    : 193012\n",
      "too_few_pts                   : 145797\n",
      "good_exp                      : 121035\n",
      "good_low_val                  : 98333\n",
      "blocked_7                     : 96673\n",
      "next_value                    : 64554\n",
      "exp_was_live                  : 47932\n",
      "lower_val_avail               : 32872\n",
      "bad_bigger_val                : 32872\n",
      "exp_small_deck                : 29401\n",
      "bad_X                         : 19954\n",
      "Episode 37000, Average Reward Last 1000: -0.46, eps=0.1122\n",
      "Episode 37200, Average Reward Last 1000: -0.37, eps=0.1113\n",
      "P1 1 - 0.1 * 7 + -1.3 = -0.6\n",
      "P1 2 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 3 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 4 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 5 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 6 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 7 - 0.1 * 7 + 0.5 = 1.2000000000000002\n",
      "P1 8 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 9 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 10 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 11 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 12 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 13 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 14 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 15 - 0.1 * 7 + 0.3 = 1.0\n",
      "P1 16 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 17 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 18 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 19 - 0.1 * 7 + 1.5 = 2.2\n",
      "P1 20 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 21 - 0.1 * 7 + 0.0 = 0.7000000000000001\n",
      "P1 22 - 0.1 * 7 + 0.3 = 1.0\n",
      "Episode 37400, Average Reward Last 1000: -0.53, eps=0.1103\n",
      "Episode 37600, Average Reward Last 1000: -0.61, eps=0.1091\n",
      "Episode 37800, Average Reward Last 1000: -0.56, eps=0.1080\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 224576\n",
      "good_exp_1                    : 198158\n",
      "too_few_pts                   : 149339\n",
      "good_exp                      : 124382\n",
      "good_low_val                  : 100972\n",
      "blocked_7                     : 99186\n",
      "next_value                    : 66400\n",
      "exp_was_live                  : 50174\n",
      "lower_val_avail               : 33828\n",
      "bad_bigger_val                : 33828\n",
      "exp_small_deck                : 30263\n",
      "bad_X                         : 20451\n",
      "Episode 38000, Average Reward Last 1000: -0.33, eps=0.1069\n",
      "Episode 38200, Average Reward Last 1000: -0.46, eps=0.1058\n",
      "Episode 38400, Average Reward Last 1000: -0.39, eps=0.1046\n",
      "Episode 38600, Average Reward Last 1000: -0.47, eps=0.1035\n",
      "Episode 38800, Average Reward Last 1000: -0.47, eps=0.1025\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 236211\n",
      "good_exp_1                    : 203204\n",
      "too_few_pts                   : 152920\n",
      "good_exp                      : 127703\n",
      "good_low_val                  : 103559\n",
      "blocked_7                     : 101751\n",
      "next_value                    : 68281\n",
      "exp_was_live                  : 52640\n",
      "lower_val_avail               : 34795\n",
      "bad_bigger_val                : 34795\n",
      "exp_small_deck                : 31167\n",
      "bad_X                         : 20983\n",
      "Episode 39000, Average Reward Last 1000: -0.64, eps=0.1016\n",
      "Episode 39200, Average Reward Last 1000: -0.62, eps=0.1007\n",
      "Episode 39400, Average Reward Last 1000: -0.52, eps=0.0999\n",
      "Episode 39600, Average Reward Last 1000: -0.25, eps=0.0991\n",
      "Episode 39800, Average Reward Last 1000: 0.00, eps=0.0983\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 244531\n",
      "good_exp_1                    : 208553\n",
      "too_few_pts                   : 156488\n",
      "good_exp                      : 131171\n",
      "good_low_val                  : 106312\n",
      "blocked_7                     : 104157\n",
      "next_value                    : 70312\n",
      "exp_was_live                  : 54227\n",
      "lower_val_avail               : 35767\n",
      "bad_bigger_val                : 35767\n",
      "exp_small_deck                : 32012\n",
      "bad_X                         : 21433\n",
      "Episode 40000, Average Reward Last 1000: 0.35, eps=0.0975\n",
      "Episode 40200, Average Reward Last 1000: 0.56, eps=0.0968\n",
      "Episode 40400, Average Reward Last 1000: 0.64, eps=0.0960\n",
      "Episode 40600, Average Reward Last 1000: 0.57, eps=0.0953\n",
      "Episode 40800, Average Reward Last 1000: 0.21, eps=0.0944\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 253856\n",
      "good_exp_1                    : 213756\n",
      "too_few_pts                   : 160210\n",
      "good_exp                      : 134501\n",
      "good_low_val                  : 108995\n",
      "blocked_7                     : 106705\n",
      "next_value                    : 72198\n",
      "exp_was_live                  : 56243\n",
      "lower_val_avail               : 36693\n",
      "bad_bigger_val                : 36693\n",
      "exp_small_deck                : 32898\n",
      "bad_X                         : 21947\n",
      "Episode 41000, Average Reward Last 1000: -0.31, eps=0.0935\n",
      "Episode 41200, Average Reward Last 1000: -0.71, eps=0.0926\n",
      "Episode 41400, Average Reward Last 1000: -0.95, eps=0.0917\n",
      "Episode 41600, Average Reward Last 1000: -1.42, eps=0.0909\n",
      "Episode 41800, Average Reward Last 1000: -1.45, eps=0.0901\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 263898\n",
      "good_exp_1                    : 218810\n",
      "too_few_pts                   : 164056\n",
      "good_exp                      : 137715\n",
      "good_low_val                  : 111615\n",
      "blocked_7                     : 109379\n",
      "next_value                    : 73972\n",
      "exp_was_live                  : 58580\n",
      "lower_val_avail               : 37565\n",
      "bad_bigger_val                : 37565\n",
      "exp_small_deck                : 33718\n",
      "bad_X                         : 22580\n",
      "Episode 42000, Average Reward Last 1000: -1.29, eps=0.0894\n",
      "Episode 42200, Average Reward Last 1000: -1.26, eps=0.0886\n",
      "Episode 42400, Average Reward Last 1000: -1.18, eps=0.0879\n",
      "Episode 42600, Average Reward Last 1000: -0.88, eps=0.0872\n",
      "P1 1 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 2 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 3 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 4 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 5 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 6 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 7 - 0.1 * 4 + 0.19999999999999996 = 0.6\n",
      "P1 8 - 0.1 * 4 + 2.0 = 2.4\n",
      "P1 9 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 10 - 0.1 * 4 + -1.3 = -0.9\n",
      "P1 11 - 0.1 * 4 + -0.7 = -0.29999999999999993\n",
      "P1 12 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 13 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 14 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 15 - 0.1 * 4 + 2.0 = 2.4\n",
      "P1 16 - 0.1 * 4 + 0.3 = 0.7\n",
      "P1 17 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 18 - 0.1 * 4 + 0.0 = 0.4\n",
      "P1 19 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 20 - 0.1 * 4 + 1.5 = 1.9\n",
      "P1 21 - 0.1 * 4 + 0.0 = 0.4\n",
      "Episode 42800, Average Reward Last 1000: -0.83, eps=0.0864\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 272895\n",
      "good_exp_1                    : 224075\n",
      "too_few_pts                   : 167781\n",
      "good_exp                      : 141136\n",
      "good_low_val                  : 114335\n",
      "blocked_7                     : 111916\n",
      "next_value                    : 75854\n",
      "exp_was_live                  : 60420\n",
      "lower_val_avail               : 38548\n",
      "bad_bigger_val                : 38548\n",
      "exp_small_deck                : 34563\n",
      "bad_X                         : 23210\n",
      "Episode 43000, Average Reward Last 1000: -0.74, eps=0.0857\n",
      "Episode 43200, Average Reward Last 1000: -0.41, eps=0.0848\n",
      "Episode 43400, Average Reward Last 1000: -0.09, eps=0.0839\n",
      "Episode 43600, Average Reward Last 1000: 0.16, eps=0.0829\n",
      "Episode 43800, Average Reward Last 1000: 0.34, eps=0.0821\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 285169\n",
      "good_exp_1                    : 229192\n",
      "too_few_pts                   : 171211\n",
      "good_exp                      : 144471\n",
      "good_low_val                  : 116979\n",
      "blocked_7                     : 114362\n",
      "next_value                    : 77729\n",
      "exp_was_live                  : 62841\n",
      "lower_val_avail               : 39524\n",
      "bad_bigger_val                : 39524\n",
      "exp_small_deck                : 35438\n",
      "bad_X                         : 23681\n",
      "Episode 44000, Average Reward Last 1000: 0.22, eps=0.0811\n",
      "Episode 44200, Average Reward Last 1000: 0.06, eps=0.0802\n",
      "P1 1 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 2 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 3 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 4 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 5 - 0.1 * -7 + 1.5 = 0.7999999999999999\n",
      "P1 6 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 7 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 8 - 0.1 * -7 + 1.5 = 0.7999999999999999\n",
      "P1 9 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 10 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 11 - 0.1 * -7 + 1.5 = 0.7999999999999999\n",
      "P1 12 - 0.1 * -7 + 2.0 = 1.2999999999999998\n",
      "P1 13 - 0.1 * -7 + -3.3 = -4.0\n",
      "P1 14 - 0.1 * -7 + -3.3 = -4.0\n",
      "P1 15 - 0.1 * -7 + 2.0 = 1.2999999999999998\n",
      "P1 16 - 0.1 * -7 + 0.3 = -0.4000000000000001\n",
      "P1 17 - 0.1 * -7 + 2.0 = 1.2999999999999998\n",
      "P1 18 - 0.1 * -7 + -1.5 = -2.2\n",
      "P1 19 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 20 - 0.1 * -7 + 1.5 = 0.7999999999999999\n",
      "P1 21 - 0.1 * -7 + 0.0 = -0.7000000000000001\n",
      "P1 1 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 2 - 0.1 * 8 + 1.5 = 2.3\n",
      "P1 3 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 4 - 0.1 * 8 + -1.3 = -0.5\n",
      "P1 5 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 6 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 7 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 8 - 0.1 * 8 + 1.5 = 2.3\n",
      "P1 9 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 10 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 11 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 12 - 0.1 * 8 + 1.5 = 2.3\n",
      "P1 13 - 0.1 * 8 + 1.5 = 2.3\n",
      "P1 14 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 15 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 16 - 0.1 * 8 + 2.0 = 2.8\n",
      "P1 17 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 18 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 19 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 20 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 21 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 22 - 0.1 * 8 + 0.0 = 0.8\n",
      "P1 23 - 0.1 * 8 + 0.0 = 0.8\n",
      "Episode 44400, Average Reward Last 1000: -0.17, eps=0.0793\n",
      "Episode 44600, Average Reward Last 1000: -0.61, eps=0.0783\n",
      "Episode 44800, Average Reward Last 1000: -0.81, eps=0.0774\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 299303\n",
      "good_exp_1                    : 234221\n",
      "too_few_pts                   : 174728\n",
      "good_exp                      : 147810\n",
      "good_low_val                  : 119570\n",
      "blocked_7                     : 116887\n",
      "next_value                    : 79566\n",
      "exp_was_live                  : 65914\n",
      "lower_val_avail               : 40497\n",
      "bad_bigger_val                : 40497\n",
      "exp_small_deck                : 36286\n",
      "bad_X                         : 24245\n",
      "Episode 45000, Average Reward Last 1000: -0.68, eps=0.0765\n",
      "Episode 45200, Average Reward Last 1000: -0.65, eps=0.0756\n",
      "Episode 45400, Average Reward Last 1000: -0.63, eps=0.0746\n",
      "Episode 45600, Average Reward Last 1000: -0.36, eps=0.0737\n",
      "Episode 45800, Average Reward Last 1000: -0.33, eps=0.0727\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 315239\n",
      "good_exp_1                    : 239211\n",
      "too_few_pts                   : 178103\n",
      "good_exp                      : 151163\n",
      "good_low_val                  : 122132\n",
      "blocked_7                     : 119373\n",
      "next_value                    : 81343\n",
      "exp_was_live                  : 69622\n",
      "lower_val_avail               : 41496\n",
      "bad_bigger_val                : 41496\n",
      "exp_small_deck                : 37126\n",
      "bad_X                         : 24770\n",
      "Episode 46000, Average Reward Last 1000: -0.48, eps=0.0717\n",
      "Episode 46200, Average Reward Last 1000: -0.56, eps=0.0707\n",
      "Episode 46400, Average Reward Last 1000: -0.61, eps=0.0698\n",
      "Episode 46600, Average Reward Last 1000: -0.66, eps=0.0690\n",
      "Plays: 203 in episode 46704\n",
      "Episode 46800, Average Reward Last 1000: -0.55, eps=0.0682\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 330094\n",
      "good_exp_1                    : 244308\n",
      "too_few_pts                   : 181524\n",
      "good_exp                      : 154551\n",
      "good_low_val                  : 124734\n",
      "blocked_7                     : 121830\n",
      "next_value                    : 83131\n",
      "exp_was_live                  : 72722\n",
      "lower_val_avail               : 42472\n",
      "bad_bigger_val                : 42472\n",
      "exp_small_deck                : 37984\n",
      "bad_X                         : 25327\n",
      "Episode 47000, Average Reward Last 1000: -0.50, eps=0.0675\n",
      "P1 1 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 2 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 3 - 0.1 * -5 + -1.3 = -1.8\n",
      "P1 4 - 0.1 * -5 + 1.5 = 1.0\n",
      "P1 5 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 6 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 7 - 0.1 * -5 + 1.5 = 1.0\n",
      "P1 8 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 9 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 10 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 11 - 0.1 * -5 + 1.5 = 1.0\n",
      "P1 12 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 13 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 14 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 15 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 16 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 17 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 18 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 19 - 0.1 * -5 + -1.0 = -1.5\n",
      "P1 20 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 21 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 22 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 23 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 24 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 25 - 0.1 * -5 + 0.0 = -0.5\n",
      "P1 26 - 0.1 * -5 + 0.0 = -0.5\n",
      "Episode 47200, Average Reward Last 1000: -0.65, eps=0.0667\n",
      "Episode 47400, Average Reward Last 1000: -0.99, eps=0.0659\n",
      "Episode 47600, Average Reward Last 1000: -1.37, eps=0.0652\n",
      "Episode 47800, Average Reward Last 1000: -1.60, eps=0.0644\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 344551\n",
      "good_exp_1                    : 249216\n",
      "too_few_pts                   : 185161\n",
      "good_exp                      : 157756\n",
      "good_low_val                  : 127286\n",
      "blocked_7                     : 124461\n",
      "next_value                    : 84758\n",
      "exp_was_live                  : 76214\n",
      "lower_val_avail               : 43359\n",
      "bad_bigger_val                : 43359\n",
      "exp_small_deck                : 38897\n",
      "bad_X                         : 26018\n",
      "Episode 48000, Average Reward Last 1000: -1.84, eps=0.0636\n",
      "Episode 48200, Average Reward Last 1000: -1.94, eps=0.0629\n",
      "Episode 48400, Average Reward Last 1000: -1.87, eps=0.0620\n",
      "P1 1 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 2 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 3 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 4 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 5 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 6 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 7 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 8 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 9 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 10 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 11 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 12 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 13 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 14 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 15 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 16 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 17 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 18 - 0.1 * -8 + 2.0 = 1.2\n",
      "P1 19 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 20 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 21 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 22 - 0.1 * -8 + -3.3 = -4.1\n",
      "P1 23 - 0.1 * -8 + -1.7999999999999998 = -2.5999999999999996\n",
      "P1 24 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 25 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 26 - 0.1 * -8 + 1.8 = 1.0\n",
      "P1 27 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 28 - 0.1 * -8 + 1.5 = 0.7\n",
      "P1 29 - 0.1 * -8 + -0.39999999999999997 = -1.2\n",
      "P1 30 - 0.1 * -8 + 0.0 = -0.8\n",
      "P1 31 - 0.1 * -8 + 0.0 = -0.8\n",
      "Episode 48600, Average Reward Last 1000: -1.76, eps=0.0612\n",
      "Episode 48800, Average Reward Last 1000: -1.86, eps=0.0604\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 360785\n",
      "good_exp_1                    : 254084\n",
      "too_few_pts                   : 188709\n",
      "good_exp                      : 160982\n",
      "good_low_val                  : 129808\n",
      "blocked_7                     : 127020\n",
      "next_value                    : 86429\n",
      "exp_was_live                  : 80246\n",
      "lower_val_avail               : 44255\n",
      "bad_bigger_val                : 44255\n",
      "exp_small_deck                : 39756\n",
      "bad_X                         : 26658\n",
      "Episode 49000, Average Reward Last 1000: -1.61, eps=0.0596\n",
      "Episode 49200, Average Reward Last 1000: -1.56, eps=0.0588\n",
      "Episode 49400, Average Reward Last 1000: -1.43, eps=0.0581\n",
      "Episode 49600, Average Reward Last 1000: -1.09, eps=0.0573\n",
      "Episode 49800, Average Reward Last 1000: -0.89, eps=0.0565\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 378371\n",
      "good_exp_1                    : 259087\n",
      "too_few_pts                   : 192122\n",
      "good_exp                      : 164369\n",
      "good_low_val                  : 132464\n",
      "blocked_7                     : 129547\n",
      "next_value                    : 88212\n",
      "exp_was_live                  : 84214\n",
      "lower_val_avail               : 45193\n",
      "bad_bigger_val                : 45193\n",
      "exp_small_deck                : 40624\n",
      "bad_X                         : 27238\n",
      "Episode 50000, Average Reward Last 1000: -0.87, eps=0.0557\n",
      "Episode 50200, Average Reward Last 1000: -0.67, eps=0.0549\n",
      "Episode 50400, Average Reward Last 1000: -0.37, eps=0.0541\n",
      "Episode 50600, Average Reward Last 1000: -0.51, eps=0.0534\n",
      "Episode 50800, Average Reward Last 1000: -0.45, eps=0.0527\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 395754\n",
      "good_exp_1                    : 264060\n",
      "too_few_pts                   : 195529\n",
      "good_exp                      : 167710\n",
      "good_low_val                  : 135059\n",
      "blocked_7                     : 132057\n",
      "next_value                    : 89981\n",
      "exp_was_live                  : 88073\n",
      "lower_val_avail               : 46166\n",
      "bad_bigger_val                : 46166\n",
      "exp_small_deck                : 41465\n",
      "bad_X                         : 27791\n",
      "Episode 51000, Average Reward Last 1000: -0.42, eps=0.0520\n",
      "Episode 51200, Average Reward Last 1000: -0.19, eps=0.0513\n",
      "Plays: 235 in episode 51316\n",
      "Episode 51400, Average Reward Last 1000: -0.57, eps=0.0506\n",
      "Plays: 217 in episode 51531\n",
      "Episode 51600, Average Reward Last 1000: -0.58, eps=0.0498\n",
      "Plays: 259 in episode 51731\n",
      "Episode 51800, Average Reward Last 1000: -0.68, eps=0.0491\n",
      "P1 1 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 2 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 3 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 4 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 5 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 6 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 7 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 8 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 9 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 10 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 11 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 12 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 13 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 14 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 15 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 16 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 17 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 18 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 19 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 20 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 21 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 22 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 23 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 24 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 25 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 26 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 27 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 28 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 29 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 30 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 31 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 32 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 33 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 34 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 35 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 36 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 37 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 38 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 39 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 40 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 41 - 0.1 * -24 + 1.3 = -1.1000000000000003\n",
      "P1 42 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 43 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 44 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 45 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 46 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 47 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 48 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 49 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 50 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 51 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 52 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 53 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 54 - 0.1 * -24 + 0.0 = -2.4000000000000004\n",
      "P1 55 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 56 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 57 - 0.1 * -24 + 0.5 = -1.9000000000000004\n",
      "P1 58 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 59 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 60 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "P1 61 - 0.1 * -24 + 1.5 = -0.9000000000000004\n",
      "P1 62 - 0.1 * -24 + -1.5 = -3.9000000000000004\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 414532\n",
      "good_exp_1                    : 268967\n",
      "too_few_pts                   : 198943\n",
      "good_exp                      : 171033\n",
      "good_low_val                  : 137684\n",
      "blocked_7                     : 134593\n",
      "exp_was_live                  : 92455\n",
      "next_value                    : 91736\n",
      "lower_val_avail               : 47056\n",
      "bad_bigger_val                : 47056\n",
      "exp_small_deck                : 42366\n",
      "bad_X                         : 28343\n",
      "Episode 52000, Average Reward Last 1000: -0.94, eps=0.0483\n",
      "Episode 52200, Average Reward Last 1000: -1.52, eps=0.0476\n",
      "Episode 52400, Average Reward Last 1000: -1.49, eps=0.0469\n",
      "Episode 52600, Average Reward Last 1000: -1.57, eps=0.0462\n",
      "P1 1 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 2 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 3 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 4 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 5 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 6 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 7 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 8 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 9 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 10 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 11 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 12 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 13 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 14 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 15 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 16 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 17 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 18 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 19 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 20 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 21 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 22 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 23 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 24 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 25 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 26 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 27 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 28 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 29 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 30 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 31 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 32 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 33 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 34 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 35 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 36 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 37 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 38 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 39 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 40 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 41 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 42 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 43 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 44 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 45 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 46 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 47 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 48 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 49 - 0.1 * 2 + 0.19999999999999996 = 0.39999999999999997\n",
      "P1 50 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 51 - 0.1 * 2 + 1.5 = 1.7\n",
      "P1 52 - 0.1 * 2 + -0.5 = -0.3\n",
      "P1 53 - 0.1 * 2 + 2.0 = 2.2\n",
      "P1 54 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 55 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 56 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 57 - 0.1 * 2 + 0.0 = 0.2\n",
      "P1 58 - 0.1 * 2 + -0.7 = -0.49999999999999994\n",
      "Episode 52800, Average Reward Last 1000: -1.54, eps=0.0455\n",
      "Plays: 221 in episode 52973\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 434461\n",
      "good_exp_1                    : 273753\n",
      "too_few_pts                   : 202404\n",
      "good_exp                      : 174286\n",
      "good_low_val                  : 140248\n",
      "blocked_7                     : 137098\n",
      "exp_was_live                  : 97029\n",
      "next_value                    : 93424\n",
      "lower_val_avail               : 47912\n",
      "bad_bigger_val                : 47912\n",
      "exp_small_deck                : 43232\n",
      "bad_X                         : 28940\n",
      "Episode 53000, Average Reward Last 1000: -1.39, eps=0.0448\n",
      "Episode 53200, Average Reward Last 1000: -1.09, eps=0.0441\n",
      "Plays: 243 in episode 53260\n",
      "Episode 53400, Average Reward Last 1000: -0.94, eps=0.0434\n",
      "Episode 53600, Average Reward Last 1000: -0.78, eps=0.0427\n",
      "Plays: 228 in episode 53691\n",
      "Episode 53800, Average Reward Last 1000: -0.60, eps=0.0420\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 454689\n",
      "good_exp_1                    : 278730\n",
      "too_few_pts                   : 205734\n",
      "good_exp                      : 177641\n",
      "good_low_val                  : 142895\n",
      "blocked_7                     : 139573\n",
      "exp_was_live                  : 101659\n",
      "next_value                    : 95198\n",
      "lower_val_avail               : 48819\n",
      "bad_bigger_val                : 48819\n",
      "exp_small_deck                : 44078\n",
      "bad_X                         : 29479\n",
      "Episode 54000, Average Reward Last 1000: -0.42, eps=0.0414\n",
      "P1 1 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 2 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 3 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 4 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 5 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 6 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 7 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 8 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 9 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 10 - 0.1 * -16 + -3.3 = -4.9\n",
      "P1 11 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 12 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 13 - 0.1 * -16 + -3.3 = -4.9\n",
      "P1 14 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 15 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 16 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 17 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 18 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 19 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 20 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 21 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 22 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 23 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 24 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 25 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 26 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 27 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 28 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 29 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 30 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 31 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 32 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 33 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 34 - 0.1 * -16 + 1.8 = 0.19999999999999996\n",
      "P1 35 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 36 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 37 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 38 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 39 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 40 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 41 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 42 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 43 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 44 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 45 - 0.1 * -16 + 0.0 = -1.6\n",
      "P1 46 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 47 - 0.1 * -16 + -1.5 = -3.1\n",
      "P1 48 - 0.1 * -16 + 1.5 = -0.10000000000000009\n",
      "P1 49 - 0.1 * -16 + -1.5 = -3.1\n",
      "Episode 54200, Average Reward Last 1000: -0.46, eps=0.0408\n",
      "Episode 54400, Average Reward Last 1000: -0.65, eps=0.0401\n",
      "Episode 54600, Average Reward Last 1000: -0.69, eps=0.0396\n",
      "Plays: 211 in episode 54754\n",
      "Episode 54800, Average Reward Last 1000: -0.65, eps=0.0389\n",
      "Plays: 205 in episode 54947\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 474709\n",
      "good_exp_1                    : 283627\n",
      "too_few_pts                   : 209084\n",
      "good_exp                      : 180937\n",
      "good_low_val                  : 145522\n",
      "blocked_7                     : 142044\n",
      "exp_was_live                  : 105981\n",
      "next_value                    : 96966\n",
      "lower_val_avail               : 49697\n",
      "bad_bigger_val                : 49697\n",
      "exp_small_deck                : 44969\n",
      "bad_X                         : 30024\n",
      "Episode 55000, Average Reward Last 1000: -0.86, eps=0.0384\n",
      "Episode 55200, Average Reward Last 1000: -0.85, eps=0.0378\n",
      "Episode 55400, Average Reward Last 1000: -0.72, eps=0.0372\n",
      "Episode 55600, Average Reward Last 1000: -0.74, eps=0.0367\n",
      "P1 1 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 2 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 3 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 4 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 5 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 6 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 7 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 8 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 9 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 10 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 11 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 12 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 13 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 14 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 15 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 16 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 17 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 18 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 19 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 20 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 21 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 22 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 23 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 24 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 25 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 26 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 27 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 28 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 29 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 30 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 31 - 0.1 * 3 + -0.5 = -0.19999999999999996\n",
      "P1 32 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 33 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 34 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 35 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 36 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 37 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 38 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 39 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 40 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 41 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 42 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 43 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 44 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 45 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 46 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 47 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 48 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 49 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 50 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 51 - 0.1 * 3 + 1.0 = 1.3\n",
      "P1 52 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 53 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 54 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 55 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 56 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 57 - 0.1 * 3 + 1.5 = 1.8\n",
      "P1 58 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "P1 59 - 0.1 * 3 + 2.0 = 2.3\n",
      "P1 60 - 0.1 * 3 + 0.0 = 0.30000000000000004\n",
      "Episode 55800, Average Reward Last 1000: -1.08, eps=0.0361\n",
      "Plays: 214 in episode 55844\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 493931\n",
      "good_exp_1                    : 288507\n",
      "too_few_pts                   : 212446\n",
      "good_exp                      : 184248\n",
      "good_low_val                  : 148136\n",
      "blocked_7                     : 144456\n",
      "exp_was_live                  : 109897\n",
      "next_value                    : 98659\n",
      "lower_val_avail               : 50601\n",
      "bad_bigger_val                : 50601\n",
      "exp_small_deck                : 45828\n",
      "bad_X                         : 30620\n",
      "Episode 56000, Average Reward Last 1000: -1.07, eps=0.0356\n",
      "Plays: 205 in episode 56010\n",
      "Plays: 221 in episode 56046\n",
      "Episode 56200, Average Reward Last 1000: -1.10, eps=0.0351\n",
      "P1 1 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 2 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 3 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 4 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 5 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 6 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 7 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 8 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 9 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 10 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 11 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 12 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 13 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 14 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 15 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 16 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 17 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 18 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 19 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 20 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 21 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 22 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 23 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 24 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 25 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 26 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 27 - 0.1 * -12 + 2.0 = 0.7999999999999998\n",
      "P1 28 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 29 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 30 - 0.1 * -12 + 2.0 = 0.7999999999999998\n",
      "P1 31 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 32 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 33 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 34 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 35 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 36 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 37 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 38 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 39 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 40 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 41 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 42 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 43 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 44 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 45 - 0.1 * -12 + 1.5 = 0.2999999999999998\n",
      "P1 46 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 47 - 0.1 * -12 + 0.6 = -0.6000000000000002\n",
      "P1 48 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 49 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 50 - 0.1 * -12 + -1.0 = -2.2\n",
      "P1 51 - 0.1 * -12 + -1.5 = -2.7\n",
      "P1 52 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 53 - 0.1 * -12 + 0.8 = -0.40000000000000013\n",
      "P1 54 - 0.1 * -12 + 0.0 = -1.2000000000000002\n",
      "P1 55 - 0.1 * -12 + -1.5 = -2.7\n",
      "Episode 56400, Average Reward Last 1000: -1.23, eps=0.0345\n",
      "Plays: 226 in episode 56526\n",
      "Episode 56600, Average Reward Last 1000: -1.21, eps=0.0341\n",
      "Episode 56800, Average Reward Last 1000: -1.10, eps=0.0336\n",
      "Plays: 213 in episode 56951\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 512474\n",
      "good_exp_1                    : 293416\n",
      "too_few_pts                   : 215828\n",
      "good_exp                      : 187548\n",
      "good_low_val                  : 150767\n",
      "blocked_7                     : 146909\n",
      "exp_was_live                  : 113623\n",
      "next_value                    : 100388\n",
      "lower_val_avail               : 51515\n",
      "bad_bigger_val                : 51515\n",
      "exp_small_deck                : 46690\n",
      "bad_X                         : 31258\n",
      "Episode 57000, Average Reward Last 1000: -0.85, eps=0.0331\n",
      "Plays: 252 in episode 57041\n",
      "Plays: 231 in episode 57169\n",
      "Episode 57200, Average Reward Last 1000: -0.58, eps=0.0326\n",
      "Plays: 220 in episode 57229\n",
      "Episode 57400, Average Reward Last 1000: -0.26, eps=0.0321\n",
      "Episode 57600, Average Reward Last 1000: -0.11, eps=0.0316\n",
      "Episode 57800, Average Reward Last 1000: -0.03, eps=0.0311\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 531765\n",
      "good_exp_1                    : 298461\n",
      "too_few_pts                   : 219106\n",
      "good_exp                      : 190941\n",
      "good_low_val                  : 153432\n",
      "blocked_7                     : 149291\n",
      "exp_was_live                  : 117345\n",
      "next_value                    : 102242\n",
      "lower_val_avail               : 52431\n",
      "bad_bigger_val                : 52431\n",
      "exp_small_deck                : 47477\n",
      "bad_X                         : 31788\n",
      "Episode 58000, Average Reward Last 1000: -0.00, eps=0.0307\n",
      "Episode 58200, Average Reward Last 1000: -0.06, eps=0.0302\n",
      "Plays: 239 in episode 58371\n",
      "Episode 58400, Average Reward Last 1000: -0.27, eps=0.0300\n",
      "Plays: 228 in episode 58519\n",
      "Plays: 259 in episode 58596\n",
      "Episode 58600, Average Reward Last 1000: -0.29, eps=0.0300\n",
      "Plays: 225 in episode 58671\n",
      "Plays: 221 in episode 58759\n",
      "Episode 58800, Average Reward Last 1000: -0.34, eps=0.0300\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 553063\n",
      "good_exp_1                    : 303370\n",
      "too_few_pts                   : 222410\n",
      "good_exp                      : 194304\n",
      "good_low_val                  : 156111\n",
      "blocked_7                     : 151708\n",
      "exp_was_live                  : 121382\n",
      "next_value                    : 104037\n",
      "lower_val_avail               : 53328\n",
      "bad_bigger_val                : 53328\n",
      "exp_small_deck                : 48289\n",
      "bad_X                         : 32356\n",
      "Episode 59000, Average Reward Last 1000: -0.54, eps=0.0300\n",
      "Plays: 224 in episode 59114\n",
      "Episode 59200, Average Reward Last 1000: -0.65, eps=0.0300\n",
      "Episode 59400, Average Reward Last 1000: -0.67, eps=0.0300\n",
      "Episode 59600, Average Reward Last 1000: -0.87, eps=0.0300\n",
      "Plays: 274 in episode 59744\n",
      "Episode 59800, Average Reward Last 1000: -0.82, eps=0.0300\n",
      "Plays: 288 in episode 59986\n",
      "\n",
      "=== Step Rule Firing Counts ===\n",
      "draw_to_tgt                   : 572541\n",
      "good_exp_1                    : 308302\n",
      "too_few_pts                   : 225787\n",
      "good_exp                      : 197639\n",
      "good_low_val                  : 158785\n",
      "blocked_7                     : 154182\n",
      "exp_was_live                  : 125399\n",
      "next_value                    : 105811\n",
      "lower_val_avail               : 54206\n",
      "bad_bigger_val                : 54206\n",
      "exp_small_deck                : 49137\n",
      "bad_X                         : 32958\n",
      "Episode 60000, Average Reward Last 1000: -0.87, eps=0.0300\n"
     ]
    }
   ],
   "source": [
    "# Modified Training Loop with Action + Draw Selection from Policy\n",
    "env = LostCitiesEnv()\n",
    "num_card_actions = card_cnt\n",
    "num_draw_choices = color_cnt+1\n",
    "model = ActorCritic(state_size=state_size, action_size=num_card_actions, draw_size=num_draw_choices, \n",
    "                         nn_layer_1=nn_layer_1, nn_layer_2=nn_layer_2, nn_layer_2_dropout=nn_layer_2_dropout)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "replay_buffer = deque(maxlen=replay_size)\n",
    "rule_counter = defaultdict(int)\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    mean_reward = 0.0\n",
    "    play_cnt=0\n",
    "    plays_p1 = []\n",
    "    plays_p2 = []\n",
    "\n",
    "    while not done:\n",
    "        play_cnt+=1\n",
    "        features_np = extract_features(state)\n",
    "        features = torch.tensor(features_np, dtype=torch.float32)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        card_logits, draw_logits, value = model(features)\n",
    "\n",
    "        # Get legal actions and legal draws\n",
    "        # actions, draws = env.get_legal_actions(state['current_player'])\n",
    "        actions, draws = env.get_legal_actions(state['current_player'])\n",
    "        legal_action_indices = list(range(len(actions)))\n",
    "\n",
    "        valid_draws = [d for d in draws if d == 'deck' or (d in env.center_piles and env.center_piles[d])]\n",
    "        if not valid_draws:\n",
    "            print(\"No valid drawsforcing episode end.\")\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "        # legal_draw_indices = list(range(len(valid_draws)))  # typically ['deck', 'R', 'B', 'G']\n",
    "\n",
    "        # Stop this game is no legal actions - though this is of course not true, but...\n",
    "        # Print discard and draw for plays 1001 to 1020\n",
    "        if 10001 <= play_cnt <= 10020:\n",
    "            print(f\"Legal actions: {actions}\")\n",
    "            print(f\"Action indices: {[i for i in range(len(actions))]}\")\n",
    "            # Not valid at this point\n",
    "            # print(f\"Play {play_cnt}: Discard action = {chosen_action}, Draw choice = {chosen_draw}\")\n",
    "        if play_cnt>=10020:\n",
    "            print(play_cnt, actions, draws, valid_draws)\n",
    "            print(f\"\\n--- STUCK STATE at play {play_cnt} ---\")\n",
    "            print(f\"Deck size: {state['deck_size']}\")\n",
    "            print(f\"Player hand: {state['hands'][state['current_player']]}\")\n",
    "            print(f\"Expeditions:\")\n",
    "            for color in env.expeditions[state['current_player']]:\n",
    "                print(f\"  {color}: {env.expeditions[state['current_player']][color]}\")\n",
    "            print(f\"Center piles:\")\n",
    "            for color in env.center_piles:\n",
    "                print(f\"  {color}: {env.center_piles[color]}\")\n",
    "            print(f\"Available actions: {actions}\")\n",
    "            print(f\"Available draws: {draws}\")\n",
    "            print(f\"----------------------\\n\")\n",
    "            raise SystemExit(f\"STOP\")\n",
    "        \n",
    "        if not actions:\n",
    "            print(f\"No legal actions for player {state['current_player']}. Ending episode early.\")\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "        # Sample card action with epsilon-greedy\n",
    "        if random.random() < epsilon:\n",
    "            # Random action\n",
    "            card_idx = random.randint(0, len(actions) - 1)\n",
    "        else:\n",
    "            # Model-based action\n",
    "            card_probs = torch.softmax(card_logits[:len(actions)], dim=0)\n",
    "            card_dist = torch.distributions.Categorical(card_probs)\n",
    "            card_idx = card_dist.sample().item()\n",
    "        \n",
    "        chosen_action = actions[card_idx]\n",
    "\n",
    "        # Filter valid draws based on chosen_action (if it's a center discard)\n",
    "        discard_color = None\n",
    "        if chosen_action[0] == 'center':\n",
    "            discard_color = chosen_action[1][0]\n",
    "        \n",
    "        filtered_draws = [\n",
    "            d for d in valid_draws if d != discard_color\n",
    "        ]\n",
    "        if not filtered_draws:\n",
    "            # Failsafe: fallback to deck\n",
    "            filtered_draws = ['deck']\n",
    "\n",
    "        valid_draws=filtered_draws\n",
    "\n",
    "        # Sample draw choice (FIXED)\n",
    "        if random.random() < epsilon:\n",
    "            chosen_draw = random.choice(valid_draws)\n",
    "        else:\n",
    "            # Correct mapping: get logits only for valid draws\n",
    "            draw_indices_in_logits = [draw_to_index[d] for d in valid_draws]\n",
    "            draw_logits_filtered = draw_logits[draw_indices_in_logits]\n",
    "            draw_probs = torch.softmax(draw_logits_filtered, dim=0)\n",
    "            draw_dist = torch.distributions.Categorical(draw_probs)\n",
    "            draw_idx = draw_dist.sample().item()\n",
    "            chosen_draw = valid_draws[draw_idx]\n",
    "\n",
    "        # Compute shaped intermediate reward\n",
    "        step_reward = compute_step_reward(state, chosen_action, chosen_draw, env, step_functions, rule_counter)\n",
    "\n",
    "        # Map draw_choice to its index for policy update\n",
    "        chosen_draw_idx = draw_to_index[chosen_draw]\n",
    "\n",
    "        # Save the current player before doing env.step\n",
    "        current_player=state['current_player']\n",
    "        \n",
    "        # Take action and draw based on policies\n",
    "        next_state, reward, done = env.step(chosen_action, chosen_draw)\n",
    "\n",
    "        # Combine shaped reward + final score (if any)\n",
    "        # total_reward = reward + booster * step_reward\n",
    "        total_reward = step_booster * step_reward\n",
    "\n",
    "        # Store full experience (must include both action idx and draw idx!)\n",
    "        # replay_buffer.append((features_np, card_idx, chosen_draw_idx, total_reward))\n",
    "        # Now, do it all at end of game\n",
    "        if current_player=='P1':\n",
    "            plays_p1.append((features_np, card_idx, chosen_draw_idx, step_reward))\n",
    "        else:\n",
    "            plays_p2.append((features_np, card_idx, chosen_draw_idx, step_reward))\n",
    "            \n",
    "        # Advance state\n",
    "        state = next_state\n",
    "        mean_reward += total_reward\n",
    "\n",
    "        # Annealing\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "        ddebug = random.random()<1e-6\n",
    "        if done:\n",
    "            reward_p1 = env.compute_score('P1')\n",
    "            reward_p2 = env.compute_score('P2')\n",
    "            p1cnt=0\n",
    "            for (features_np, card_idx, draw_idx, step_reward) in plays_p1:\n",
    "                total_reward = episode_booster * reward_p1 + step_reward\n",
    "                replay_buffer.append((features_np, card_idx, draw_idx, total_reward))\n",
    "                if ddebug:\n",
    "                    p1cnt+=1\n",
    "                    print(f\"P1 {p1cnt} - {episode_booster} * {reward_p1} + {step_reward} = {total_reward}\")\n",
    "            for (features_np, card_idx, draw_idx, step_reward) in plays_p2:\n",
    "                total_reward = episode_booster * reward_p2 + step_reward\n",
    "                replay_buffer.append((features_np, card_idx, draw_idx, total_reward))\n",
    "\n",
    "    # Final mean reward is the average over plays - approximate over P1 and P2\n",
    "    mean_reward=1.0*mean_reward/play_cnt\n",
    "    \n",
    "    if play_cnt>200:\n",
    "        print(f\"Plays: {play_cnt} in episode {episode}\")\n",
    "\n",
    "    # Train\n",
    "    if episode % train_every == 0 and len(replay_buffer) >= batch_size:\n",
    "        for _ in range(batch_cnt):\n",
    "            minibatch = random.sample(replay_buffer, batch_size)\n",
    "    \n",
    "            # Unpack minibatch into separate lists\n",
    "            states_b, actions_b, draws_b, rewards_b = zip(*minibatch)\n",
    "\n",
    "            # Convert lists to tensors\n",
    "            states_np = np.array(states_b)  # Convert list of arrays  single array\n",
    "            states_t = torch.tensor(states_np, dtype=torch.float32)\n",
    "    \n",
    "            # Convert to tensors in batch\n",
    "            # states_t = torch.tensor(states_b, dtype=torch.float32)  # Shape: [batch_size, state_size]\n",
    "            actions_t = torch.tensor(actions_b, dtype=torch.long)   # Shape: [batch_size]\n",
    "            draws_t = torch.tensor(draws_b, dtype=torch.long)       # Shape: [batch_size]\n",
    "            rewards_t = torch.tensor(rewards_b, dtype=torch.float32)  # Shape: [batch_size]\n",
    "    \n",
    "            # Forward pass in batch\n",
    "            card_logits_b, draw_logits_b, values_b = model(states_t)  # Each output shape: [batch_size, num_actions/draws]\n",
    "    \n",
    "            # Compute log probs for card actions\n",
    "            card_probs_b = torch.softmax(card_logits_b, dim=1)\n",
    "            log_card_probs_b = torch.log(card_probs_b + 1e-8)\n",
    "            selected_log_card_probs = log_card_probs_b[range(batch_size), actions_t]\n",
    "    \n",
    "            # Compute log probs for draws\n",
    "            draw_probs_b = torch.softmax(draw_logits_b, dim=1)\n",
    "            log_draw_probs_b = torch.log(draw_probs_b + 1e-8)\n",
    "            selected_log_draw_probs = log_draw_probs_b[range(batch_size), draws_t]\n",
    "    \n",
    "            # Compute advantage\n",
    "            advantages = rewards_t - values_b.squeeze(1)  # Shape: [batch_size]\n",
    "    \n",
    "            # Losses\n",
    "            critic_loss = advantages.pow(2).mean()\n",
    "            actor_loss_card = -(selected_log_card_probs * advantages).mean()\n",
    "            actor_loss_draw = -(selected_log_draw_probs * advantages).mean()\n",
    "    \n",
    "            total_loss = critic_loss + actor_loss_card + actor_loss_draw\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    all_rewards.append(reward_p1)\n",
    "    all_rewards.append(reward_p2)    \n",
    "    mean_rewards.append(mean_reward)\n",
    "\n",
    "    if episode % 1000 == 0:\n",
    "        print(\"\\n=== Step Rule Firing Counts ===\")\n",
    "        for rule, count in sorted(rule_counter.items(), key=lambda x: -x[1]):\n",
    "            print(f\"{rule:<30}: {count}\")    \n",
    "    \n",
    "    if episode % 200 == 0:\n",
    "        avg_score = np.mean(all_rewards[-2000:]) if len(all_rewards) >= 2000 else np.mean(all_rewards)\n",
    "        print(f\"Episode {episode}, Average Reward Last {min(len(all_rewards), 1000)}: {avg_score:.2f}, eps={epsilon:.4f}\")\n",
    "        pd.Series(all_rewards).to_csv(file_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81139b17-fc42-47cf-bde3-448596ffd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lc_model_'+fv+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e178f444-1675-4da7-a529-08eaf5010431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_bot(epsilon=0.0):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    play_cnt = 0\n",
    "\n",
    "    while not done:\n",
    "        play_cnt += 1\n",
    "        current_player = state['current_player']\n",
    "\n",
    "        print(f\"\\n=== Turn {play_cnt}  {current_player} ===\")\n",
    "\n",
    "        actions, draws = env.get_legal_actions(current_player)\n",
    "        valid_draws = [d for d in draws if d == 'deck' or (d in env.center_piles and env.center_piles[d])]\n",
    "\n",
    "        if not actions or not valid_draws:\n",
    "            print(\"No legal actions or draws. Ending game.\")\n",
    "            break\n",
    "\n",
    "        if current_player == 'P2':\n",
    "            # ===== HUMAN TURN =====\n",
    "            hand = state['hands'][current_player]\n",
    "            exped = env.expeditions[current_player]\n",
    "            center = env.center_piles\n",
    "            opp_exped = env.expeditions['P1']\n",
    "\n",
    "            exped_str = \" | \".join(f\"{color}:{exped.get(color, [])}\" for color in COLORS)\n",
    "            opp_exped_str = \" | \".join(f\"{color}:{opp_exped.get(color, [])}\" for color in COLORS)\n",
    "            center_str = \" | \".join(f\"{color}:{center[color]}\" for color in COLORS)\n",
    "\n",
    "            print(f\"Your hand: {hand}\")\n",
    "            print(f\"Your expeditions: {exped_str}\")\n",
    "            print(f\"Center piles: {center_str}\")\n",
    "            print(f\"Opponent expeditions: {opp_exped_str}\")\n",
    "            print(f\"Valid draws: {valid_draws}\")\n",
    "\n",
    "            user_input = input(\"Enter move as (E/C) CARD DRAW (e.g., E B3 D): \").strip().upper()\n",
    "            try:\n",
    "                move_type, card_str, draw_choice = user_input.split()\n",
    "                assert move_type in ['E', 'C']\n",
    "                assert any(card_str == card for _, card in actions), \"Invalid card\"\n",
    "                assert draw_choice in ['D'] + COLORS, \"Invalid draw\"\n",
    "            except Exception as e:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "\n",
    "            chosen_action = ('expedition', card_str) if move_type == 'E' else ('center', card_str)\n",
    "            chosen_draw = 'deck' if draw_choice == 'D' else draw_choice\n",
    "\n",
    "        else:\n",
    "            # ===== MODEL TURN =====\n",
    "            features_np = extract_features(state)\n",
    "            features = torch.tensor(features_np, dtype=torch.float32)\n",
    "            card_logits, draw_logits, value = model(features)\n",
    "\n",
    "            # Card action selection (no change)\n",
    "            card_probs = torch.softmax(card_logits[:len(actions)], dim=0)\n",
    "            card_dist = torch.distributions.Categorical(card_probs)\n",
    "            card_idx = card_dist.sample().item()\n",
    "            chosen_action = actions[card_idx]\n",
    "\n",
    "            # Filter valid draws based on chosen_action (if it's a center discard)\n",
    "            discard_color = None\n",
    "            if chosen_action[0] == 'center':\n",
    "                discard_color = chosen_action[1][0]\n",
    "            \n",
    "            filtered_draws = [\n",
    "                d for d in valid_draws if d != discard_color\n",
    "            ]\n",
    "            if not filtered_draws:\n",
    "                # Failsafe: fallback to deck\n",
    "                filtered_draws = ['deck']\n",
    "\n",
    "            valid_draws=filtered_draws\n",
    "            \n",
    "            # Draw choice selection (FIXED)\n",
    "            if random.random() < epsilon:\n",
    "                chosen_draw = random.choice(valid_draws)\n",
    "            else:\n",
    "                # Map valid draws to their indices in logits\n",
    "                draw_indices_in_logits = [draw_to_index[d] for d in valid_draws]\n",
    "                draw_logits_filtered = draw_logits[draw_indices_in_logits]\n",
    "                draw_probs = torch.softmax(draw_logits_filtered, dim=0)\n",
    "                draw_dist = torch.distributions.Categorical(draw_probs)\n",
    "                draw_idx = draw_dist.sample().item()\n",
    "                chosen_draw = valid_draws[draw_idx]\n",
    "\n",
    "            opp_hand = state['hands'][current_player]\n",
    "            print(f\"P1 plays: {chosen_action} | Draws: {chosen_draw} -- holding {opp_hand}\")\n",
    "\n",
    "        # Step and advance\n",
    "        next_state, reward, done = env.step(chosen_action, chosen_draw)\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            p1_score = env.compute_score('P1')\n",
    "            p2_score = env.compute_score('P2')\n",
    "            print(f\"\\n=== Game Over ===\")\n",
    "            print(f\"Final Score  P1: {p1_score} | P2: {p2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04655e75-7777-4871-adbb-f9abc72cbfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCritic(\n",
       "  (fc1): Linear(in_features=43, out_features=96, bias=True)\n",
       "  (fc2): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.15, inplace=False)\n",
       "  (policy_action_head): Linear(in_features=32, out_features=18, bias=True)\n",
       "  (policy_draw_head): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (value_head): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lc_model_v1B_2.pt'))\n",
    "model.eval()  # Important: sets model to evaluation mode (no dropout etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3b70826-0775-469b-8c72-34e923f851c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1  P1 ===\n",
      "P1 plays: ('center', 'B3') | Draws: deck -- holding ['B3', 'B4', 'B6']\n",
      "\n",
      "=== Turn 2  P2 ===\n",
      "Your hand: ['R2', 'R3', 'R6']\n",
      "Your expeditions: R:[] | B:[] | G:[]\n",
      "Center piles: R:[] | B:['B3'] | G:[]\n",
      "Opponent expeditions: R:[] | B:[] | G:[]\n",
      "Valid draws: ['deck', 'B']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m play_bot(\u001b[38;5;241m0.00\u001b[39m)\n",
      "Cell \u001b[1;32mIn[93], line 36\u001b[0m, in \u001b[0;36mplay_bot\u001b[1;34m(epsilon)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpponent expeditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopp_exped_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid draws: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_draws\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter move as (E/C) CARD DRAW (e.g., E B3 D): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     move_type, card_str, draw_choice \u001b[38;5;241m=\u001b[39m user_input\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "play_bot(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f86ea-effa-4a7a-8a03-ef5b72e471fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
